{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577ac833",
   "metadata": {},
   "source": [
    "# Create Bitcoin Price Prediction Dataset with Local News Summaries\n",
    "\n",
    "This notebook creates a custom dataset for fine-tuning a language model to predict Bitcoin prices using only local data sources. It combines:\n",
    "1.  **Daily News Summaries**: Generated from your local Bitcoin news analysis files.\n",
    "2.  **Historical Price Data**: From Yahoo Finance.\n",
    "3.  **Additional Market Data**: Gold and Oil prices for macro context.\n",
    "\n",
    "The final dataset will be structured for an instruction-based fine-tuning task without any external dataset dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33ceb92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8374.68s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets pandas numpy yfinance tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6750c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import yfinance as yf\n",
    "from datasets import Dataset, load_dataset\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ccf99de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully logged in.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# IMPORTANT: Replace \"YOUR_HF_TOKEN\" with your actual Hugging Face access token.\n",
    "# For better security, it's recommended to use environment variables or secrets management.\n",
    "hf_token = \"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\" \n",
    "\n",
    "if not hf_token or hf_token == \"YOUR_HF_TOKEN\":\n",
    "    print(\"❌ Please replace 'YOUR_HF_TOKEN' with your actual Hugging Face access token and re-run the cell.\")\n",
    "else:\n",
    "    try:\n",
    "        login(token=hf_token, add_to_git_credential=False)\n",
    "        print(\"✅ Successfully logged in.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Login failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e789706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading price data for Bitcoin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/l2rdx46d6lv3b5xc17b420yc0000gn/T/ipykernel_74050/3686329067.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download('BTC-USD', start='2018-01-01', end='2024-06-01', progress=False)\n",
      "/var/folders/cg/l2rdx46d6lv3b5xc17b420yc0000gn/T/ipykernel_74050/3686329067.py:46: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  gold_data = yf.download('GC=F', start='2018-01-01', end='2024-06-01', progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data columns: [('Close', 'BTC-USD'), ('High', 'BTC-USD'), ('Low', 'BTC-USD'), ('Open', 'BTC-USD'), ('Volume', 'BTC-USD')]\n",
      "Flattened columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
      "✅ Bitcoin price data loaded.\n",
      "Final price columns: ['btc_price']\n",
      "Data shape: (2343, 1)\n",
      "\n",
      "Loading additional market data...\n",
      "Downloading Gold and Oil data...\n",
      "✅ Gold and Oil data loaded.\n",
      "\n",
      "Skipping external LLM-Augmented dataset (using local data only)...\n",
      "✅ Using local Bitcoin news and price data only.\n",
      "\n",
      "--- Bitcoin Price Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/l2rdx46d6lv3b5xc17b420yc0000gn/T/ipykernel_74050/3686329067.py:47: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  oil_data = yf.download('CL=F', start='2018-01-01', end='2024-06-01', progress=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00+00:00</th>\n",
       "      <td>13657.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00+00:00</th>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              btc_price\n",
       "Date                                   \n",
       "2018-01-01 00:00:00+00:00  13657.200195\n",
       "2018-01-02 00:00:00+00:00  14982.099609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Load Historical Price Data ---\n",
    "print(\"Downloading price data for Bitcoin...\")\n",
    "try:\n",
    "    data = yf.download('BTC-USD', start='2018-01-01', end='2024-06-01', progress=False)\n",
    "    \n",
    "    # Debug: Check the raw structure\n",
    "    print(\"Raw data columns:\", data.columns.tolist())\n",
    "    \n",
    "    # Handle MultiIndex columns from yfinance\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        # Flatten MultiIndex columns - take the first level (metric names like 'Close', 'Open', etc.)\n",
    "        data.columns = [col[0] for col in data.columns]\n",
    "        print(\"Flattened columns:\", data.columns.tolist())\n",
    "    \n",
    "    # Create a clean price dataframe with a single 'btc_price' column\n",
    "    if 'Close' in data.columns:\n",
    "        df_prices = pd.DataFrame({'btc_price': data['Close']})\n",
    "    elif 'Adj Close' in data.columns:\n",
    "        df_prices = pd.DataFrame({'btc_price': data['Adj Close']})\n",
    "    else:\n",
    "        # Fallback to the first numeric column\n",
    "        num_cols = [c for c in data.columns if data[c].dtype.kind in 'biufc']\n",
    "        if num_cols:\n",
    "            df_prices = pd.DataFrame({'btc_price': data[num_cols[0]]})\n",
    "        else:\n",
    "            df_prices = pd.DataFrame(columns=['btc_price'])\n",
    "    \n",
    "    df_prices.index = pd.to_datetime(df_prices.index, utc=True)\n",
    "    \n",
    "    # Remove any duplicate columns\n",
    "    df_prices = df_prices.loc[:, ~df_prices.columns.duplicated()]\n",
    "    \n",
    "    print(\"✅ Bitcoin price data loaded.\")\n",
    "    print(\"Final price columns:\", df_prices.columns.tolist())\n",
    "    print(f\"Data shape: {df_prices.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not load price data. Error: {e}\")\n",
    "    df_prices = pd.DataFrame(columns=['btc_price'])\n",
    "\n",
    "# Try to load additional market data like in the other notebooks\n",
    "print(\"\\nLoading additional market data...\")\n",
    "try:\n",
    "    print(\"Downloading Gold and Oil data...\")\n",
    "    # Download separately to avoid issues\n",
    "    gold_data = yf.download('GC=F', start='2018-01-01', end='2024-06-01', progress=False)\n",
    "    oil_data = yf.download('CL=F', start='2018-01-01', end='2024-06-01', progress=False)\n",
    "    \n",
    "    # Handle gold data\n",
    "    if not gold_data.empty:\n",
    "        if isinstance(gold_data.columns, pd.MultiIndex):\n",
    "            gold_data.columns = [col[0] for col in gold_data.columns]\n",
    "        df_gold = pd.DataFrame({'gold_price': gold_data.get('Close', gold_data.iloc[:, 0])})\n",
    "        df_gold.index = pd.to_datetime(df_gold.index, utc=True)\n",
    "        df_gold = df_gold.loc[:, ~df_gold.columns.duplicated()]\n",
    "    else:\n",
    "        df_gold = pd.DataFrame(columns=['gold_price'])\n",
    "    \n",
    "    # Handle oil data\n",
    "    if not oil_data.empty:\n",
    "        if isinstance(oil_data.columns, pd.MultiIndex):\n",
    "            oil_data.columns = [col[0] for col in oil_data.columns]\n",
    "        df_oil = pd.DataFrame({'oil_price': oil_data.get('Close', oil_data.iloc[:, 0])})\n",
    "        df_oil.index = pd.to_datetime(df_oil.index, utc=True)\n",
    "        df_oil = df_oil.loc[:, ~df_oil.columns.duplicated()]\n",
    "    else:\n",
    "        df_oil = pd.DataFrame(columns=['oil_price'])\n",
    "    \n",
    "    print(\"✅ Gold and Oil data loaded.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not load commodity data: {e}\")\n",
    "    df_gold = pd.DataFrame(columns=['gold_price'])\n",
    "    df_oil = pd.DataFrame(columns=['oil_price'])\n",
    "\n",
    "# Skip loading external LLM metrics dataset - using only local data\n",
    "print(\"\\nSkipping external LLM-Augmented dataset (using local data only)...\")\n",
    "df_llm_metrics = pd.DataFrame()\n",
    "print(\"✅ Using local Bitcoin news and price data only.\")\n",
    "\n",
    "print(\"\\n--- Bitcoin Price Data ---\")\n",
    "display(df_prices.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93f8c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete daily news data...\n",
      "📁 Sample file structure from: 2019-11-21.json📁 Sample file structure from: 2019-11-21.json\n",
      "Available keys: ['date', 'long_term', 'short_term', 'daily_view']\n",
      "Daily view keys: ['date', 'summary', 'scenario_probs', 'recommendation_short_term', 'recommendation_long_term', 'key_risks', 'watch_items']\n",
      "--------------------------------------------------\n",
      "\n",
      "Available keys: ['date', 'long_term', 'short_term', 'daily_view']\n",
      "Daily view keys: ['date', 'summary', 'scenario_probs', 'recommendation_short_term', 'recommendation_long_term', 'key_risks', 'watch_items']\n",
      "--------------------------------------------------\n",
      "✅ Loaded 2437 complete news records.\n",
      "📊 Available columns: 11\n",
      "📅 Date range: 2018-01-01 00:00:00+00:00 to 2024-12-31 00:00:00+00:00\n",
      "🔍 Column names: ['summary', 'daily_sentiment', 'daily_key_events', 'daily_market_impact', 'daily_price_drivers', 'daily_risk_factors', 'daily_opportunities', 'news_date', 'news_long_term', 'news_short_term', 'raw_news_data']\n",
      "✅ Loaded 2437 complete news records.\n",
      "📊 Available columns: 11\n",
      "📅 Date range: 2018-01-01 00:00:00+00:00 to 2024-12-31 00:00:00+00:00\n",
      "🔍 Column names: ['summary', 'daily_sentiment', 'daily_key_events', 'daily_market_impact', 'daily_price_drivers', 'daily_risk_factors', 'daily_opportunities', 'news_date', 'news_long_term', 'news_short_term', 'raw_news_data']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>daily_sentiment</th>\n",
       "      <th>daily_key_events</th>\n",
       "      <th>daily_market_impact</th>\n",
       "      <th>daily_price_drivers</th>\n",
       "      <th>daily_risk_factors</th>\n",
       "      <th>daily_opportunities</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_long_term</th>\n",
       "      <th>news_short_term</th>\n",
       "      <th>raw_news_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00+00:00</th>\n",
       "      <td>The market sentiment for Bitcoin is decidedly ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>[{'pick_idx': 4, 'id': 'n0a76d5794f43', 'title...</td>\n",
       "      <td>[{'pick_idx': 1, 'id': 'n42d97c698aea', 'title...</td>\n",
       "      <td>{\"date\": \"2018-01-01\", \"long_term\": [{\"pick_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00+00:00</th>\n",
       "      <td>The market is showing mixed signals as 2018 be...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>[{'pick_idx': 20, 'id': 'nb7a3ae68fdf7', 'titl...</td>\n",
       "      <td>[{'pick_idx': 7, 'id': 'nf6baa9c6d6a2', 'title...</td>\n",
       "      <td>{\"date\": \"2018-01-02\", \"long_term\": [{\"pick_id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     summary  \\\n",
       "date                                                                           \n",
       "2018-01-01 00:00:00+00:00  The market sentiment for Bitcoin is decidedly ...   \n",
       "2018-01-02 00:00:00+00:00  The market is showing mixed signals as 2018 be...   \n",
       "\n",
       "                          daily_sentiment daily_key_events  \\\n",
       "date                                                         \n",
       "2018-01-01 00:00:00+00:00         neutral               []   \n",
       "2018-01-02 00:00:00+00:00         neutral               []   \n",
       "\n",
       "                          daily_market_impact daily_price_drivers  \\\n",
       "date                                                                \n",
       "2018-01-01 00:00:00+00:00             unknown                  []   \n",
       "2018-01-02 00:00:00+00:00             unknown                  []   \n",
       "\n",
       "                          daily_risk_factors daily_opportunities   news_date  \\\n",
       "date                                                                           \n",
       "2018-01-01 00:00:00+00:00                 []                  []  2018-01-01   \n",
       "2018-01-02 00:00:00+00:00                 []                  []  2018-01-02   \n",
       "\n",
       "                                                              news_long_term  \\\n",
       "date                                                                           \n",
       "2018-01-01 00:00:00+00:00  [{'pick_idx': 4, 'id': 'n0a76d5794f43', 'title...   \n",
       "2018-01-02 00:00:00+00:00  [{'pick_idx': 20, 'id': 'nb7a3ae68fdf7', 'titl...   \n",
       "\n",
       "                                                             news_short_term  \\\n",
       "date                                                                           \n",
       "2018-01-01 00:00:00+00:00  [{'pick_idx': 1, 'id': 'n42d97c698aea', 'title...   \n",
       "2018-01-02 00:00:00+00:00  [{'pick_idx': 7, 'id': 'nf6baa9c6d6a2', 'title...   \n",
       "\n",
       "                                                               raw_news_data  \n",
       "date                                                                          \n",
       "2018-01-01 00:00:00+00:00  {\"date\": \"2018-01-01\", \"long_term\": [{\"pick_id...  \n",
       "2018-01-02 00:00:00+00:00  {\"date\": \"2018-01-02\", \"long_term\": [{\"pick_id...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. Load Complete News Data ---\n",
    "print(\"Loading complete daily news data...\")\n",
    "summaries_path = \"/Users/tahamajs/Documents/uni/LLM/Files/Final Project/outputs_btc_effects/per_date/*.json\"\n",
    "all_summary_files = glob.glob(summaries_path)\n",
    "summaries_list = []\n",
    "\n",
    "# First, let's inspect the structure of a sample file\n",
    "if all_summary_files:\n",
    "    sample_file = all_summary_files[0]\n",
    "    print(f\"📁 Sample file structure from: {os.path.basename(sample_file)}\")\n",
    "    try:\n",
    "        with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "            sample_data = json.load(f)\n",
    "            print(\"Available keys:\", list(sample_data.keys()))\n",
    "            if 'daily_view' in sample_data:\n",
    "                print(\"Daily view keys:\", list(sample_data['daily_view'].keys()))\n",
    "            print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read sample file: {e}\")\n",
    "\n",
    "for file_path in all_summary_files:\n",
    "    if os.path.getsize(file_path) > 0:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                # Extract the date from the filename (e.g., '2024-01-15.json')\n",
    "                date_str = os.path.basename(file_path).split('.')[0]\n",
    "                \n",
    "                # Extract ALL available information from the JSON\n",
    "                daily_info = {\n",
    "                    'date': pd.to_datetime(date_str, utc=True),\n",
    "                    # Basic summary (as before)\n",
    "                    'summary': data.get('daily_view', {}).get('summary', 'No summary available.'),\n",
    "                }\n",
    "                \n",
    "                # Add daily_view information if available\n",
    "                daily_view = data.get('daily_view', {})\n",
    "                if daily_view:\n",
    "                    daily_info.update({\n",
    "                        'daily_sentiment': daily_view.get('sentiment', 'neutral'),\n",
    "                        'daily_key_events': daily_view.get('key_events', []),\n",
    "                        'daily_market_impact': daily_view.get('market_impact', 'unknown'),\n",
    "                        'daily_price_drivers': daily_view.get('price_drivers', []),\n",
    "                        'daily_risk_factors': daily_view.get('risk_factors', []),\n",
    "                        'daily_opportunities': daily_view.get('opportunities', []),\n",
    "                    })\n",
    "                \n",
    "                # Add any other top-level keys from the JSON\n",
    "                for key, value in data.items():\n",
    "                    if key != 'daily_view' and isinstance(value, (str, int, float, list)):\n",
    "                        daily_info[f'news_{key}'] = value\n",
    "                    elif key != 'daily_view' and isinstance(value, dict):\n",
    "                        # For nested dictionaries, flatten them with prefixes\n",
    "                        for subkey, subvalue in value.items():\n",
    "                            if isinstance(subvalue, (str, int, float, list)):\n",
    "                                daily_info[f'news_{key}_{subkey}'] = subvalue\n",
    "                \n",
    "                # Add raw JSON as backup (for complex structures)\n",
    "                daily_info['raw_news_data'] = json.dumps(data, ensure_ascii=False)\n",
    "                \n",
    "                summaries_list.append(daily_info)\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Could not decode JSON from {file_path}\")\n",
    "\n",
    "df_summaries = pd.DataFrame(summaries_list)\n",
    "if not df_summaries.empty:\n",
    "    df_summaries.set_index('date', inplace=True)\n",
    "    df_summaries.sort_index(inplace=True)\n",
    "    print(f\"✅ Loaded {len(df_summaries)} complete news records.\")\n",
    "    print(f\"📊 Available columns: {len(df_summaries.columns)}\")\n",
    "    print(f\"📅 Date range: {df_summaries.index.min()} to {df_summaries.index.max()}\")\n",
    "    print(f\"🔍 Column names: {list(df_summaries.columns)}\")\n",
    "    display(df_summaries.head(2))\n",
    "else:\n",
    "    print(\"❌ No summaries were loaded. Check the file path.\")\n",
    "    df_summaries = pd.DataFrame(columns=['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ac8d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all data sources into a single DataFrame...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341866f889c94a8b9c6a6bfdf97655a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating Daily Data:   0%|          | 0/2343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final combined dataset created with 2303 samples.\n",
      "\n",
      "Debug statistics:\n",
      "Total days processed: 2343\n",
      "Days with no price data: 0\n",
      "Days with insufficient history (<30 days): 30\n",
      "Days with insufficient future (<10 days): 10\n",
      "Days successfully added to dataset: 2303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>daily_sentiment</th>\n",
       "      <th>daily_key_events</th>\n",
       "      <th>daily_market_impact</th>\n",
       "      <th>daily_price_drivers</th>\n",
       "      <th>daily_risk_factors</th>\n",
       "      <th>daily_opportunities</th>\n",
       "      <th>news_long_term</th>\n",
       "      <th>news_short_term</th>\n",
       "      <th>raw_news_data</th>\n",
       "      <th>btc_price_history_60d</th>\n",
       "      <th>btc_price_target_10d</th>\n",
       "      <th>gold_close_price</th>\n",
       "      <th>oil_close_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>The crypto market on January 31, 2018, was cha...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'pick_idx': 11, 'id': 'n4d25fd07511b', 'titl...</td>\n",
       "      <td>[{'pick_idx': 5, 'id': 'nc285bbcb1a6b', 'title...</td>\n",
       "      <td>{\"date\": \"2018-01-31\", \"long_term\": [{\"pick_id...</td>\n",
       "      <td>[13657.2001953125, 14982.099609375, 15201.0, 1...</td>\n",
       "      <td>[9170.5400390625, 8830.75, 9174.91015625, 8277...</td>\n",
       "      <td>1339.000000</td>\n",
       "      <td>64.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>Bitcoin experienced a significant downturn tod...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'pick_idx': 8, 'id': 'n19dbb7010a58', 'title...</td>\n",
       "      <td>[{'pick_idx': 3, 'id': 'nc7631b9dff9a', 'title...</td>\n",
       "      <td>{\"date\": \"2018-02-01\", \"long_term\": [{\"pick_id...</td>\n",
       "      <td>[13657.2001953125, 14982.099609375, 15201.0, 1...</td>\n",
       "      <td>[8830.75, 9174.91015625, 8277.009765625, 6955....</td>\n",
       "      <td>1344.300049</td>\n",
       "      <td>65.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>The cryptocurrency market is experiencing a si...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'pick_idx': 37, 'id': 'n05a6f3d453b5', 'titl...</td>\n",
       "      <td>[{'pick_idx': 4, 'id': 'ndc5191bddd44', 'title...</td>\n",
       "      <td>{\"date\": \"2018-02-02\", \"long_term\": [{\"pick_id...</td>\n",
       "      <td>[13657.2001953125, 14982.099609375, 15201.0, 1...</td>\n",
       "      <td>[9174.91015625, 8277.009765625, 6955.270019531...</td>\n",
       "      <td>1333.699951</td>\n",
       "      <td>65.449997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>The cryptocurrency market is experiencing sign...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'pick_idx': 14, 'id': 'n153e90d94f5e', 'titl...</td>\n",
       "      <td>[{'pick_idx': 4, 'id': 'n0f56c708e25d', 'title...</td>\n",
       "      <td>{\"date\": \"2018-02-03\", \"long_term\": [{\"pick_id...</td>\n",
       "      <td>[13657.2001953125, 14982.099609375, 15201.0, 1...</td>\n",
       "      <td>[8277.009765625, 6955.27001953125, 7754.0, 762...</td>\n",
       "      <td>1333.699951</td>\n",
       "      <td>65.449997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>The crypto market is experiencing significant ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'pick_idx': 12, 'id': 'n21eb7aad55cf', 'titl...</td>\n",
       "      <td>[{'pick_idx': 13, 'id': 'ndcba5b9f608f', 'titl...</td>\n",
       "      <td>{\"date\": \"2018-02-04\", \"long_term\": [{\"pick_id...</td>\n",
       "      <td>[13657.2001953125, 14982.099609375, 15201.0, 1...</td>\n",
       "      <td>[6955.27001953125, 7754.0, 7621.2998046875, 82...</td>\n",
       "      <td>1333.699951</td>\n",
       "      <td>65.449997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                       news_summary  \\\n",
       "0  2018-01-31  The crypto market on January 31, 2018, was cha...   \n",
       "1  2018-02-01  Bitcoin experienced a significant downturn tod...   \n",
       "2  2018-02-02  The cryptocurrency market is experiencing a si...   \n",
       "3  2018-02-03  The cryptocurrency market is experiencing sign...   \n",
       "4  2018-02-04  The crypto market is experiencing significant ...   \n",
       "\n",
       "  daily_sentiment daily_key_events daily_market_impact daily_price_drivers  \\\n",
       "0         neutral               []             unknown                  []   \n",
       "1         neutral               []             unknown                  []   \n",
       "2         neutral               []             unknown                  []   \n",
       "3         neutral               []             unknown                  []   \n",
       "4         neutral               []             unknown                  []   \n",
       "\n",
       "  daily_risk_factors daily_opportunities  \\\n",
       "0                 []                  []   \n",
       "1                 []                  []   \n",
       "2                 []                  []   \n",
       "3                 []                  []   \n",
       "4                 []                  []   \n",
       "\n",
       "                                      news_long_term  \\\n",
       "0  [{'pick_idx': 11, 'id': 'n4d25fd07511b', 'titl...   \n",
       "1  [{'pick_idx': 8, 'id': 'n19dbb7010a58', 'title...   \n",
       "2  [{'pick_idx': 37, 'id': 'n05a6f3d453b5', 'titl...   \n",
       "3  [{'pick_idx': 14, 'id': 'n153e90d94f5e', 'titl...   \n",
       "4  [{'pick_idx': 12, 'id': 'n21eb7aad55cf', 'titl...   \n",
       "\n",
       "                                     news_short_term  \\\n",
       "0  [{'pick_idx': 5, 'id': 'nc285bbcb1a6b', 'title...   \n",
       "1  [{'pick_idx': 3, 'id': 'nc7631b9dff9a', 'title...   \n",
       "2  [{'pick_idx': 4, 'id': 'ndc5191bddd44', 'title...   \n",
       "3  [{'pick_idx': 4, 'id': 'n0f56c708e25d', 'title...   \n",
       "4  [{'pick_idx': 13, 'id': 'ndcba5b9f608f', 'titl...   \n",
       "\n",
       "                                       raw_news_data  \\\n",
       "0  {\"date\": \"2018-01-31\", \"long_term\": [{\"pick_id...   \n",
       "1  {\"date\": \"2018-02-01\", \"long_term\": [{\"pick_id...   \n",
       "2  {\"date\": \"2018-02-02\", \"long_term\": [{\"pick_id...   \n",
       "3  {\"date\": \"2018-02-03\", \"long_term\": [{\"pick_id...   \n",
       "4  {\"date\": \"2018-02-04\", \"long_term\": [{\"pick_id...   \n",
       "\n",
       "                               btc_price_history_60d  \\\n",
       "0  [13657.2001953125, 14982.099609375, 15201.0, 1...   \n",
       "1  [13657.2001953125, 14982.099609375, 15201.0, 1...   \n",
       "2  [13657.2001953125, 14982.099609375, 15201.0, 1...   \n",
       "3  [13657.2001953125, 14982.099609375, 15201.0, 1...   \n",
       "4  [13657.2001953125, 14982.099609375, 15201.0, 1...   \n",
       "\n",
       "                                btc_price_target_10d  gold_close_price  \\\n",
       "0  [9170.5400390625, 8830.75, 9174.91015625, 8277...       1339.000000   \n",
       "1  [8830.75, 9174.91015625, 8277.009765625, 6955....       1344.300049   \n",
       "2  [9174.91015625, 8277.009765625, 6955.270019531...       1333.699951   \n",
       "3  [8277.009765625, 6955.27001953125, 7754.0, 762...       1333.699951   \n",
       "4  [6955.27001953125, 7754.0, 7621.2998046875, 82...       1333.699951   \n",
       "\n",
       "   oil_close_price  \n",
       "0        64.730003  \n",
       "1        65.800003  \n",
       "2        65.449997  \n",
       "3        65.449997  \n",
       "4        65.449997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset columns: ['date', 'news_summary', 'daily_sentiment', 'daily_key_events', 'daily_market_impact', 'daily_price_drivers', 'daily_risk_factors', 'daily_opportunities', 'news_long_term', 'news_short_term', 'raw_news_data', 'btc_price_history_60d', 'btc_price_target_10d', 'gold_close_price', 'oil_close_price']\n",
      "Sample price history length: 30\n",
      "Sample target length: 10\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Combine All Data Sources ---\n",
    "print(\"Combining all data sources into a single DataFrame...\")\n",
    "\n",
    "# Helper function from the advanced notebooks\n",
    "def get_value_for_day(df, day_str, col_name):\n",
    "    if df.empty or day_str not in df.index:\n",
    "        return np.nan\n",
    "    try:\n",
    "        value = df.loc[day_str, col_name]\n",
    "        if not pd.api.types.is_scalar(value): \n",
    "            value = value.iloc[0] if hasattr(value, 'iloc') else value\n",
    "        return value\n",
    "    except (KeyError, IndexError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "# Create a daily date range (use a narrower range where we know we have data)\n",
    "daily_dates = pd.date_range(start='2018-01-01', end='2024-05-31', freq='D', tz='UTC')\n",
    "final_data_list = []\n",
    "\n",
    "# Debug counters\n",
    "total_days = len(daily_dates)\n",
    "days_with_no_price_data = 0\n",
    "days_with_insufficient_history = 0\n",
    "days_with_insufficient_future = 0\n",
    "days_added = 0\n",
    "\n",
    "for day in tqdm(daily_dates, desc=\"Aggregating Daily Data\"):\n",
    "    day_str = day.strftime('%Y-%m-%d')\n",
    "\n",
    "    try:\n",
    "        # Check if the price data exists and has the required column\n",
    "        if df_prices.empty or 'btc_price' not in df_prices.columns:\n",
    "            days_with_no_price_data += 1\n",
    "            continue\n",
    "            \n",
    "        # Get historical prices (past 60 days) - FIX: Extract Series first, then convert to list\n",
    "        past_prices_df = df_prices[(df_prices.index >= (day - timedelta(days=60))) & (df_prices.index < day)]\n",
    "        if past_prices_df.empty:\n",
    "            days_with_insufficient_history += 1\n",
    "            continue\n",
    "        past_60_day_prices = past_prices_df['btc_price'].dropna().tolist()  # Extract Series first\n",
    "        \n",
    "        if len(past_60_day_prices) < 30:  # Require at least 30 days of history\n",
    "            days_with_insufficient_history += 1\n",
    "            continue\n",
    "        \n",
    "        # Get future prices (next 10 days) - FIX: Extract Series first, then convert to list\n",
    "        future_prices_df = df_prices[(df_prices.index > day) & (df_prices.index <= (day + timedelta(days=10)))]\n",
    "        if future_prices_df.empty:\n",
    "            days_with_insufficient_future += 1\n",
    "            continue\n",
    "        future_10_day_prices = future_prices_df['btc_price'].dropna().tolist()  # Extract Series first\n",
    "\n",
    "        # Need a full 10-day target\n",
    "        if len(future_10_day_prices) < 10:\n",
    "            days_with_insufficient_future += 1\n",
    "            continue\n",
    "\n",
    "        # Get additional market data (like in the advanced notebooks)\n",
    "        gold_price = get_value_for_day(df_gold, day_str, 'gold_price') if not df_gold.empty else np.nan\n",
    "        oil_price = get_value_for_day(df_oil, day_str, 'oil_price') if not df_oil.empty else np.nan\n",
    "        \n",
    "        # Skip external LLM metrics - using only local data\n",
    "        hash_rate = np.nan\n",
    "        difficulty = np.nan\n",
    "        transactions = np.nan\n",
    "        unique_addresses = np.nan\n",
    "        fng_index = np.nan\n",
    "        cbbi_index = np.nan\n",
    "        llm_sentiment = np.nan\n",
    "        market_cap = np.nan\n",
    "        total_bitcoins = np.nan\n",
    "        estimated_tx_volume = np.nan\n",
    "\n",
    "        # Get comprehensive news data for this date\n",
    "        news_summary = get_value_for_day(df_summaries, day_str, 'summary')\n",
    "        daily_sentiment = get_value_for_day(df_summaries, day_str, 'daily_sentiment')\n",
    "        daily_key_events = get_value_for_day(df_summaries, day_str, 'daily_key_events')\n",
    "        daily_market_impact = get_value_for_day(df_summaries, day_str, 'daily_market_impact')\n",
    "        daily_price_drivers = get_value_for_day(df_summaries, day_str, 'daily_price_drivers')\n",
    "        daily_risk_factors = get_value_for_day(df_summaries, day_str, 'daily_risk_factors')\n",
    "        daily_opportunities = get_value_for_day(df_summaries, day_str, 'daily_opportunities')\n",
    "        news_long_term = get_value_for_day(df_summaries, day_str, 'news_long_term')\n",
    "        news_short_term = get_value_for_day(df_summaries, day_str, 'news_short_term')\n",
    "        raw_news_data = get_value_for_day(df_summaries, day_str, 'raw_news_data')\n",
    "\n",
    "        final_data_list.append({\n",
    "            'date': day.date(),\n",
    "            # Comprehensive news data\n",
    "            'news_summary': news_summary,\n",
    "            'daily_sentiment': daily_sentiment,\n",
    "            'daily_key_events': daily_key_events,\n",
    "            'daily_market_impact': daily_market_impact,\n",
    "            'daily_price_drivers': daily_price_drivers,\n",
    "            'daily_risk_factors': daily_risk_factors,\n",
    "            'daily_opportunities': daily_opportunities,\n",
    "            'news_long_term': news_long_term,\n",
    "            'news_short_term': news_short_term,\n",
    "            'raw_news_data': raw_news_data,\n",
    "            # Price data\n",
    "            'btc_price_history_60d': past_60_day_prices,\n",
    "            'btc_price_target_10d': future_10_day_prices,\n",
    "            # Additional market data\n",
    "            'gold_close_price': gold_price,\n",
    "            'oil_close_price': oil_price,\n",
    "            # Note: Skipping external LLM metrics to avoid dependencies\n",
    "            # Using only local Bitcoin news and price data\n",
    "        })\n",
    "        days_added += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for {day_str}: {e}\")\n",
    "        continue\n",
    "\n",
    "final_dataset = pd.DataFrame(final_data_list)\n",
    "\n",
    "    # Fill missing values for available columns\n",
    "if not final_dataset.empty:\n",
    "    # Forward fill numeric columns that exist\n",
    "    cols_to_fill_numeric = ['gold_close_price', 'oil_close_price']\n",
    "    for col in cols_to_fill_numeric:\n",
    "        if col in final_dataset.columns:\n",
    "            final_dataset[col] = final_dataset[col].ffill()\n",
    "    \n",
    "    # Fill news text columns\n",
    "    final_dataset['news_summary'].fillna('No news summary available.', inplace=True)\n",
    "    final_dataset['daily_sentiment'].fillna('neutral', inplace=True)\n",
    "    final_dataset['daily_market_impact'].fillna('unknown', inplace=True)\n",
    "    final_dataset['daily_key_events'].fillna('[]', inplace=True)\n",
    "    final_dataset['daily_price_drivers'].fillna('[]', inplace=True)\n",
    "    final_dataset['daily_risk_factors'].fillna('[]', inplace=True)\n",
    "    final_dataset['daily_opportunities'].fillna('[]', inplace=True)\n",
    "    final_dataset['news_long_term'].fillna('[]', inplace=True)\n",
    "    final_dataset['news_short_term'].fillna('[]', inplace=True)\n",
    "    final_dataset['raw_news_data'].fillna('{}', inplace=True)\n",
    "print(f\"\\n✅ Final combined dataset created with {len(final_dataset)} samples.\")\n",
    "print(f\"\\nDebug statistics:\")\n",
    "print(f\"Total days processed: {total_days}\")\n",
    "print(f\"Days with no price data: {days_with_no_price_data}\")\n",
    "print(f\"Days with insufficient history (<30 days): {days_with_insufficient_history}\")\n",
    "print(f\"Days with insufficient future (<10 days): {days_with_insufficient_future}\")\n",
    "print(f\"Days successfully added to dataset: {days_added}\")\n",
    "\n",
    "if not final_dataset.empty:\n",
    "    display(final_dataset.head())\n",
    "    print(f\"\\nDataset columns: {final_dataset.columns.tolist()}\")\n",
    "    print(f\"Sample price history length: {len(final_dataset.iloc[0]['btc_price_history_60d']) if not final_dataset.empty else 'N/A'}\")\n",
    "    print(f\"Sample target length: {len(final_dataset.iloc[0]['btc_price_target_10d']) if not final_dataset.empty else 'N/A'}\")\n",
    "else:\n",
    "    print(\"Dataset is empty. No samples were created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b16f2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug Information:\n",
      "Price data date range: 2018-01-01 00:00:00+00:00 to 2024-05-31 00:00:00+00:00\n",
      "Price data column names: ['btc_price']\n",
      "Total price data points: 2343\n",
      "Sample prices: [13657.2001953125, 14982.099609375, 15201.0]\n"
     ]
    }
   ],
   "source": [
    "# --- Debug Price Data Information ---\n",
    "print(\"\\nDebug Information:\")\n",
    "if 'df_prices' in locals() and not df_prices.empty:\n",
    "    print(f\"Price data date range: {df_prices.index.min()} to {df_prices.index.max()}\")\n",
    "    print(f\"Price data column names: {df_prices.columns.tolist()}\")\n",
    "    print(f\"Total price data points: {len(df_prices)}\")\n",
    "    \n",
    "    # Handle duplicate columns by using iloc to access the first column\n",
    "    if len(df_prices.columns) > 0:\n",
    "        first_col_name = df_prices.columns[0]\n",
    "        sample_prices = df_prices.iloc[:3, 0].tolist()  # Use iloc to avoid duplicate column issues\n",
    "        print(f\"Sample prices: {sample_prices}\")\n",
    "    \n",
    "    # Check for data gaps\n",
    "    date_diff = df_prices.index.to_series().diff().dropna()\n",
    "    gaps = date_diff[date_diff > pd.Timedelta(days=1)]\n",
    "    if not gaps.empty:\n",
    "        print(f\"Found {len(gaps)} gaps in price data. First 3 gaps:\")\n",
    "        for idx, gap in gaps.head(3).items():\n",
    "            print(f\"  Gap of {gap} after {idx}\")\n",
    "    \n",
    "    # Check if we have duplicate columns\n",
    "    if len(df_prices.columns) != len(df_prices.columns.unique()):\n",
    "        print(f\"⚠️  WARNING: Found duplicate columns! Unique columns: {df_prices.columns.unique()}\")\n",
    "        print(\"This needs to be fixed in the price loading cell.\")\n",
    "else:\n",
    "    print(\"Price data is empty or not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "941a8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transformation with advanced features...\n",
      "\n",
      "✅ Advanced dataset transformation complete!\n",
      "   Rows processed: 2303\n",
      "   Rows kept: 2303\n",
      "   Rows skipped: 0\n",
      "   Final dataset size: 2303 samples\n",
      "\n",
      "Sample entry:\n",
      "\n",
      "✅ Advanced dataset transformation complete!\n",
      "   Rows processed: 2303\n",
      "   Rows kept: 2303\n",
      "   Rows skipped: 0\n",
      "   Final dataset size: 2303 samples\n",
      "\n",
      "Sample entry:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are an expert quantitative crypto analyst....</td>\n",
       "      <td>Daily Context — 2018-01-31\\n\\n[Technical Price...</td>\n",
       "      <td>{\"action\":\"SELL\",\"confidence\":95,\"stop_loss\":9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You are an expert quantitative crypto analyst....   \n",
       "\n",
       "                                               input  \\\n",
       "0  Daily Context — 2018-01-31\\n\\n[Technical Price...   \n",
       "\n",
       "                                              output  \n",
       "0  {\"action\":\"SELL\",\"confidence\":95,\"stop_loss\":9...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: You are an expert quantitative crypto analyst. Your tasks:\n",
      "1) Analyze the context and decide an actionable stance for BTC-USD: BUY, SELL, or HOLD.\n",
      "2) Forecast the NEXT 10 daily CLOSING prices (USD).\n",
      "\n",
      "...\n",
      "Input: Daily Context — 2018-01-31\n",
      "\n",
      "[Technical Price Analysis]\n",
      "- Current Price: $10,106.30\n",
      "- 60-Day Range: $10,106.30 → $17,527.00\n",
      "- 1D Return: -10.54%\n",
      "- 7D Return: -7.01%\n",
      "- 30D Return: N/A%\n",
      "- Volatility (14d): 5.76%\n",
      "- Avg Daily Change (14d): 501.23\n",
      "- Drawdown from Max: -42.34%\n",
      "\n",
      "[Price History (Last 60 Days...\n",
      "Output: {\"action\":\"SELL\",\"confidence\":95,\"stop_loss\":9103.84,\"take_profit\":11108.76,\"forecast_10d\":[9170.54, 8830.75, 9174.91, 8277.01, 6955.27, 7754.00, 7621.30, 8265.59, 8736.98, 8621.90]}\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Create Advanced Instruction-Formatted Dataset ---\n",
    "print(\"Starting transformation with advanced features...\")\n",
    "\n",
    "# Helper functions from the advanced notebooks\n",
    "def _fmt_usd(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return \"N/A\"\n",
    "    try:\n",
    "        return f\"${float(x):,.2f}\"\n",
    "    except Exception:\n",
    "        return \"N/A\"\n",
    "\n",
    "def _fmt_float(x, nd=2):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return \"N/A\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return \"N/A\"\n",
    "\n",
    "def _derive_price_features(prices):\n",
    "    \"\"\"Calculate technical indicators from price history\"\"\"\n",
    "    if not isinstance(prices, (list, tuple)) or len(prices) == 0:\n",
    "        return dict(\n",
    "            last_close=np.nan, min60=np.nan, max60=np.nan,\n",
    "            ret_1d_pct=np.nan, ret_7d_pct=np.nan, ret_30d_pct=np.nan,\n",
    "            std14_pct=np.nan, avg_abs_change14=np.nan, drawdown_from_max_pct=np.nan\n",
    "        )\n",
    "    \n",
    "    arr = np.array(prices, dtype=float)\n",
    "    last_close = arr[-1]\n",
    "    min60 = float(np.min(arr))\n",
    "    max60 = float(np.max(arr))\n",
    "\n",
    "    def _pct(a, b):\n",
    "        try:\n",
    "            return (float(a) / float(b) - 1.0) * 100.0\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    ret_1d_pct  = _pct(arr[-1], arr[-2])  if arr.size >= 2  else np.nan\n",
    "    ret_7d_pct  = _pct(arr[-1], arr[-8])  if arr.size >= 8  else np.nan\n",
    "    ret_30d_pct = _pct(arr[-1], arr[-31]) if arr.size >= 31 else np.nan\n",
    "\n",
    "    if arr.size >= 15:\n",
    "        # percent returns over last 14 intervals\n",
    "        rets = np.diff(arr[-15:]) / arr[-15:-1] * 100.0\n",
    "        std14_pct = float(np.std(rets, ddof=1))\n",
    "        avg_abs_change14 = float(np.mean(np.abs(np.diff(arr[-15:]))))\n",
    "    else:\n",
    "        std14_pct = np.nan\n",
    "        avg_abs_change14 = np.nan\n",
    "\n",
    "    drawdown_from_max_pct = _pct(arr[-1], max60)\n",
    "    return dict(\n",
    "        last_close=float(last_close), min60=min60, max60=max60,\n",
    "        ret_1d_pct=float(ret_1d_pct) if not pd.isna(ret_1d_pct) else np.nan,\n",
    "        ret_7d_pct=float(ret_7d_pct) if not pd.isna(ret_7d_pct) else np.nan,\n",
    "        ret_30d_pct=float(ret_30d_pct) if not pd.isna(ret_30d_pct) else np.nan,\n",
    "        std14_pct=float(std14_pct) if not pd.isna(std14_pct) else np.nan,\n",
    "        avg_abs_change14=float(avg_abs_change14) if not pd.isna(avg_abs_change14) else np.nan,\n",
    "        drawdown_from_max_pct=float(drawdown_from_max_pct) if not pd.isna(drawdown_from_max_pct) else np.nan\n",
    "    )\n",
    "\n",
    "def _label_action(last_close, future_10, std14_pct):\n",
    "    \"\"\"Generate trading action based on volatility-aware analysis\"\"\"\n",
    "    if last_close is None or np.isnan(last_close) or future_10 is None or len(future_10) < 10:\n",
    "        return \"HOLD\", 50\n",
    "    day10 = float(future_10[-1])\n",
    "    ret10_pct = (day10 / float(last_close) - 1.0) * 100.0\n",
    "    vol_ref = float(std14_pct) if std14_pct is not None and not np.isnan(std14_pct) else 2.0\n",
    "    thr = max(1.0, 0.35 * vol_ref)  # %\n",
    "    if ret10_pct >= thr:\n",
    "        action = \"BUY\"\n",
    "    elif ret10_pct <= -thr:\n",
    "        action = \"SELL\"\n",
    "    else:\n",
    "        action = \"HOLD\"\n",
    "    conf = int(np.clip(10 + (abs(ret10_pct) / max(0.5, vol_ref)) * 40, 5, 95))\n",
    "    return action, conf\n",
    "\n",
    "def _risk_bands(last_close, avg_abs_change14):\n",
    "    \"\"\"Calculate stop-loss and take-profit levels\"\"\"\n",
    "    if last_close is None or np.isnan(last_close):\n",
    "        return np.nan, np.nan\n",
    "    step = float(avg_abs_change14) if avg_abs_change14 is not None and not np.isnan(avg_abs_change14) else 0.02 * float(last_close)\n",
    "    step = max(step, 0.005 * float(last_close))  # at least 0.5% of price\n",
    "    sl = max(0.01, float(last_close) - 2.0 * step)\n",
    "    tp = float(last_close) + 2.0 * step\n",
    "    return sl, tp\n",
    "\n",
    "llm_finetuning_data = []\n",
    "rows_seen, rows_kept, rows_skipped = 0, 0, 0\n",
    "\n",
    "for index, row in final_dataset.iterrows():\n",
    "    rows_seen += 1\n",
    "    \n",
    "    # Ensure we have valid price data\n",
    "    if not row['btc_price_history_60d'] or not row['btc_price_target_10d'] or len(row['btc_price_target_10d']) < 10:\n",
    "        rows_skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Calculate price features\n",
    "    hist_prices = row['btc_price_history_60d']\n",
    "    price_history_str = \", \".join([f\"{p:.2f}\" for p in hist_prices])\n",
    "    feats = _derive_price_features(hist_prices)\n",
    "    \n",
    "    # Generate trading signals\n",
    "    action, confidence = _label_action(feats['last_close'], row['btc_price_target_10d'], feats['std14_pct'])\n",
    "    sl, tp = _risk_bands(feats['last_close'], feats['avg_abs_change14'])\n",
    "\n",
    "    # Format additional data\n",
    "    gold_price = _fmt_usd(row.get('gold_close_price'))\n",
    "    oil_price = _fmt_usd(row.get('oil_close_price'))\n",
    "    mcap_str = _fmt_usd(row.get('btc_market_cap'))\n",
    "    hash_rate = _fmt_float(row.get('btc_hash_rate'))\n",
    "    tx_count = _fmt_float(row.get('btc_transactions'), 0)\n",
    "    uniq_addr = _fmt_float(row.get('btc_unique_addresses'), 0)\n",
    "    fng_str = _fmt_float(row.get('fear_and_greed_index'))\n",
    "    cbbi_str = _fmt_float(row.get('cbbi_index'))\n",
    "    diff_str = _fmt_float(row.get('btc_difficulty'), 0)\n",
    "    tot_supply = _fmt_float(row.get('btc_total_supply'), 0)\n",
    "    est_tx_vol = _fmt_usd(row.get('btc_estimated_tx_volume_usd'))\n",
    "    llm_sent = \"N/A\" if pd.isna(row.get('llm_sentiment_class')) else str(row.get('llm_sentiment_class'))\n",
    "\n",
    "    # --- Advanced Instruction ---\n",
    "    instruction = (\n",
    "        \"You are an expert quantitative crypto analyst. Your tasks:\\n\"\n",
    "        \"1) Analyze the context and decide an actionable stance for BTC-USD: BUY, SELL, or HOLD.\\n\"\n",
    "        \"2) Forecast the NEXT 10 daily CLOSING prices (USD).\\n\\n\"\n",
    "        f\"CONTEXT DATE: {row['date']}\\n\\n\"\n",
    "        \"ANALYSIS FRAMEWORK:\\n\"\n",
    "        \"• Technical Analysis: Use price trends, volatility, and momentum indicators\\n\"\n",
    "        \"• Macro Analysis: Consider gold/oil prices for broader market context\\n\"\n",
    "        \"• News Analysis: Integrate comprehensive daily news summaries for market catalysts\\n\\n\"\n",
    "        \"OUTPUT FORMAT (JSON ONLY):\\n\"\n",
    "        \"Return a single JSON object with EXACTLY these keys:\\n\"\n",
    "        \"{\\\"action\\\":\\\"BUY|SELL|HOLD\\\",\\\"confidence\\\":<int 1-99>,\"\n",
    "        \"\\\"stop_loss\\\":<price 2dp>,\\\"take_profit\\\":<price 2dp>,\"\n",
    "        \"\\\"forecast_10d\\\":[<10 prices 2dp>]}\\n\"\n",
    "        \"No extra text, no explanations, just the JSON.\"\n",
    "    )\n",
    "\n",
    "    # --- Enhanced Input (using only local data) ---\n",
    "    input_text = f\"\"\"\n",
    "Daily Context — {row['date']}\n",
    "\n",
    "[Technical Price Analysis]\n",
    "- Current Price: {_fmt_usd(feats['last_close'])}\n",
    "- 60-Day Range: {_fmt_usd(feats['min60'])} → {_fmt_usd(feats['max60'])}\n",
    "- 1D Return: {_fmt_float(feats['ret_1d_pct'])}%\n",
    "- 7D Return: {_fmt_float(feats['ret_7d_pct'])}%\n",
    "- 30D Return: {_fmt_float(feats['ret_30d_pct'])}%\n",
    "- Volatility (14d): {_fmt_float(feats['std14_pct'])}%\n",
    "- Avg Daily Change (14d): {_fmt_float(feats['avg_abs_change14'])}\n",
    "- Drawdown from Max: {_fmt_float(feats['drawdown_from_max_pct'])}%\n",
    "\n",
    "[Price History (Last 60 Days USD)]\n",
    "[{price_history_str}]\n",
    "\n",
    "[Macro & Commodities Context]\n",
    "- Gold Price: {gold_price}\n",
    "- Crude Oil Price: {oil_price}\n",
    "\n",
    "[Market Context]\n",
    "- Bitcoin dominates crypto market as leading digital asset\n",
    "- Price influenced by adoption, regulation, and macro factors\n",
    "\n",
    "[Comprehensive News Analysis]\n",
    "Summary: {row['news_summary']}\n",
    "\n",
    "Sentiment: {row.get('daily_sentiment', 'neutral')}\n",
    "Market Impact: {row.get('daily_market_impact', 'unknown')}\n",
    "\n",
    "Key Events: {', '.join(row.get('daily_key_events', [])) if isinstance(row.get('daily_key_events'), list) and row.get('daily_key_events') else 'No key events'}\n",
    "\n",
    "Price Drivers: {', '.join(row.get('daily_price_drivers', [])) if isinstance(row.get('daily_price_drivers'), list) and row.get('daily_price_drivers') else 'No specific drivers'}\n",
    "\n",
    "Risk Factors: {', '.join(row.get('daily_risk_factors', [])) if isinstance(row.get('daily_risk_factors'), list) and row.get('daily_risk_factors') else 'No major risks'}\n",
    "\n",
    "Opportunities: {', '.join(row.get('daily_opportunities', [])) if isinstance(row.get('daily_opportunities'), list) and row.get('daily_opportunities') else 'No specific opportunities'}\n",
    "\n",
    "Short-term News: {str(row.get('news_short_term', 'No short-term news'))[:200] + '...' if len(str(row.get('news_short_term', ''))) > 200 else str(row.get('news_short_term', 'No short-term news'))}\n",
    "\n",
    "Long-term News: {str(row.get('news_long_term', 'No long-term news'))[:200] + '...' if len(str(row.get('news_long_term', ''))) > 200 else str(row.get('news_long_term', 'No long-term news'))}\n",
    "\n",
    "Based on this comprehensive multi-dimensional analysis incorporating technical indicators, fundamentals, sentiment, and detailed news analysis, provide your trading decision and 10-day price forecast in the specified JSON format.\n",
    "\"\"\".strip()\n",
    "\n",
    "    # --- Enhanced Output ---\n",
    "    forecast_str = \", \".join([f\"{p:.2f}\" for p in row['btc_price_target_10d'][:10]])\n",
    "    output_text = (\n",
    "        '{'\n",
    "        f'\"action\":\"{action}\",'\n",
    "        f'\"confidence\":{confidence},'\n",
    "        f'\"stop_loss\":{sl:.2f},'\n",
    "        f'\"take_profit\":{tp:.2f},'\n",
    "        f'\"forecast_10d\":[{forecast_str}]'\n",
    "        '}'\n",
    "    )\n",
    "\n",
    "    llm_finetuning_data.append({\n",
    "        'instruction': instruction.strip(),\n",
    "        'input': input_text,\n",
    "        'output': output_text\n",
    "    })\n",
    "    rows_kept += 1\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "df_finetuning = pd.DataFrame(llm_finetuning_data)\n",
    "hf_finetuning_dataset = Dataset.from_pandas(df_finetuning)\n",
    "\n",
    "print(f\"\\n✅ Advanced dataset transformation complete!\")\n",
    "print(f\"   Rows processed: {rows_seen}\")\n",
    "print(f\"   Rows kept: {rows_kept}\")\n",
    "print(f\"   Rows skipped: {rows_skipped}\")\n",
    "print(f\"   Final dataset size: {len(hf_finetuning_dataset)} samples\")\n",
    "\n",
    "if not df_finetuning.empty:\n",
    "    print(\"\\nSample entry:\")\n",
    "    display(df_finetuning.head(1))\n",
    "    print(\"Instruction:\", df_finetuning.iloc[0]['instruction'][:200] + \"...\")\n",
    "    print(\"Input:\", df_finetuning.iloc[0]['input'][:300] + \"...\")\n",
    "    print(\"Output:\", df_finetuning.iloc[0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aad5abaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving enhanced dataset to Hugging Face Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89898d6bcbfc442cb670731b2b649d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f45216b94e7494ba45414581889f002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb41db6da9534ae69f18df93779b8887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de006022d04d46e7bb1da7aad8a46600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66dc162ae23458f98b42ac7e58dc458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        :   1%|          | 16.7kB / 1.86MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset successfully uploaded!\n",
      "🔗 View at: https://huggingface.co/datasets/tahamajs/bitcoin-prediction-dataset-with-local-news-summaries\n",
      "📊 Total samples: 2303\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Save Enhanced Dataset to Hugging Face Hub ---\n",
    "if not df_finetuning.empty:\n",
    "    print(\"Saving enhanced dataset to Hugging Face Hub...\")\n",
    "    \n",
    "    # Define repository name\n",
    "    repo_id = \"tahamajs/bitcoin-prediction-dataset-with-local-news-summaries\"\n",
    "    \n",
    "    try:\n",
    "        # Push to Hugging Face Hub\n",
    "        hf_finetuning_dataset.push_to_hub(\n",
    "            repo_id,\n",
    "            commit_message=\"Bitcoin prediction dataset with local news summaries and technical indicators (no external dependencies)\"\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Dataset successfully uploaded!\")\n",
    "        print(f\"🔗 View at: https://huggingface.co/datasets/{repo_id}\")\n",
    "        print(f\"📊 Total samples: {len(hf_finetuning_dataset)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error uploading to Hugging Face: {e}\")\n",
    "        print(\"💡 Make sure you're logged in with a valid token.\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No data to save - dataset is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "699103c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE SAMPLE FROM THE BITCOIN PREDICTION DATASET\n",
      "================================================================================\n",
      "\n",
      "🎯 INSTRUCTION:\n",
      "--------------------------------------------------\n",
      "You are an expert quantitative crypto analyst. Your tasks:\n",
      "1) Analyze the context and decide an actionable stance for BTC-USD: BUY, SELL, or HOLD.\n",
      "2) Forecast the NEXT 10 daily CLOSING prices (USD).\n",
      "\n",
      "CONTEXT DATE: 2018-01-31\n",
      "\n",
      "ANALYSIS FRAMEWORK:\n",
      "• Technical Analysis: Use price trends, volatility, and momentum indicators\n",
      "• Macro Analysis: Consider gold/oil prices for broader market context\n",
      "• News Analysis: Integrate comprehensive daily news summaries for market catalysts\n",
      "\n",
      "OUTPUT FORMAT (JSON ONLY):\n",
      "Return a single JSON object with EXACTLY these keys:\n",
      "{\"action\":\"BUY|SELL|HOLD\",\"confidence\":<int 1-99>,\"stop_loss\":<price 2dp>,\"take_profit\":<price 2dp>,\"forecast_10d\":[<10 prices 2dp>]}\n",
      "No extra text, no explanations, just the JSON.\n",
      "\n",
      "📊 INPUT:\n",
      "--------------------------------------------------\n",
      "Daily Context — 2018-01-31\n",
      "\n",
      "[Technical Price Analysis]\n",
      "- Current Price: $10,106.30\n",
      "- 60-Day Range: $10,106.30 → $17,527.00\n",
      "- 1D Return: -10.54%\n",
      "- 7D Return: -7.01%\n",
      "- 30D Return: N/A%\n",
      "- Volatility (14d): 5.76%\n",
      "- Avg Daily Change (14d): 501.23\n",
      "- Drawdown from Max: -42.34%\n",
      "\n",
      "[Price History (Last 60 Days USD)]\n",
      "[13657.20, 14982.10, 15201.00, 15599.20, 17429.50, 17527.00, 16477.60, 15170.10, 14595.40, 14973.30, 13405.80, 13980.60, 14360.20, 13772.00, 13819.80, 11490.50, 11188.60, 11474.90, 11607.40, 12899.20, 11600.10, 10931.40, 10868.40, 11359.40, 11259.40, 11171.40, 11440.70, 11786.30, 11296.40, 10106.30]\n",
      "\n",
      "[Macro & Commodities Context]\n",
      "- Gold Price: $1,339.00\n",
      "- Crude Oil Price: $64.73\n",
      "\n",
      "[Market Context]\n",
      "- Bitcoin dominates crypto market as leading digital asset\n",
      "- Price influenced by adoption, regulation, and macro factors\n",
      "\n",
      "[Comprehensive News Analysis]\n",
      "Summary: The crypto market on January 31, 2018, was characterized by continued volatility and regulatory concerns. Facebook's announcement to ban crypto ads was a significant bearish signal, restricting marketing channels. While South Korea's finance minister clarified no ban was planned, the uncovering of illegal trades signaled ongoing regulatory scrutiny. Bitcoin remained below $10,000, indicating persistent bearish momentum, further pressured by news of the Bitfinex subpoena by the CFTC and the Coincheck hack aftermath. Despite some short-term price recoveries, the overall sentiment remained cautious due to these headwinds.\n",
      "\n",
      "Sentiment: neutral\n",
      "Market Impact: unknown\n",
      "\n",
      "Key Events: No key events\n",
      "\n",
      "Price Drivers: No specific drivers\n",
      "\n",
      "Risk Factors: No major risks\n",
      "\n",
      "Opportunities: No specific opportunities\n",
      "\n",
      "Short-term News: [{'pick_idx': 5, 'id': 'nc285bbcb1a6b', 'title': 'Bitcoin and Ethereum Price Forecast – Facebook Bans Cryptocurrency and ICO ads', 'url': 'https://finance.yahoo.com/news/bitcoin-ethereum-price-forecas...\n",
      "\n",
      "Long-term News: [{'pick_idx': 11, 'id': 'n4d25fd07511b', 'title': 'Bitcoin Futures Just Hit Wall Street, and the Price is Surging', 'url': 'https://finance.yahoo.com/news/bitcoin-futures-just-hit-wall-165600537.html'...\n",
      "\n",
      "Based on this comprehensive multi-dimensional analysis incorporating technical indicators, fundamentals, sentiment, and detailed news analysis, provide your trading decision and 10-day price forecast in the specified JSON format.\n",
      "\n",
      "🎲 OUTPUT:\n",
      "--------------------------------------------------\n",
      "{\"action\":\"SELL\",\"confidence\":95,\"stop_loss\":9103.84,\"take_profit\":11108.76,\"forecast_10d\":[9170.54, 8830.75, 9174.91, 8277.01, 6955.27, 7754.00, 7621.30, 8265.59, 8736.98, 8621.90]}\n",
      "\n",
      "================================================================================\n",
      "This is sample 1 of 2303 total samples in the dataset\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Print One Complete Sample ---\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE SAMPLE FROM THE BITCOIN PREDICTION DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not df_finetuning.empty:\n",
    "    # Get the first sample\n",
    "    sample = df_finetuning.iloc[0]\n",
    "    \n",
    "    print(\"\\n🎯 INSTRUCTION:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(sample['instruction'])\n",
    "    \n",
    "    print(\"\\n📊 INPUT:\")\n",
    "    print(\"-\" * 50) \n",
    "    print(sample['input'])\n",
    "    \n",
    "    print(\"\\n🎲 OUTPUT:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(sample['output'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"This is sample 1 of {len(df_finetuning)} total samples in the dataset\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"❌ No data available in df_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c4f76944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONDENSED SAMPLE FROM BITCOIN PREDICTION DATASET\n",
      "================================================================================\n",
      "\n",
      "🎯 INSTRUCTION (First 300 characters):\n",
      "--------------------------------------------------\n",
      "You are an expert quantitative crypto analyst. Your tasks:\n",
      "1) Analyze the context and decide an actionable stance for BTC-USD: BUY, SELL, or HOLD.\n",
      "2) Forecast the NEXT 10 daily CLOSING prices (USD).\n",
      "\n",
      "CONTEXT DATE: 2018-01-31\n",
      "\n",
      "ANALYSIS FRAMEWORK:\n",
      "• Technical Analysis: Use price trends, volatility, and momentum indicators\n",
      "• Macro Analysis: Consider gold/oil prices for broader market context\n",
      "• News Analysis: Integrate comprehensive daily news summaries for market catalysts\n",
      "\n",
      "OUTPUT FORMAT (JSON ONLY):\n",
      "Return a single JSON object with EXACTLY these keys:\n",
      "{\"action\":\"BUY|SELL|HOLD\",\"confidence\":<int 1-99>,\"stop_loss\":<price 2dp>,\"take_profit\":<price 2dp>,\"forecast_10d\":[<10 prices 2dp>]}\n",
      "No extra text, no explanations, just the JSON....\n",
      "\n",
      "📊 INPUT SECTIONS:\n",
      "--------------------------------------------------\n",
      "\n",
      "[Technical Price Analysis]\n",
      "  - Current Price: $10,106.30\n",
      "  - 60-Day Range: $10,106.30 → $17,527.00\n",
      "\n",
      "[Price History (Last 60 Days USD)]\n",
      "\n",
      "[13657.20, 14982.10, 15201.00, 15599.20, 17429.50, 17527.00, 16477.60, 15170.10, 14595.40, 14973.30, 13405.80, 13980.60, 14360.20, 13772.00, 13819.80, 11490.50, 11188.60, 11474.90, 11607.40, 12899.20, 11600.10, 10931.40, 10868.40, 11359.40, 11259.40, 11171.40, 11440.70, 11786.30, 11296.40, 10106.30]\n",
      "\n",
      "[Macro & Commodities Context]\n",
      "\n",
      "[Market Context]\n",
      "\n",
      "[Comprehensive News Analysis]\n",
      "\n",
      "🎲 OUTPUT:\n",
      "--------------------------------------------------\n",
      "{\"action\":\"SELL\",\"confidence\":95,\"stop_loss\":9103.84,\"take_profit\":11108.76,\"forecast_10d\":[9170.54, 8830.75, 9174.91, 8277.01, 6955.27, 7754.00, 7621.30, 8265.59, 8736.98, 8621.90]}\n",
      "\n",
      "📈 DATASET STATS:\n",
      "--------------------------------------------------\n",
      "• Total samples: 2303\n",
      "• Avg instruction length: 736 chars\n",
      "• Avg input length: 2507 chars\n",
      "• Avg output length: 188 chars\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Print Condensed Sample with Key Sections ---\n",
    "print(\"=\"*80)\n",
    "print(\"CONDENSED SAMPLE FROM BITCOIN PREDICTION DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not df_finetuning.empty:\n",
    "    sample = df_finetuning.iloc[0]\n",
    "    \n",
    "    print(\"\\n🎯 INSTRUCTION (First 300 characters):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(sample['instruction'] + \"...\")\n",
    "    \n",
    "    print(f\"\\n📊 INPUT SECTIONS:\")\n",
    "    print(\"-\" * 50)\n",
    "    input_lines = sample['input'].split('\\n')\n",
    "    \n",
    "    # Show key sections\n",
    "    current_section = \"\"\n",
    "    for line in input_lines:\n",
    "        if line.startswith('[') and line.endswith(']'):\n",
    "            current_section = line\n",
    "            print(f\"\\n{current_section}\")\n",
    "            continue\n",
    "        elif line.strip() and current_section:\n",
    "            # Show first few lines of each section\n",
    "            if current_section == \"[Technical Price Analysis]\":\n",
    "                if line.startswith('- Current Price:') or line.startswith('- 60-Day Range:'):\n",
    "                    print(f\"  {line}\")\n",
    "            elif current_section == \"[Price History (Last 60 Days USD)]\":\n",
    "                if line.startswith('['):\n",
    "                    prices = line[1:-1].split(', ')\n",
    "                    print(f\"  [First 5 prices: {', '.join(prices[:5])}, ... Last 5: {', '.join(prices[-5:])}]\")\n",
    "            elif current_section == \"[On-Chain & Market Fundamentals]\":\n",
    "                if line.startswith('- Market Cap:') or line.startswith('- Hash Rate:'):\n",
    "                    print(f\"  {line}\")\n",
    "            elif current_section == \"[News Summary]\":\n",
    "                print(f\"  {line[:100]}{'...' if len(line) > 100 else ''}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n🎲 OUTPUT:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(sample['output'])\n",
    "    \n",
    "    print(f\"\\n📈 DATASET STATS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"• Total samples: {len(df_finetuning)}\")\n",
    "    print(f\"• Avg instruction length: {df_finetuning['instruction'].str.len().mean():.0f} chars\")\n",
    "    print(f\"• Avg input length: {df_finetuning['input'].str.len().mean():.0f} chars\") \n",
    "    print(f\"• Avg output length: {df_finetuning['output'].str.len().mean():.0f} chars\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(\"❌ No data available in df_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14bc8352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NEWS SUMMARY COVERAGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📰 SUMMARY STATISTICS:\n",
      "--------------------------------------------------\n",
      "• Total news summary files found: 2437\n",
      "• Total summaries loaded into df_summaries: 2437\n",
      "• Summary date range: 2018-01-01 00:00:00+00:00 to 2024-12-31 00:00:00+00:00\n",
      "\n",
      "• Total samples in final dataset: 2303\n",
      "• Final dataset date range: 2018-01-31 to 2024-05-21\n",
      "\n",
      "📊 NEWS COVERAGE IN FINAL DATASET:\n",
      "--------------------------------------------------\n",
      "• Samples with actual news summaries: 2193\n",
      "• Samples with default 'No news summary available': 110\n",
      "• Samples with completely missing news: 0\n",
      "• News coverage percentage: 95.2%\n",
      "\n",
      "📅 SAMPLE DATES WITH NEWS:\n",
      "--------------------------------------------------\n",
      "  ✅ 2018-01-31\n",
      "  ✅ 2018-02-01\n",
      "  ✅ 2018-02-02\n",
      "  ✅ 2018-02-03\n",
      "  ✅ 2018-02-04\n",
      "\n",
      "📅 SAMPLE DATES WITHOUT NEWS:\n",
      "--------------------------------------------------\n",
      "  ❌ 2018-02-12\n",
      "  ❌ 2018-02-28\n",
      "  ❌ 2018-03-01\n",
      "  ❌ 2018-03-10\n",
      "  ❌ 2018-03-11\n",
      "\n",
      "🔍 MISSING NEWS PATTERN ANALYSIS:\n",
      "--------------------------------------------------\n",
      "• Earliest missing date: 2018-02-12\n",
      "• Latest missing date: 2024-04-21\n",
      "• Missing dates before 2023: 92\n",
      "• Missing dates from 2023 onwards: 18\n",
      "\n",
      "================================================================================\n",
      "  ❌ 2018-02-12\n",
      "  ❌ 2018-02-28\n",
      "  ❌ 2018-03-01\n",
      "  ❌ 2018-03-10\n",
      "  ❌ 2018-03-11\n",
      "\n",
      "🔍 MISSING NEWS PATTERN ANALYSIS:\n",
      "--------------------------------------------------\n",
      "• Earliest missing date: 2018-02-12\n",
      "• Latest missing date: 2024-04-21\n",
      "• Missing dates before 2023: 92\n",
      "• Missing dates from 2023 onwards: 18\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Analyze News Summary Coverage ---\n",
    "print(\"=\"*80)\n",
    "print(\"NEWS SUMMARY COVERAGE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📰 SUMMARY STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check original summaries loaded\n",
    "print(f\"• Total news summary files found: {len(all_summary_files)}\")\n",
    "print(f\"• Total summaries loaded into df_summaries: {len(df_summaries)}\")\n",
    "print(f\"• Summary date range: {df_summaries.index.min()} to {df_summaries.index.max()}\")\n",
    "\n",
    "# Check final dataset coverage\n",
    "print(f\"\\n• Total samples in final dataset: {len(final_dataset)}\")\n",
    "print(f\"• Final dataset date range: {final_dataset['date'].min()} to {final_dataset['date'].max()}\")\n",
    "\n",
    "# Check how many samples have news summaries vs missing ones\n",
    "samples_with_news = final_dataset['news_summary'].notna().sum()\n",
    "samples_missing_news = final_dataset['news_summary'].isna().sum()\n",
    "samples_with_default_text = (final_dataset['news_summary'] == 'No news summary available.').sum()\n",
    "\n",
    "print(f\"\\n📊 NEWS COVERAGE IN FINAL DATASET:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Samples with actual news summaries: {samples_with_news - samples_with_default_text}\")\n",
    "print(f\"• Samples with default 'No news summary available': {samples_with_default_text}\")\n",
    "print(f\"• Samples with completely missing news: {samples_missing_news}\")\n",
    "print(f\"• News coverage percentage: {((samples_with_news - samples_with_default_text) / len(final_dataset) * 100):.1f}%\")\n",
    "\n",
    "# Show some sample dates that have news vs don't have news\n",
    "print(f\"\\n📅 SAMPLE DATES WITH NEWS:\")\n",
    "print(\"-\" * 50)\n",
    "dates_with_news = final_dataset[\n",
    "    (final_dataset['news_summary'].notna()) & \n",
    "    (final_dataset['news_summary'] != 'No news summary available.')\n",
    "]['date'].head(5)\n",
    "for date in dates_with_news:\n",
    "    print(f\"  ✅ {date}\")\n",
    "\n",
    "print(f\"\\n📅 SAMPLE DATES WITHOUT NEWS:\")\n",
    "print(\"-\" * 50)\n",
    "dates_without_news = final_dataset[\n",
    "    (final_dataset['news_summary'].isna()) | \n",
    "    (final_dataset['news_summary'] == 'No news summary available.')\n",
    "]['date'].head(5)\n",
    "for date in dates_without_news:\n",
    "    print(f\"  ❌ {date}\")\n",
    "\n",
    "# Check if there's a pattern in missing dates\n",
    "print(f\"\\n🔍 MISSING NEWS PATTERN ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "missing_news_df = final_dataset[\n",
    "    (final_dataset['news_summary'].isna()) | \n",
    "    (final_dataset['news_summary'] == 'No news summary available.')\n",
    "]\n",
    "\n",
    "if not missing_news_df.empty:\n",
    "    print(f\"• Earliest missing date: {missing_news_df['date'].min()}\")\n",
    "    print(f\"• Latest missing date: {missing_news_df['date'].max()}\")\n",
    "    \n",
    "    # Check if missing dates are mostly early dates (before news collection started)\n",
    "    missing_dates = pd.to_datetime(missing_news_df['date'])\n",
    "    early_missing = (missing_dates < pd.to_datetime('2023-01-01')).sum()\n",
    "    recent_missing = (missing_dates >= pd.to_datetime('2023-01-01')).sum()\n",
    "    \n",
    "    print(f\"• Missing dates before 2023: {early_missing}\")\n",
    "    print(f\"• Missing dates from 2023 onwards: {recent_missing}\")\n",
    "else:\n",
    "    print(\"• No missing news summaries found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6cb9cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PER-DATE NEWS SUMMARY COMPLETENESS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "🔍 CHECKING INDIVIDUAL DATE COVERAGE:\n",
      "--------------------------------------------------\n",
      "• Dates with available news summaries: 2437\n",
      "• Dates in final dataset: 2303\n",
      "• Dates with both news and price data: 2193\n",
      "• Dates with news but not in final dataset: 244\n",
      "• Dates in dataset but missing news: 110\n",
      "\n",
      "📊 DETAILED PER-DATE ANALYSIS:\n",
      "--------------------------------------------------\n",
      "  2018-01-31 | ✅ COMPLETE | News file exists: True | Summary length: 626\n",
      "  2018-02-01 | ✅ COMPLETE | News file exists: True | Summary length: 554\n",
      "  2018-02-02 | ✅ COMPLETE | News file exists: True | Summary length: 758\n",
      "  2018-02-03 | ✅ COMPLETE | News file exists: True | Summary length: 506\n",
      "  2018-02-04 | ✅ COMPLETE | News file exists: True | Summary length: 458\n",
      "  2018-02-05 | ✅ COMPLETE | News file exists: True | Summary length: 537\n",
      "  2018-02-06 | ✅ COMPLETE | News file exists: True | Summary length: 495\n",
      "  2018-02-07 | ✅ COMPLETE | News file exists: True | Summary length: 507\n",
      "  2018-02-08 | ✅ COMPLETE | News file exists: True | Summary length: 657\n",
      "  2018-02-09 | ✅ COMPLETE | News file exists: True | Summary length: 627\n",
      "\n",
      "🔬 SAMPLE NEWS CONTENT ANALYSIS:\n",
      "--------------------------------------------------\n",
      "Sample Date: 2021-01-03\n",
      "Original summary length: 460\n",
      "Dataset summary length: 460\n",
      "Summaries match: True\n",
      "\n",
      "Original preview: Bitcoin has continued its parabolic ascent, breaching $34,000 for the first time, driven by strong institutional interest and a narrative of digital gold. The market sentiment is overwhelmingly bullis...\n",
      "Dataset preview:  Bitcoin has continued its parabolic ascent, breaching $34,000 for the first time, driven by strong institutional interest and a narrative of digital gold. The market sentiment is overwhelmingly bullis...\n",
      "\n",
      "📈 SUMMARY (Sample of 10 dates):\n",
      "--------------------------------------------------\n",
      "• Dates with complete news: 10\n",
      "• Dates with partial news: 0\n",
      "• Dates with no news: 0\n",
      "• Complete coverage rate: 100.0%\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Analyze News Summary Completeness Per Date ---\n",
    "print(\"=\"*80)\n",
    "print(\"PER-DATE NEWS SUMMARY COMPLETENESS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n🔍 CHECKING INDIVIDUAL DATE COVERAGE:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check what news summaries are available vs what's in the final dataset\n",
    "available_news_dates = set(df_summaries.index.date)\n",
    "final_dataset_dates = set(pd.to_datetime(final_dataset['date']).dt.date)\n",
    "\n",
    "print(f\"• Dates with available news summaries: {len(available_news_dates)}\")\n",
    "print(f\"• Dates in final dataset: {len(final_dataset_dates)}\")\n",
    "\n",
    "# Find overlap and missing dates\n",
    "overlap_dates = available_news_dates.intersection(final_dataset_dates)\n",
    "news_available_but_not_used = available_news_dates - final_dataset_dates\n",
    "news_missing_for_dataset_dates = final_dataset_dates - available_news_dates\n",
    "\n",
    "print(f\"• Dates with both news and price data: {len(overlap_dates)}\")\n",
    "print(f\"• Dates with news but not in final dataset: {len(news_available_but_not_used)}\")\n",
    "print(f\"• Dates in dataset but missing news: {len(news_missing_for_dataset_dates)}\")\n",
    "\n",
    "# Detailed analysis for each date in final dataset\n",
    "print(f\"\\n📊 DETAILED PER-DATE ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "dates_with_complete_news = 0\n",
    "dates_with_partial_news = 0\n",
    "dates_with_no_news = 0\n",
    "\n",
    "# Sample some dates to check individual completeness\n",
    "sample_dates = final_dataset.head(10)  # Check first 10 dates as examples\n",
    "\n",
    "for idx, row in sample_dates.iterrows():\n",
    "    date_obj = pd.to_datetime(row['date']).date()\n",
    "    news_summary = row['news_summary']\n",
    "    \n",
    "    # Check if this date has news available in our summaries\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "    has_news_file = date_obj in available_news_dates\n",
    "    \n",
    "    if pd.isna(news_summary) or news_summary == 'No news summary available.':\n",
    "        status = \"❌ NO NEWS\"\n",
    "        dates_with_no_news += 1\n",
    "    elif has_news_file and len(news_summary) > 50:  # Assuming substantial content\n",
    "        status = \"✅ COMPLETE\"\n",
    "        dates_with_complete_news += 1\n",
    "    else:\n",
    "        status = \"⚠️  PARTIAL\"\n",
    "        dates_with_partial_news += 1\n",
    "    \n",
    "    print(f\"  {date_obj} | {status} | News file exists: {has_news_file} | Summary length: {len(str(news_summary)) if news_summary else 0}\")\n",
    "\n",
    "# Check if news summaries contain all available information for each date\n",
    "print(f\"\\n🔬 SAMPLE NEWS CONTENT ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Pick a specific date and check what's in the original file vs what's in the dataset\n",
    "if not df_summaries.empty and not final_dataset.empty:\n",
    "    # Get a date that exists in both\n",
    "    common_date = list(overlap_dates)[0] if overlap_dates else None\n",
    "    \n",
    "    if common_date:\n",
    "        # Get original summary from file\n",
    "        original_summary = df_summaries.loc[pd.to_datetime(common_date, utc=True), 'summary']\n",
    "        \n",
    "        # Get summary from final dataset\n",
    "        dataset_row = final_dataset[final_dataset['date'] == common_date]\n",
    "        if not dataset_row.empty:\n",
    "            dataset_summary = dataset_row.iloc[0]['news_summary']\n",
    "            \n",
    "            print(f\"Sample Date: {common_date}\")\n",
    "            print(f\"Original summary length: {len(str(original_summary))}\")\n",
    "            print(f\"Dataset summary length: {len(str(dataset_summary))}\")\n",
    "            print(f\"Summaries match: {str(original_summary) == str(dataset_summary)}\")\n",
    "            \n",
    "            if len(str(original_summary)) > 100:\n",
    "                print(f\"\\nOriginal preview: {str(original_summary)[:200]}...\")\n",
    "                print(f\"Dataset preview:  {str(dataset_summary)[:200]}...\")\n",
    "\n",
    "# Summary statistics\n",
    "total_checked = len(sample_dates)\n",
    "print(f\"\\n📈 SUMMARY (Sample of {total_checked} dates):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Dates with complete news: {dates_with_complete_news}\")\n",
    "print(f\"• Dates with partial news: {dates_with_partial_news}\")\n",
    "print(f\"• Dates with no news: {dates_with_no_news}\")\n",
    "\n",
    "if total_checked > 0:\n",
    "    print(f\"• Complete coverage rate: {(dates_with_complete_news/total_checked)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff9faf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED DATASET WITH COMPREHENSIVE NEWS INFORMATION\n",
      "================================================================================\n",
      "\n",
      "🎯 ENHANCED INPUT PREVIEW:\n",
      "--------------------------------------------------\n",
      "[Comprehensive News Analysis]\n",
      "Summary: The crypto market on January 31, 2018, was characterized by continued volatility and regulatory concerns. Facebook's announcement to ban crypto ads was a significant bearish signal, restricting marketing channels. While South Korea's finance minister clarified no ban was planned, the uncovering of illegal trades signaled ongoing regulatory scrutiny. Bitcoin remained below $10,000, indicating persistent bearish momentum, further pressured by news of the Bitfinex subpoena by the CFTC and the Coincheck hack aftermath. Despite some short-term price recoveries, the overall sentiment remained cautious due to these headwinds.\n",
      "\n",
      "Sentiment: neutral\n",
      "Market Impact: unknown\n",
      "\n",
      "Key Events: No key events\n",
      "\n",
      "Price Drivers: No specific drivers\n",
      "\n",
      "Risk Factors: No major risks\n",
      "\n",
      "Opportunities: No specific opportunities\n",
      "\n",
      "Short-term News: [{'pick_idx': 5, 'id': 'nc285bbcb1a6b', 'title': 'Bitcoin and Ethereum Price Forecast – Facebook Bans Cryptocurrency and ICO ads', 'url': 'https://finance.yahoo.com/news/bitcoin-ethereum-price-forecas...\n",
      "... (truncated for display)\n",
      "\n",
      "📊 DATASET ENHANCEMENTS:\n",
      "--------------------------------------------------\n",
      "• Total samples: 2303\n",
      "• Columns in raw dataset: 15\n",
      "• News-related columns: 10\n",
      "  - ['news_summary', 'daily_sentiment', 'daily_key_events', 'daily_market_impact', 'daily_price_drivers', 'daily_risk_factors', 'daily_opportunities', 'news_long_term', 'news_short_term', 'raw_news_data']\n",
      "\n",
      "🔍 SAMPLE DATA RICHNESS:\n",
      "• Has sentiment data: True\n",
      "• Has key events: []\n",
      "• Has price drivers: []\n",
      "• Has long-term news: [ True  True  True  True  True  True  True  True  True  True]\n",
      "• Has short-term news: [ True  True  True  True  True  True  True  True  True  True]\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/l2rdx46d6lv3b5xc17b420yc0000gn/T/ipykernel_74050/3320223170.py:49: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  has_events = pd.notna(sample_row.get('daily_key_events')) and str(sample_row.get('daily_key_events')) != '[]'\n",
      "/var/folders/cg/l2rdx46d6lv3b5xc17b420yc0000gn/T/ipykernel_74050/3320223170.py:50: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  has_drivers = pd.notna(sample_row.get('daily_price_drivers')) and str(sample_row.get('daily_price_drivers')) != '[]'\n"
     ]
    }
   ],
   "source": [
    "# --- Show Enhanced Dataset Sample with Comprehensive News ---\n",
    "print(\"=\"*80)\n",
    "print(\"ENHANCED DATASET WITH COMPREHENSIVE NEWS INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not df_finetuning.empty:\n",
    "    sample = df_finetuning.iloc[0]\n",
    "    \n",
    "    print(\"\\n🎯 ENHANCED INPUT PREVIEW:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Extract just the news section to see the enhancement\n",
    "    input_text = sample['input']\n",
    "    lines = input_text.split('\\n')\n",
    "    \n",
    "    # Find the news section\n",
    "    in_news_section = False\n",
    "    news_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if '[Comprehensive News Analysis]' in line:\n",
    "            in_news_section = True\n",
    "        elif in_news_section and line.startswith('[') and line.endswith(']') and 'News' not in line:\n",
    "            break  # End of news section\n",
    "        \n",
    "        if in_news_section:\n",
    "            news_lines.append(line)\n",
    "    \n",
    "    # Show the enhanced news section\n",
    "    for line in news_lines[:15]:  # Show first 15 lines\n",
    "        print(line)\n",
    "    \n",
    "    if len(news_lines) > 15:\n",
    "        print(\"... (truncated for display)\")\n",
    "    \n",
    "    print(f\"\\n📊 DATASET ENHANCEMENTS:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"• Total samples: {len(df_finetuning)}\")\n",
    "    print(f\"• Columns in raw dataset: {len(final_dataset.columns)}\")\n",
    "    \n",
    "    # Count news-related columns\n",
    "    news_cols = [col for col in final_dataset.columns if 'news' in col.lower() or 'daily' in col.lower()]\n",
    "    print(f\"• News-related columns: {len(news_cols)}\")\n",
    "    print(f\"  - {news_cols}\")\n",
    "    \n",
    "    # Check data richness\n",
    "    sample_row = final_dataset.iloc[0]\n",
    "    has_sentiment = pd.notna(sample_row.get('daily_sentiment'))\n",
    "    has_events = pd.notna(sample_row.get('daily_key_events')) and str(sample_row.get('daily_key_events')) != '[]'\n",
    "    has_drivers = pd.notna(sample_row.get('daily_price_drivers')) and str(sample_row.get('daily_price_drivers')) != '[]'\n",
    "    \n",
    "    print(f\"\\n🔍 SAMPLE DATA RICHNESS:\")\n",
    "    print(f\"• Has sentiment data: {has_sentiment}\")\n",
    "    print(f\"• Has key events: {has_events}\")\n",
    "    print(f\"• Has price drivers: {has_drivers}\")\n",
    "    print(f\"• Has long-term news: {pd.notna(sample_row.get('news_long_term'))}\")\n",
    "    print(f\"• Has short-term news: {pd.notna(sample_row.get('news_short_term'))}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(\"❌ No data available in df_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b908d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current News Section Structure:\n",
      "==================================================\n",
      "'[Comprehensive News Analysis]'\n",
      "\"Summary: The crypto market on January 31, 2018, was characterized by continued volatility and regulatory concerns. Facebook's announcement to ban crypto ads was a significant bearish signal, restricting marketing channels. While South Korea's finance minister clarified no ban was planned, the uncovering of illegal trades signaled ongoing regulatory scrutiny. Bitcoin remained below $10,000, indicating persistent bearish momentum, further pressured by news of the Bitfinex subpoena by the CFTC and the Coincheck hack aftermath. Despite some short-term price recoveries, the overall sentiment remained cautious due to these headwinds.\"\n",
      "''\n",
      "'Sentiment: neutral'\n",
      "'Market Impact: unknown'\n",
      "''\n",
      "'Key Events: No key events'\n",
      "''\n",
      "'Price Drivers: No specific drivers'\n",
      "''\n",
      "'Risk Factors: No major risks'\n",
      "''\n",
      "'Opportunities: No specific opportunities'\n",
      "''\n",
      "\"Short-term News: [{'pick_idx': 5, 'id': 'nc285bbcb1a6b', 'title': 'Bitcoin and Ethereum Price Forecast – Facebook Bans Cryptocurrency and ICO ads', 'url': 'https://finance.yahoo.com/news/bitcoin-ethereum-price-forecas...\"\n",
      "''\n",
      "\"Long-term News: [{'pick_idx': 11, 'id': 'n4d25fd07511b', 'title': 'Bitcoin Futures Just Hit Wall Street, and the Price is Surging', 'url': 'https://finance.yahoo.com/news/bitcoin-futures-just-hit-wall-165600537.html'...\"\n",
      "''\n",
      "'Based on this comprehensive multi-dimensional analysis incorporating technical indicators, fundamentals, sentiment, and detailed news analysis, provide your trading decision and 10-day price forecast in the specified JSON format.'\n"
     ]
    }
   ],
   "source": [
    "# --- Check Current News Section Structure ---\n",
    "if not df_finetuning.empty:\n",
    "    sample = df_finetuning.iloc[0]\n",
    "    input_text = sample['input']\n",
    "    \n",
    "    # Find and print the news section\n",
    "    lines = input_text.split('\\n')\n",
    "    in_news_section = False\n",
    "    news_section_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if '[Comprehensive News Analysis]' in line:\n",
    "            in_news_section = True\n",
    "        elif in_news_section and line.startswith('[') and line.endswith(']') and 'News' not in line:\n",
    "            break\n",
    "        \n",
    "        if in_news_section:\n",
    "            news_section_lines.append(line)\n",
    "    \n",
    "    print(\"Current News Section Structure:\")\n",
    "    print(\"=\"*50)\n",
    "    for line in news_section_lines:\n",
    "        print(repr(line))  # Use repr to see exact formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45146609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ENHANCED instruction-formatted dataset with comprehensive news...\n",
      "\n",
      "✅ ENHANCED dataset transformation complete!\n",
      "   Rows processed: 2303\n",
      "   Rows kept: 2303\n",
      "   Rows skipped: 0\n",
      "   Final enhanced dataset size: 2303 samples\n",
      "\n",
      "Enhanced sample preview:\n",
      "Enhanced News Section:\n",
      "  [Comprehensive News & Market Analysis]\n",
      "  \n",
      "  Daily News Summary:\n",
      "  The crypto market on January 31, 2018, was characterized by continued volatility and regulatory concerns. Facebook's announcement to ban crypto ads was a significant bearish signal, restricting marketing channels. While South Korea's finance minister clarified no ban was planned, the uncovering of illegal trades signaled ongoing regulatory scrutiny. Bitcoin remained below $10,000, indicating persistent bearish momentum, further pressured by news of the Bitfinex subpoena by the CFTC and the Coincheck hack aftermath. Despite some short-term price recoveries, the overall sentiment remained cautious due to these headwinds.\n",
      "  \n",
      "  Market Sentiment: neutral\n",
      "  Market Impact: unknown\n",
      "  \n",
      "  Short-term News Analysis:\n",
      "\n",
      "Sample input length: 25,506 chars\n",
      "Sample output: {\"action\":\"SELL\",\"confidence\":99,\"stop_loss\":10548.72,\"take_profit\":9272.00,\"forecast_10d\":[9170.54, 8830.75, 9174.91, 8277.01, 6955.27, 7754.00, 7621.30, 8265.59, 8736.98, 8621.90]}\n",
      "\n",
      "✅ ENHANCED dataset transformation complete!\n",
      "   Rows processed: 2303\n",
      "   Rows kept: 2303\n",
      "   Rows skipped: 0\n",
      "   Final enhanced dataset size: 2303 samples\n",
      "\n",
      "Enhanced sample preview:\n",
      "Enhanced News Section:\n",
      "  [Comprehensive News & Market Analysis]\n",
      "  \n",
      "  Daily News Summary:\n",
      "  The crypto market on January 31, 2018, was characterized by continued volatility and regulatory concerns. Facebook's announcement to ban crypto ads was a significant bearish signal, restricting marketing channels. While South Korea's finance minister clarified no ban was planned, the uncovering of illegal trades signaled ongoing regulatory scrutiny. Bitcoin remained below $10,000, indicating persistent bearish momentum, further pressured by news of the Bitfinex subpoena by the CFTC and the Coincheck hack aftermath. Despite some short-term price recoveries, the overall sentiment remained cautious due to these headwinds.\n",
      "  \n",
      "  Market Sentiment: neutral\n",
      "  Market Impact: unknown\n",
      "  \n",
      "  Short-term News Analysis:\n",
      "\n",
      "Sample input length: 25,506 chars\n",
      "Sample output: {\"action\":\"SELL\",\"confidence\":99,\"stop_loss\":10548.72,\"take_profit\":9272.00,\"forecast_10d\":[9170.54, 8830.75, 9174.91, 8277.01, 6955.27, 7754.00, 7621.30, 8265.59, 8736.98, 8621.90]}\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Create ENHANCED Instruction-Formatted Dataset with ALL News Info ---\n",
    "print(\"Creating ENHANCED instruction-formatted dataset with comprehensive news...\")\n",
    "\n",
    "# Helper functions (same as before)\n",
    "def _fmt_usd(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return \"N/A\"\n",
    "    try:\n",
    "        return f\"${float(x):,.2f}\"\n",
    "    except Exception:\n",
    "        return \"N/A\"\n",
    "\n",
    "def _fmt_float(x, nd=2):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return \"N/A\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return \"N/A\"\n",
    "\n",
    "def _derive_price_features(prices):\n",
    "    \"\"\"Calculate technical indicators from price history\"\"\"\n",
    "    if not isinstance(prices, (list, tuple)) or len(prices) == 0:\n",
    "        return dict(\n",
    "            last_close=np.nan, min60=np.nan, max60=np.nan,\n",
    "            ret_1d_pct=np.nan, ret_7d_pct=np.nan, ret_30d_pct=np.nan,\n",
    "            std14_pct=np.nan, avg_abs_change14=np.nan, drawdown_from_max_pct=np.nan\n",
    "        )\n",
    "    \n",
    "    arr = np.array(prices, dtype=float)\n",
    "    last_close = arr[-1]\n",
    "    min60 = float(np.min(arr))\n",
    "    max60 = float(np.max(arr))\n",
    "\n",
    "    def _pct(a, b):\n",
    "        try:\n",
    "            return (float(a) / float(b) - 1.0) * 100.0\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    ret_1d_pct  = _pct(arr[-1], arr[-2])  if arr.size >= 2  else np.nan\n",
    "    ret_7d_pct  = _pct(arr[-1], arr[-8])  if arr.size >= 8  else np.nan\n",
    "    ret_30d_pct = _pct(arr[-1], arr[-31]) if arr.size >= 31 else np.nan\n",
    "\n",
    "    if arr.size >= 15:\n",
    "        rets = np.diff(arr[-15:]) / arr[-15:-1] * 100.0\n",
    "        std14_pct = float(np.std(rets, ddof=1))\n",
    "        avg_abs_change14 = float(np.mean(np.abs(np.diff(arr[-15:]))))\n",
    "    else:\n",
    "        std14_pct = np.nan\n",
    "        avg_abs_change14 = np.nan\n",
    "\n",
    "    drawdown_from_max_pct = _pct(arr[-1], max60)\n",
    "    return dict(\n",
    "        last_close=float(last_close), min60=min60, max60=max60,\n",
    "        ret_1d_pct=float(ret_1d_pct) if not pd.isna(ret_1d_pct) else np.nan,\n",
    "        ret_7d_pct=float(ret_7d_pct) if not pd.isna(ret_7d_pct) else np.nan,\n",
    "        ret_30d_pct=float(ret_30d_pct) if not pd.isna(ret_30d_pct) else np.nan,\n",
    "        std14_pct=float(std14_pct) if not pd.isna(std14_pct) else np.nan,\n",
    "        avg_abs_change14=float(avg_abs_change14) if not pd.isna(avg_abs_change14) else np.nan,\n",
    "        drawdown_from_max_pct=float(drawdown_from_max_pct) if not pd.isna(drawdown_from_max_pct) else np.nan\n",
    "    )\n",
    "\n",
    "def _label_action(last_close, future_10, std14_pct):\n",
    "    \"\"\"Generate trading action based on volatility-aware analysis\"\"\"\n",
    "    if last_close is None or np.isnan(last_close) or future_10 is None or len(future_10) < 10:\n",
    "        return \"HOLD\", 50\n",
    "    day10 = float(future_10[-1])\n",
    "    ret10_pct = (day10 / float(last_close) - 1.0) * 100.0\n",
    "    vol_ref = float(std14_pct) if std14_pct is not None and not np.isnan(std14_pct) else 2.0\n",
    "    thr = max(1.0, 0.35 * vol_ref)\n",
    "    if ret10_pct >= thr:\n",
    "        action = \"BUY\"\n",
    "    elif ret10_pct <= -thr:\n",
    "        action = \"SELL\"\n",
    "    else:\n",
    "        action = \"HOLD\"\n",
    "    conf = min(99, max(1, int(50 + 15 * abs(ret10_pct) / max(1, thr))))\n",
    "    return action, conf\n",
    "\n",
    "def _stop_take(action, last_close, std14_pct):\n",
    "    \"\"\"Calculate stop loss and take profit based on volatility\"\"\"\n",
    "    if std14_pct is None or np.isnan(std14_pct):\n",
    "        std14_pct = 2.0\n",
    "    vol_ref = float(std14_pct)\n",
    "    if action == \"BUY\":\n",
    "        sl = last_close * (1 - 0.015 - 0.005 * vol_ref)\n",
    "        tp = last_close * (1 + 0.025 + 0.01 * vol_ref)\n",
    "    elif action == \"SELL\":\n",
    "        sl = last_close * (1 + 0.015 + 0.005 * vol_ref)\n",
    "        tp = last_close * (1 - 0.025 - 0.01 * vol_ref)\n",
    "    else:  # HOLD\n",
    "        sl = last_close * 0.95\n",
    "        tp = last_close * 1.05\n",
    "    return float(sl), float(tp)\n",
    "\n",
    "# Create enhanced dataset with complete news information\n",
    "enhanced_finetuning_data = []\n",
    "rows_seen = 0\n",
    "rows_kept = 0\n",
    "rows_skipped = 0\n",
    "\n",
    "for idx, row in final_dataset.iterrows():\n",
    "    rows_seen += 1\n",
    "    \n",
    "    # Calculate price features\n",
    "    hist_prices = eval(row['btc_price_history_60d']) if isinstance(row['btc_price_history_60d'], str) else row['btc_price_history_60d']\n",
    "    future_prices = eval(row['btc_price_target_10d']) if isinstance(row['btc_price_target_10d'], str) else row['btc_price_target_10d']\n",
    "    \n",
    "    feats = _derive_price_features(hist_prices)\n",
    "    current_price = _fmt_usd(feats['last_close'])\n",
    "    \n",
    "    # Generate trading signals\n",
    "    action, confidence = _label_action(feats['last_close'], future_prices, feats['std14_pct'])\n",
    "    sl, tp = _stop_take(action, feats['last_close'], feats['std14_pct'])\n",
    "    \n",
    "    # Format price history\n",
    "    price_history_str = \", \".join([f\"{p:.2f}\" for p in hist_prices[-10:]])  # Show last 10 days\n",
    "    \n",
    "    # Format commodity data\n",
    "    gold_price = _fmt_usd(row.get('gold_price', np.nan))\n",
    "    oil_price = _fmt_usd(row.get('oil_price', np.nan))\n",
    "    \n",
    "    # Enhanced Instruction\n",
    "    instruction = (\n",
    "        f\"CONTEXT DATE: {row['date']}\\n\\n\"\n",
    "        \"ANALYSIS FRAMEWORK:\\n\"\n",
    "        \"• Technical Analysis: Use price trends, volatility, and momentum indicators\\n\"\n",
    "        \"• Macro Analysis: Consider gold/oil prices for broader market context\\n\"\n",
    "        \"• News Analysis: Integrate comprehensive daily news summaries for market catalysts\\n\\n\"\n",
    "        \"OUTPUT FORMAT (JSON ONLY):\\n\"\n",
    "        \"Return a single JSON object with EXACTLY these keys:\\n\"\n",
    "        \"{\\\"action\\\":\\\"BUY|SELL|HOLD\\\",\\\"confidence\\\":<int 1-99>,\"\n",
    "        \"\\\"stop_loss\\\":<price 2dp>,\\\"take_profit\\\":<price 2dp>,\"\n",
    "        \"\\\"forecast_10d\\\":[<10 prices 2dp>]}\\n\"\n",
    "        \"No extra text, no explanations, just the JSON.\"\n",
    "    )\n",
    "\n",
    "    # Check if there's meaningful news data\n",
    "    has_real_news = (\n",
    "        (row.get('news_summary') and \n",
    "         row.get('news_summary') not in ['No news summary available.', '']) or\n",
    "        (row.get('daily_sentiment') and \n",
    "         row.get('daily_sentiment') not in ['neutral', 'No sentiment data available.', '']) or\n",
    "        (row.get('daily_market_impact') and \n",
    "         row.get('daily_market_impact') not in ['unknown', 'No market impact assessment available.', '']) or\n",
    "        (row.get('daily_key_events') and \n",
    "         len(row.get('daily_key_events', [])) > 0) or\n",
    "        (row.get('daily_price_drivers') and \n",
    "         len(row.get('daily_price_drivers', [])) > 0) or\n",
    "        (row.get('daily_risk_factors') and \n",
    "         len(row.get('daily_risk_factors', [])) > 0) or\n",
    "        (row.get('daily_opportunities') and \n",
    "         len(row.get('daily_opportunities', [])) > 0) or\n",
    "        (row.get('news_short_term') and \n",
    "         row.get('news_short_term') not in ['No short-term news available.', '']) or\n",
    "        (row.get('news_long_term') and \n",
    "         row.get('news_long_term') not in ['No long-term news available.', ''])\n",
    "    )\n",
    "    \n",
    "    # Build news section only if there's real data\n",
    "    news_section = \"\"\n",
    "    if has_real_news:\n",
    "        news_section = f\"\"\"\n",
    "\n",
    "[Comprehensive News & Market Analysis]\n",
    "\n",
    "Daily News Summary:\n",
    "{row.get('news_summary', 'No news summary available.')}\n",
    "\n",
    "Market Sentiment: {row.get('daily_sentiment', 'No sentiment data available.')}\n",
    "Market Impact: {row.get('daily_market_impact', 'No market impact assessment available.')}\n",
    "\n",
    "Short-term News Analysis:\n",
    "{str(row.get('news_short_term', 'No short-term news available.'))}\n",
    "\n",
    "Long-term News Analysis:\n",
    "{str(row.get('news_long_term', 'No long-term news available.'))}\n",
    "\"\"\"\n",
    "\n",
    "    # ENHANCED INPUT with conditional comprehensive news\n",
    "    input_text = f\"\"\"\n",
    "Daily Context — {row['date']}\n",
    "\n",
    "[Technical Price Analysis]\n",
    "- Current Price: {_fmt_usd(feats['last_close'])}\n",
    "- 60-Day Range: {_fmt_usd(feats['min60'])} → {_fmt_usd(feats['max60'])}\n",
    "- 1D Return: {_fmt_float(feats['ret_1d_pct'])}%\n",
    "- 7D Return: {_fmt_float(feats['ret_7d_pct'])}%\n",
    "- 30D Return: {_fmt_float(feats['ret_30d_pct'])}%\n",
    "- Volatility (14d): {_fmt_float(feats['std14_pct'])}%\n",
    "- Avg Daily Change (14d): {_fmt_float(feats['avg_abs_change14'])}\n",
    "- Drawdown from Max: {_fmt_float(feats['drawdown_from_max_pct'])}%\n",
    "\n",
    "[Price History (Last 60 Days USD)]\n",
    "[{price_history_str}]\n",
    "\n",
    "[Macro & Commodities Context]\n",
    "- Gold Price: {gold_price}\n",
    "- Crude Oil Price: {oil_price}\n",
    "\n",
    "[Market Context]\n",
    "- Bitcoin dominates crypto market as leading digital asset\n",
    "- Price influenced by adoption, regulation, and macro factors{news_section}\n",
    "\n",
    "Based on this comprehensive multi-dimensional analysis incorporating technical indicators, fundamentals, sentiment, and detailed news analysis, provide your trading decision and 10-day price forecast in the specified JSON format.\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Enhanced Output\n",
    "    forecast_str = \", \".join([f\"{p:.2f}\" for p in row['btc_price_target_10d'][:10]])\n",
    "    output_text = (\n",
    "        '{'\n",
    "        f'\"action\":\"{action}\",'\n",
    "        f'\"confidence\":{confidence},'\n",
    "        f'\"stop_loss\":{sl:.2f},'\n",
    "        f'\"take_profit\":{tp:.2f},'\n",
    "        f'\"forecast_10d\":[{forecast_str}]'\n",
    "        '}'\n",
    "    )\n",
    "\n",
    "    enhanced_finetuning_data.append({\n",
    "        'instruction': instruction.strip(),\n",
    "        'input': input_text,\n",
    "        'output': output_text\n",
    "    })\n",
    "    rows_kept += 1\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "df_enhanced_finetuning = pd.DataFrame(enhanced_finetuning_data)\n",
    "hf_enhanced_dataset = Dataset.from_pandas(df_enhanced_finetuning)\n",
    "\n",
    "print(f\"\\n✅ ENHANCED dataset transformation complete!\")\n",
    "print(f\"   Rows processed: {rows_seen}\")\n",
    "print(f\"   Rows kept: {rows_kept}\")\n",
    "print(f\"   Rows skipped: {rows_skipped}\")\n",
    "print(f\"   Final enhanced dataset size: {len(hf_enhanced_dataset)} samples\")\n",
    "\n",
    "if not df_enhanced_finetuning.empty:\n",
    "    print(\"\\nEnhanced sample preview:\")\n",
    "    sample_input = df_enhanced_finetuning.iloc[0]['input']\n",
    "    \n",
    "    # Show just the news section\n",
    "    lines = sample_input.split('\\n')\n",
    "    news_start = False\n",
    "    news_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if '[Comprehensive News & Market Analysis]' in line:\n",
    "            news_start = True\n",
    "        elif news_start and line.startswith('[') and ']' in line:\n",
    "            break\n",
    "        if news_start:\n",
    "            news_lines.append(line)\n",
    "    \n",
    "    if news_lines:\n",
    "        print(\"Enhanced News Section:\")\n",
    "        for line in news_lines[:15]:  # Show first 15 lines\n",
    "            print(f\"  {line}\")\n",
    "        if len(news_lines) > 15:\n",
    "            print(f\"  ... ({len(news_lines)-15} more lines)\")\n",
    "    else:\n",
    "        print(\"No news section (only technical analysis)\")\n",
    "        \n",
    "    print(f\"\\nSample input length: {len(sample_input):,} chars\")\n",
    "    print(f\"Sample output: {df_enhanced_finetuning.iloc[0]['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07597e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Examining news data patterns...\n",
      "\n",
      "📊 NEWS DATA ANALYSIS:\n",
      "Date: 2018-01-31 | Real News: False | Summary: 626 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2018-05-11 | Real News: False | Summary: 529 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2019-06-15 | Real News: False | Summary: 633 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2020-10-27 | Real News: False | Summary: 462 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2022-03-11 | Real News: False | Summary: 545 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2023-07-24 | Real News: False | Summary: 606 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "Date: 2024-05-19 | Real News: False | Summary: 461 chars | Sentiment: neutral | Impact: unknown | Events: 0 | Drivers: 0\n",
      "\n",
      "📈 SUMMARY: 0/7 samples have COMPLETE real news data\n",
      "📉 Samples with PLACEHOLDER data: 7/7\n",
      "🎭 Rows with CLASSIC placeholder pattern (neutral + unknown + no events/drivers): 2193/2303\n"
     ]
    }
   ],
   "source": [
    "# --- DEBUG: Check news data patterns ---\n",
    "print(\"🔍 Examining news data patterns...\")\n",
    "\n",
    "# Sample a few rows to see various news patterns\n",
    "sample_indices = [0, 100, 500, 1000, 1500, 2000, 2300]\n",
    "news_patterns = []\n",
    "\n",
    "for i in sample_indices:\n",
    "    if i < len(final_dataset):\n",
    "        row = final_dataset.iloc[i]\n",
    "        \n",
    "        # Check each news field\n",
    "        news_summary = row.get('news_summary', '')\n",
    "        daily_sentiment = row.get('daily_sentiment', '')\n",
    "        daily_market_impact = row.get('daily_market_impact', '')\n",
    "        daily_key_events = row.get('daily_key_events', [])\n",
    "        daily_price_drivers = row.get('daily_price_drivers', [])\n",
    "        \n",
    "        # Determine if this has real news\n",
    "        has_real_news = (\n",
    "            (news_summary and news_summary not in ['No news summary available.', '']) and\n",
    "            (daily_sentiment and daily_sentiment not in ['neutral', 'No sentiment data available.', '']) and\n",
    "            (daily_market_impact and daily_market_impact not in ['unknown', 'No market impact assessment available.', '']) and\n",
    "            (daily_key_events and len(daily_key_events) > 0) and\n",
    "            (daily_price_drivers and len(daily_price_drivers) > 0)\n",
    "        )\n",
    "        \n",
    "        pattern = {\n",
    "            'date': row['date'],\n",
    "            'has_real_news': has_real_news,\n",
    "            'summary_length': len(str(news_summary)),\n",
    "            'sentiment': daily_sentiment,\n",
    "            'impact': daily_market_impact,\n",
    "            'events_count': len(daily_key_events) if daily_key_events else 0,\n",
    "            'drivers_count': len(daily_price_drivers) if daily_price_drivers else 0\n",
    "        }\n",
    "        news_patterns.append(pattern)\n",
    "\n",
    "print(\"\\n📊 NEWS DATA ANALYSIS:\")\n",
    "for pattern in news_patterns:\n",
    "    print(f\"Date: {pattern['date']} | Real News: {pattern['has_real_news']} | \"\n",
    "          f\"Summary: {pattern['summary_length']} chars | \"\n",
    "          f\"Sentiment: {pattern['sentiment']} | \"\n",
    "          f\"Impact: {pattern['impact']} | \"\n",
    "          f\"Events: {pattern['events_count']} | \"\n",
    "          f\"Drivers: {pattern['drivers_count']}\")\n",
    "\n",
    "# Count overall patterns\n",
    "total_with_real_news = sum(1 for p in news_patterns if p['has_real_news'])\n",
    "print(f\"\\n📈 SUMMARY: {total_with_real_news}/{len(news_patterns)} samples have COMPLETE real news data\")\n",
    "print(f\"📉 Samples with PLACEHOLDER data: {len(news_patterns) - total_with_real_news}/{len(news_patterns)}\")\n",
    "\n",
    "# Check specific placeholder patterns\n",
    "placeholder_count = 0\n",
    "for idx, row in final_dataset.iterrows():\n",
    "    if (row.get('daily_sentiment') == 'neutral' and\n",
    "        row.get('daily_market_impact') == 'unknown' and\n",
    "        not row.get('daily_key_events') and\n",
    "        not row.get('daily_price_drivers')):\n",
    "        placeholder_count += 1\n",
    "\n",
    "print(f\"🎭 Rows with CLASSIC placeholder pattern (neutral + unknown + no events/drivers): {placeholder_count}/{len(final_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "317244e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ENHANCED dataset with comprehensive news to Hugging Face Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8693630db0824b0e9397b69c4eb9f8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17251f0e422448cca1709ff1895479dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f184277181464e078dfcc37841ea371e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f38cc10ffd34e64b547a6bdb7364485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbb454db0014ae29a31c9713837c139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        :   2%|2         |  526kB / 22.8MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced dataset successfully uploaded!\n",
      "🔗 View at: https://huggingface.co/datasets/tahamajs/bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news\n",
      "📊 Total samples: 2303\n",
      "\n",
      "📈 Enhancement Summary:\n",
      "   Previous dataset: 2303 samples\n",
      "   Enhanced dataset: 2303 samples\n",
      "   Avg input length improvement: 814.3%\n",
      "   Previous avg: 2507 chars\n",
      "   Enhanced avg: 22925 chars\n",
      "   Avg input length improvement: 814.3%\n",
      "   Previous avg: 2507 chars\n",
      "   Enhanced avg: 22925 chars\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Save ENHANCED Dataset to Hugging Face Hub ---\n",
    "if not df_enhanced_finetuning.empty:\n",
    "    print(\"Saving ENHANCED dataset with comprehensive news to Hugging Face Hub...\")\n",
    "    \n",
    "    # Define repository name for enhanced dataset\n",
    "    repo_id = \"tahamajs/bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news\"\n",
    "    \n",
    "    try:\n",
    "        # Push to Hugging Face Hub\n",
    "        hf_enhanced_dataset.push_to_hub(\n",
    "            repo_id,\n",
    "            commit_message=\"Enhanced Bitcoin prediction dataset with comprehensive local news summaries, short-term and long-term analysis, and technical indicators (no external dependencies)\"\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Enhanced dataset successfully uploaded!\")\n",
    "        print(f\"🔗 View at: https://huggingface.co/datasets/{repo_id}\")\n",
    "        print(f\"📊 Total samples: {len(hf_enhanced_dataset)}\")\n",
    "        \n",
    "        # Compare with previous dataset\n",
    "        if 'df_finetuning' in locals():\n",
    "            print(f\"\\n📈 Enhancement Summary:\")\n",
    "            print(f\"   Previous dataset: {len(df_finetuning)} samples\")\n",
    "            print(f\"   Enhanced dataset: {len(df_enhanced_finetuning)} samples\")\n",
    "            \n",
    "            # Check input length improvement\n",
    "            prev_avg_len = df_finetuning['input'].str.len().mean()\n",
    "            enhanced_avg_len = df_enhanced_finetuning['input'].str.len().mean()\n",
    "            improvement = ((enhanced_avg_len - prev_avg_len) / prev_avg_len) * 100\n",
    "            \n",
    "            print(f\"   Avg input length improvement: {improvement:.1f}%\")\n",
    "            print(f\"   Previous avg: {prev_avg_len:.0f} chars\")\n",
    "            print(f\"   Enhanced avg: {enhanced_avg_len:.0f} chars\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error uploading enhanced dataset to Hugging Face: {e}\")\n",
    "        print(\"💡 Make sure you're logged in with a valid token.\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No enhanced data to save - dataset is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8f28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

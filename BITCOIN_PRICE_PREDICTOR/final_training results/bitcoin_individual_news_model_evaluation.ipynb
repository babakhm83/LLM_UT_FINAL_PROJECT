{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a084b248",
   "metadata": {},
   "source": [
    "# Bitcoin Individual News Model Evaluation\n",
    "This notebook evaluates the Bitcoin prediction model trained on the individual news dataset with longer training parameters and provides comprehensive analysis with base model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e733fdd",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries for GRPO training\n",
    "!pip install trl==0.7.6 transformers>=4.38.0 datasets accelerate bitsandbytes\n",
    "!pip install wandb torch>=2.0.0 peft>=0.8.0 scipy evaluate\n",
    "!pip install deepspeed\n",
    "\n",
    "# Additional libraries for data processing and visualization\n",
    "!pip install pandas matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84051bc4",
   "metadata": {},
   "source": [
    "## Troubleshooting: Environment Setup\n",
    "\n",
    "If you encounter the error `operator torchvision::nms does not exist`, this is due to version incompatibility between PyTorch, torchvision, and transformers. The installation cell above installs compatible versions.\n",
    "\n",
    "**Alternative solutions if the error persists:**\n",
    "\n",
    "1. **Create a fresh environment:**\n",
    "   ```bash\n",
    "   conda create -n bitcoin_eval python=3.10\n",
    "   conda activate bitcoin_eval\n",
    "   ```\n",
    "\n",
    "2. **Install in specific order:**\n",
    "   ```bash\n",
    "   pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0\n",
    "   pip install transformers==4.35.0\n",
    "   pip install datasets peft accelerate\n",
    "   ```\n",
    "\n",
    "3. **If using CPU only:**\n",
    "   ```bash\n",
    "   pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "   ```\n",
    "\n",
    "**Note:** After installation, restart your kernel before proceeding to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation and check for compatibility issues\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"PyTorch import error: {e}\")\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Torchvision import error: {e}\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Transformers import error: {e}\")\n",
    "\n",
    "try:\n",
    "    import peft\n",
    "    print(f\"PEFT version: {peft.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"PEFT import error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ If all versions are displayed above without errors, you can proceed to the next cell.\")\n",
    "print(\"‚ùå If you see import errors, please restart your kernel and re-run the installation cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859472b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix torchvision::nms operator compatibility issue\n",
    "print(\"üîß Applying torchvision compatibility fixes...\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Method 1: Set environment variables to prevent torchvision conflicts\n",
    "os.environ['TORCHVISION_DISABLE_VIDEO_BACKEND'] = '1'\n",
    "os.environ['TORCH_DISABLE_JIT_COMPILATION'] = '1'\n",
    "\n",
    "# Method 2: Import torch first and configure it\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    # Disable JIT compilation which can cause operator registration issues\n",
    "    torch.jit.set_fusion_strategy([('STATIC', 20), ('DYNAMIC', 20)])\n",
    "    \n",
    "    # Set torch to use CPU for meta operations if GPU causes issues\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "    print(\"‚úÖ Torch configured successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error configuring torch: {e}\")\n",
    "\n",
    "# Method 3: Import torchvision with fallback\n",
    "try:\n",
    "    # Try importing torchvision operations that might conflict\n",
    "    import torchvision\n",
    "    \n",
    "    # Disable problematic torchvision operations\n",
    "    if hasattr(torchvision, 'ops'):\n",
    "        # Patch torchvision.ops.nms if it exists\n",
    "        original_nms = getattr(torchvision.ops, 'nms', None)\n",
    "        if original_nms:\n",
    "            def safe_nms(*args, **kwargs):\n",
    "                try:\n",
    "                    return original_nms(*args, **kwargs)\n",
    "                except Exception:\n",
    "                    # Return empty tensor as fallback\n",
    "                    return torch.empty(0, dtype=torch.long)\n",
    "            torchvision.ops.nms = safe_nms\n",
    "    \n",
    "    print(\"‚úÖ Torchvision patched successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Torchvision patching warning: {e}\")\n",
    "\n",
    "# Method 4: Alternative library loading order\n",
    "try:\n",
    "    # Force reload transformers after torch configuration\n",
    "    if 'transformers' in sys.modules:\n",
    "        del sys.modules['transformers']\n",
    "    \n",
    "    # Import with specific backend settings\n",
    "    os.environ['TRANSFORMERS_OFFLINE'] = '0'\n",
    "    os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "    \n",
    "    print(\"‚úÖ Environment prepared for transformers\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Environment setup warning: {e}\")\n",
    "\n",
    "print(\"üéØ Compatibility fixes applied. Proceeding with model loading...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7bf63f",
   "metadata": {},
   "source": [
    "## Alternative Installation (If Above Fails)\n",
    "\n",
    "If you continue to get the `torchvision::nms` error, try this minimal installation approach:\n",
    "\n",
    "**Step 1: Uninstall conflicting packages**\n",
    "```bash\n",
    "pip uninstall torch torchvision torchaudio transformers -y\n",
    "```\n",
    "\n",
    "**Step 2: Install CPU-only versions (most compatible)**\n",
    "```bash\n",
    "pip install torch==2.0.1+cpu torchvision==0.15.2+cpu torchaudio==2.0.2+cpu --index-url https://download.pytorch.org/whl/cpu\n",
    "pip install transformers==4.30.0 datasets==2.12.0 peft==0.4.0\n",
    "```\n",
    "\n",
    "**Step 3: Install remaining packages**\n",
    "```bash\n",
    "pip install accelerate matplotlib seaborn scipy pandas numpy\n",
    "```\n",
    "\n",
    "**Note:** This uses CPU-only PyTorch which is more stable but slower. If you need GPU support, try the original installation after this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-only installation (run this if GPU installation fails)\n",
    "# Uncomment the lines below if you want to use CPU-only versions\n",
    "\n",
    "# !pip uninstall torch torchvision torchaudio transformers -y\n",
    "# !pip install torch==2.0.1+cpu torchvision==0.15.2+cpu torchaudio==2.0.2+cpu --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install transformers==4.30.0 datasets==2.12.0 peft==0.4.0 accelerate\n",
    "# !pip install matplotlib seaborn scipy pandas numpy\n",
    "\n",
    "print(\"üí° If you're still getting errors, uncomment the lines above and run this cell\")\n",
    "print(\"This will install CPU-only versions which are more compatible but slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c77481",
   "metadata": {},
   "source": [
    "## Load Individual News Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5092026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings that might be caused by version mismatches\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Additional torchvision compatibility settings\n",
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "os.environ['TORCHVISION_DISABLE_VIDEO_BACKEND'] = '1'\n",
    "\n",
    "print(\"üîß Environment configured with compatibility settings...\")\n",
    "\n",
    "# Load the base model for individual news training\n",
    "base_model_id = './Qwen3-8B'\n",
    "adapter_path = './my-awesome-model_final_bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news-v2/checkpoint-400'  # Adjust based on your checkpoint\n",
    "\n",
    "print(\"üì¶ Loading base model and tokenizer...\")\n",
    "try:\n",
    "    # Use CPU-only loading if GPU causes issues\n",
    "    device_map = \"auto\"\n",
    "    torch_dtype = torch.float16\n",
    "    \n",
    "    # Fallback to CPU if CUDA causes torchvision issues\n",
    "    if not torch.cuda.is_available():\n",
    "        device_map = \"cpu\"\n",
    "        torch_dtype = torch.float32\n",
    "        print(\"üîÑ Using CPU mode for compatibility\")\n",
    "    \n",
    "    # Load the base model and tokenizer with error handling\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=device_map,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,  # Help with memory issues\n",
    "        use_safetensors=True if os.path.exists(os.path.join(base_model_id, \"model.safetensors.index.json\")) else False\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_id,\n",
    "        trust_remote_code=True,\n",
    "        use_fast=False  # Use slow tokenizer for better compatibility\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    print(\"‚úÖ Individual News Model loaded successfully!\")\n",
    "    print(f\"üìç Model device: {next(model.parameters()).device}\")\n",
    "    print(f\"üìä Model dtype: {next(model.parameters()).dtype}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"üí° Try the following solutions:\")\n",
    "    print(\"1. Run the CPU-only installation cell above\")\n",
    "    print(\"2. Restart your kernel and re-run all cells\")\n",
    "    print(\"3. Check if the model path './Qwen3_8B' exists\")\n",
    "    print(\"4. Use the absolute path to your model\")\n",
    "    \n",
    "    # Try CPU fallback\n",
    "    try:\n",
    "        print(\"üîÑ Attempting CPU fallback...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_id,\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=\"cpu\",\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            base_model_id,\n",
    "            trust_remote_code=True,\n",
    "            use_fast=False\n",
    "        )\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        print(\"‚úÖ CPU fallback successful!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå CPU fallback also failed: {e2}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557cab7",
   "metadata": {},
   "source": [
    "## Load LoRA Adapter from Individual News Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LoRA adapter from the individual news training (checkpoint 200)\n",
    "\n",
    "print(\"üì¶ Loading LoRA adapter...\")\n",
    "try:\n",
    "    # Load the model with LoRA adapter with enhanced error handling\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model, \n",
    "        adapter_path,\n",
    "        is_trainable=False,  # Set to False for inference\n",
    "        torch_dtype=next(model.parameters()).dtype  # Match base model dtype\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    print(\"‚úÖ Individual News Model with adapter (checkpoint-200) loaded successfully!\")\n",
    "    print(f\"üìç Adapter loaded from: {adapter_path}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Adapter path not found: {e}\")\n",
    "    print(\"üí° Possible solutions:\")\n",
    "    print(\"1. Check if the adapter path exists: './qwen_bitcoin_chat_fast_more_longer/checkpoint-200'\")\n",
    "    print(\"2. Verify that the checkpoint contains the required adapter files\")\n",
    "    print(\"3. Try using a different checkpoint if available\")\n",
    "    \n",
    "    # List available checkpoints if the directory exists\n",
    "    import os\n",
    "    base_dir = './qwen_bitcoin_chat_fast_more_longer'\n",
    "    if os.path.exists(base_dir):\n",
    "        try:\n",
    "            items = os.listdir(base_dir)\n",
    "            checkpoints = [d for d in items if d.startswith('checkpoint-') and os.path.isdir(os.path.join(base_dir, d))]\n",
    "            if checkpoints:\n",
    "                checkpoints.sort(key=lambda x: int(x.split('-')[1]) if x.split('-')[1].isdigit() else 0)\n",
    "                print(f\"üìÅ Available checkpoints: {checkpoints}\")\n",
    "                \n",
    "                # Try the latest checkpoint automatically\n",
    "                latest_checkpoint = checkpoints[-1]\n",
    "                latest_path = os.path.join(base_dir, latest_checkpoint)\n",
    "                print(f\"üîÑ Attempting to load latest checkpoint: {latest_checkpoint}\")\n",
    "                \n",
    "                try:\n",
    "                    model = PeftModel.from_pretrained(\n",
    "                        model, \n",
    "                        latest_path,\n",
    "                        is_trainable=False,\n",
    "                        torch_dtype=next(model.parameters()).dtype\n",
    "                    )\n",
    "                    model.eval()\n",
    "                    print(f\"‚úÖ Successfully loaded latest checkpoint: {latest_checkpoint}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"‚ùå Failed to load latest checkpoint: {e2}\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(\"‚ùå No checkpoint directories found in the base directory\")\n",
    "                raise\n",
    "        except Exception as list_error:\n",
    "            print(f\"‚ùå Error listing directory contents: {list_error}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(f\"‚ùå Base directory '{base_dir}' does not exist\")\n",
    "        \n",
    "        # Check for alternative paths\n",
    "        alternative_paths = [\n",
    "            './checkpoint-200',\n",
    "            './checkpoints/checkpoint-200',\n",
    "            './model_outputs/checkpoint-200',\n",
    "            '../checkpoint-200'\n",
    "        ]\n",
    "        \n",
    "        for alt_path in alternative_paths:\n",
    "            if os.path.exists(alt_path):\n",
    "                print(f\"üîç Found alternative path: {alt_path}\")\n",
    "                try:\n",
    "                    model = PeftModel.from_pretrained(\n",
    "                        model, \n",
    "                        alt_path,\n",
    "                        is_trainable=False,\n",
    "                        torch_dtype=next(model.parameters()).dtype\n",
    "                    )\n",
    "                    model.eval()\n",
    "                    print(f\"‚úÖ Successfully loaded adapter from: {alt_path}\")\n",
    "                    break\n",
    "                except Exception as e3:\n",
    "                    print(f\"‚ùå Failed to load from {alt_path}: {e3}\")\n",
    "                    continue\n",
    "        else:\n",
    "            print(\"‚ùå No valid adapter paths found\")\n",
    "            raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading LoRA adapter: {e}\")\n",
    "    print(\"üí° Alternative solutions:\")\n",
    "    print(\"1. Ensure the checkpoint was saved properly during training\")\n",
    "    print(\"2. Check file permissions on the checkpoint directory\")\n",
    "    print(\"3. Try loading without adapter for base model evaluation\")\n",
    "    \n",
    "    # Option to continue without adapter\n",
    "    response = input(\"Continue without adapter? (y/n): \").lower().strip()\n",
    "    if response == 'y':\n",
    "        print(\"‚ö†Ô∏è Continuing with base model only (no adapter loaded)\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90469356",
   "metadata": {},
   "source": [
    "## Load Test Data from Individual News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28433f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the individual news dataset\n",
    "test_dataset = load_dataset('tahamajs/bitcoin-investment-advisory-dataset', split='test')\n",
    "print(f\"Loaded {len(test_dataset)} test samples\")\n",
    "print(\"Sample test data:\")\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d01a90",
   "metadata": {},
   "source": [
    "## Utility Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prices_from_text(text):\n",
    "    \"\"\"Extract price predictions from model output\"\"\"\n",
    "    # Look for patterns like numbers separated by commas\n",
    "    price_pattern = r'(\\d+(?:\\.\\d+)?(?:,\\s*\\d+(?:\\.\\d+)?)*)'  \n",
    "    matches = re.findall(price_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        # Take the first match and split by comma\n",
    "        prices_str = matches[0]\n",
    "        try:\n",
    "            prices = [float(p.strip()) for p in prices_str.split(',')]\n",
    "            return prices\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def calculate_metrics(predictions, ground_truth):\n",
    "    \"\"\"Calculate evaluation metrics\"\"\"\n",
    "    if len(predictions) != len(ground_truth):\n",
    "        return None\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    \n",
    "    mse = np.mean((predictions - ground_truth) ** 2)\n",
    "    mae = np.mean(np.abs(predictions - ground_truth))\n",
    "    mape = np.mean(np.abs((ground_truth - predictions) / ground_truth)) * 100\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'RMSE': np.sqrt(mse)\n",
    "    }\n",
    "\n",
    "def analyze_text_quality(generated_text, expected_text):\n",
    "    \"\"\"Analyze text quality metrics beyond numerical predictions\"\"\"\n",
    "    # Text length analysis\n",
    "    gen_length = len(generated_text.split())\n",
    "    exp_length = len(expected_text.split())\n",
    "    length_ratio = gen_length / exp_length if exp_length > 0 else 0\n",
    "    \n",
    "    # Word overlap analysis\n",
    "    gen_words = set(generated_text.lower().split())\n",
    "    exp_words = set(expected_text.lower().split())\n",
    "    \n",
    "    intersection = gen_words.intersection(exp_words)\n",
    "    union = gen_words.union(exp_words)\n",
    "    \n",
    "    jaccard_similarity = len(intersection) / len(union) if len(union) > 0 else 0\n",
    "    \n",
    "    # Check for key financial terms\n",
    "    financial_terms = ['price', 'market', 'trend', 'analysis', 'prediction', 'forecast', \n",
    "                      'bitcoin', 'btc', 'increase', 'decrease', 'bullish', 'bearish',\n",
    "                      'investment', 'trading', 'volatility', 'support', 'resistance']\n",
    "    \n",
    "    gen_financial_terms = sum(1 for term in financial_terms if term in generated_text.lower())\n",
    "    exp_financial_terms = sum(1 for term in financial_terms if term in expected_text.lower())\n",
    "    \n",
    "    return {\n",
    "        'length_ratio': length_ratio,\n",
    "        'jaccard_similarity': jaccard_similarity,\n",
    "        'generated_length': gen_length,\n",
    "        'expected_length': exp_length,\n",
    "        'generated_financial_terms': gen_financial_terms,\n",
    "        'expected_financial_terms': exp_financial_terms,\n",
    "        'financial_term_coverage': gen_financial_terms / max(exp_financial_terms, 1)\n",
    "    }\n",
    "\n",
    "def format_input(example):\n",
    "    \"\"\"Format input for the individual news model\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    user_input = example.get('input', '')\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': instruction},\n",
    "        {'role': 'user', 'content': user_input}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "print(\"Utility functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db2fe6",
   "metadata": {},
   "source": [
    "## Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01604cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive evaluation\n",
    "results = []\n",
    "text_quality_results = []\n",
    "total_samples = min(100, len(test_dataset))  # Test on 100 samples or all if less\n",
    "\n",
    "print(f\"Running comprehensive evaluation on {total_samples} samples...\")\n",
    "\n",
    "for i in range(total_samples):\n",
    "    test_example = test_dataset[i]\n",
    "    test_text = format_input(test_example)\n",
    "    \n",
    "    inputs = tokenizer(test_text, return_tensors='pt', truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,  # Use greedy decoding for consistency\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract predictions and ground truth\n",
    "    predicted_prices = extract_prices_from_text(generated_text)\n",
    "    actual_output = test_example.get('output', '')\n",
    "    actual_prices = extract_prices_from_text(actual_output)\n",
    "    \n",
    "    # Analyze text quality\n",
    "    text_quality = analyze_text_quality(generated_text, actual_output)\n",
    "    text_quality_results.append(text_quality)\n",
    "    \n",
    "    if predicted_prices and actual_prices:\n",
    "        # Truncate to minimum length for fair comparison\n",
    "        min_len = min(len(predicted_prices), len(actual_prices))\n",
    "        if min_len > 0:\n",
    "            pred_truncated = predicted_prices[:min_len]\n",
    "            actual_truncated = actual_prices[:min_len]\n",
    "            \n",
    "            metrics = calculate_metrics(pred_truncated, actual_truncated)\n",
    "            if metrics:\n",
    "                results.append({\n",
    "                    'sample_id': i,\n",
    "                    'predicted': pred_truncated,\n",
    "                    'actual': actual_truncated,\n",
    "                    'metrics': metrics,\n",
    "                    'text_quality': text_quality,\n",
    "                    'generated_text': generated_text,\n",
    "                    'expected_text': actual_output\n",
    "                })\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"Processed {i + 1}/{total_samples} samples...\")\n",
    "\n",
    "print(f\"\\nEvaluation completed! Analyzed {len(results)} valid samples out of {total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb79ee5",
   "metadata": {},
   "source": [
    "## Detailed Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    # Calculate numerical performance metrics\n",
    "    all_mse = [r['metrics']['MSE'] for r in results]\n",
    "    all_mae = [r['metrics']['MAE'] for r in results]\n",
    "    all_mape = [r['metrics']['MAPE'] for r in results]\n",
    "    all_rmse = [r['metrics']['RMSE'] for r in results]\n",
    "    \n",
    "    # Calculate text quality metrics\n",
    "    all_length_ratios = [r['text_quality']['length_ratio'] for r in results]\n",
    "    all_jaccard_sim = [r['text_quality']['jaccard_similarity'] for r in results]\n",
    "    all_financial_coverage = [r['text_quality']['financial_term_coverage'] for r in results]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üéØ INDIVIDUAL NEWS MODEL - COMPREHENSIVE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüìä NUMERICAL PERFORMANCE METRICS:\")\n",
    "    print(f\"Mean Squared Error (MSE): {np.mean(all_mse):.4f} ¬± {np.std(all_mse):.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {np.mean(all_mae):.4f} ¬± {np.std(all_mae):.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {np.mean(all_rmse):.4f} ¬± {np.std(all_rmse):.4f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {np.mean(all_mape):.2f}% ¬± {np.std(all_mape):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìù TEXT QUALITY METRICS:\")\n",
    "    print(f\"Average Response Length Ratio: {np.mean(all_length_ratios):.2f} ¬± {np.std(all_length_ratios):.2f}\")\n",
    "    print(f\"Average Jaccard Similarity: {np.mean(all_jaccard_sim):.3f} ¬± {np.std(all_jaccard_sim):.3f}\")\n",
    "    print(f\"Financial Term Coverage: {np.mean(all_financial_coverage):.2f} ¬± {np.std(all_financial_coverage):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìã DETAILED TEXT ANALYSIS:\")\n",
    "    avg_gen_length = np.mean([r['text_quality']['generated_length'] for r in results])\n",
    "    avg_exp_length = np.mean([r['text_quality']['expected_length'] for r in results])\n",
    "    avg_gen_fin_terms = np.mean([r['text_quality']['generated_financial_terms'] for r in results])\n",
    "    avg_exp_fin_terms = np.mean([r['text_quality']['expected_financial_terms'] for r in results])\n",
    "    \n",
    "    print(f\"Average Generated Response Length: {avg_gen_length:.1f} words\")\n",
    "    print(f\"Average Expected Response Length: {avg_exp_length:.1f} words\")\n",
    "    print(f\"Average Financial Terms in Generated: {avg_gen_fin_terms:.1f}\")\n",
    "    print(f\"Average Financial Terms in Expected: {avg_exp_fin_terms:.1f}\")\n",
    "    \n",
    "    # Median metrics for robustness\n",
    "    print(f\"\\nüìä MEDIAN PERFORMANCE METRICS (Robust):\")\n",
    "    print(f\"Median MSE: {np.median(all_mse):.4f}\")\n",
    "    print(f\"Median MAE: {np.median(all_mae):.4f}\")\n",
    "    print(f\"Median RMSE: {np.median(all_rmse):.4f}\")\n",
    "    print(f\"Median MAPE: {np.median(all_mape):.2f}%\")\n",
    "    print(f\"Median Jaccard Similarity: {np.median(all_jaccard_sim):.3f}\")\n",
    "    \n",
    "    # Sample outputs for qualitative analysis\n",
    "    print(f\"\\nüîç SAMPLE OUTPUTS FOR QUALITATIVE ANALYSIS:\")\n",
    "    for i, result in enumerate(results[:3]):\n",
    "        print(f\"\\n--- Sample {i+1} ---\")\n",
    "        print(f\"Predicted Prices: {result['predicted']}\")\n",
    "        print(f\"Actual Prices:    {result['actual']}\")\n",
    "        print(f\"MAE: {result['metrics']['MAE']:.4f}, MAPE: {result['metrics']['MAPE']:.2f}%\")\n",
    "        print(f\"Text Similarity: {result['text_quality']['jaccard_similarity']:.3f}\")\n",
    "        print(f\"Generated Text: {result['generated_text'][:200]}...\")\n",
    "        print(f\"Expected Text:  {result['expected_text'][:200]}...\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No valid results found for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14009ab4",
   "metadata": {},
   "source": [
    "## Load Base Qwen Model for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36debb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base Qwen model for comparison\n",
    "print(\"Loading base Qwen model for comparison...\")\n",
    "\n",
    "base_qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-8B-Instruct\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "base_qwen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-8B-Instruct\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if base_qwen_tokenizer.pad_token is None:\n",
    "    base_qwen_tokenizer.pad_token = base_qwen_tokenizer.eos_token\n",
    "\n",
    "print(\"Base Qwen model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa504e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base model\n",
    "def format_input_for_base_model(example):\n",
    "    \"\"\"Format input for base Qwen model with bitcoin prediction task\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    user_input = example.get('input', '')\n",
    "    \n",
    "    bitcoin_instruction = \"\"\"You are a Bitcoin investment advisor. Based on the provided market data and news, predict the next 10 days of Bitcoin prices. Provide your predictions as comma-separated numbers.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': bitcoin_instruction},\n",
    "        {'role': 'user', 'content': f\"{instruction}\\n\\n{user_input}\\n\\nPlease provide 10 Bitcoin price predictions for the next 10 days, separated by commas.\"}\n",
    "    ]\n",
    "    return base_qwen_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Run evaluation on base model\n",
    "base_results = []\n",
    "base_text_quality_results = []\n",
    "comparison_samples = min(50, len(results))  # Use subset for comparison\n",
    "\n",
    "print(f\"Evaluating base Qwen model on {comparison_samples} samples...\")\n",
    "\n",
    "for i in range(comparison_samples):\n",
    "    test_example = test_dataset[i]\n",
    "    test_text = format_input_for_base_model(test_example)\n",
    "    \n",
    "    inputs = base_qwen_tokenizer(test_text, return_tensors='pt', truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(base_qwen_model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = base_qwen_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,\n",
    "            pad_token_id=base_qwen_tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = base_qwen_tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    predicted_prices = extract_prices_from_text(generated_text)\n",
    "    actual_output = test_example.get('output', '')\n",
    "    actual_prices = extract_prices_from_text(actual_output)\n",
    "    \n",
    "    # Analyze text quality for base model\n",
    "    text_quality = analyze_text_quality(generated_text, actual_output)\n",
    "    base_text_quality_results.append(text_quality)\n",
    "    \n",
    "    if predicted_prices and actual_prices:\n",
    "        min_len = min(len(predicted_prices), len(actual_prices))\n",
    "        if min_len > 0:\n",
    "            pred_truncated = predicted_prices[:min_len]\n",
    "            actual_truncated = actual_prices[:min_len]\n",
    "            \n",
    "            metrics = calculate_metrics(pred_truncated, actual_truncated)\n",
    "            if metrics:\n",
    "                base_results.append({\n",
    "                    'sample_id': i,\n",
    "                    'predicted': pred_truncated,\n",
    "                    'actual': actual_truncated,\n",
    "                    'metrics': metrics,\n",
    "                    'text_quality': text_quality,\n",
    "                    'generated_text': generated_text,\n",
    "                    'expected_text': actual_output\n",
    "                })\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{comparison_samples} samples...\")\n",
    "\n",
    "print(f\"\\nBase model evaluation completed! Analyzed {len(base_results)} valid samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f431b7",
   "metadata": {},
   "source": [
    "## Comprehensive Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_results and results:\n",
    "    # Extract metrics from results for proper comparison\n",
    "    # Individual News Model metrics\n",
    "    ind_mse = [r['metrics']['MSE'] for r in results]\n",
    "    ind_mae = [r['metrics']['MAE'] for r in results] \n",
    "    ind_rmse = [r['metrics']['RMSE'] for r in results]\n",
    "    ind_mape = [r['metrics']['MAPE'] for r in results]\n",
    "    ind_jaccard = [r['text_quality']['jaccard_similarity'] for r in results]\n",
    "    ind_length_ratio = [r['text_quality']['length_ratio'] for r in results]\n",
    "    ind_financial_coverage = [r['text_quality']['financial_term_coverage'] for r in results]\n",
    "    \n",
    "    # Base Model metrics\n",
    "    base_mse = [r['metrics']['MSE'] for r in base_results]\n",
    "    base_mae = [r['metrics']['MAE'] for r in base_results]\n",
    "    base_rmse = [r['metrics']['RMSE'] for r in base_results]\n",
    "    base_mape = [r['metrics']['MAPE'] for r in base_results]\n",
    "    base_jaccard = [r['text_quality']['jaccard_similarity'] for r in base_results]\n",
    "    base_length_ratio = [r['text_quality']['length_ratio'] for r in base_results]\n",
    "    base_financial_coverage = [r['text_quality']['financial_term_coverage'] for r in base_results]\n",
    "    \n",
    "    # Statistical significance testing\n",
    "    from scipy.stats import wilcoxon\n",
    "    \n",
    "    # Test for significant differences (using matched samples)\n",
    "    min_samples = min(len(results), len(base_results))\n",
    "    if min_samples >= 5:  # Minimum for statistical testing\n",
    "        mse_stat, mse_pvalue = wilcoxon(ind_mse[:min_samples], base_mse[:min_samples])\n",
    "        mae_stat, mae_pvalue = wilcoxon(ind_mae[:min_samples], base_mae[:min_samples])\n",
    "        jaccard_stat, jaccard_pvalue = wilcoxon(ind_jaccard[:min_samples], base_jaccard[:min_samples])\n",
    "        \n",
    "        print(f\"\\nüî¨ STATISTICAL SIGNIFICANCE TESTS:\")\n",
    "        print(f\"MSE difference p-value: {mse_pvalue:.4f} ({'Significant' if mse_pvalue < 0.05 else 'Not significant'})\")\n",
    "        print(f\"MAE difference p-value: {mae_pvalue:.4f} ({'Significant' if mae_pvalue < 0.05 else 'Not significant'})\")\n",
    "        print(f\"Jaccard similarity p-value: {jaccard_pvalue:.4f} ({'Significant' if jaccard_pvalue < 0.05 else 'Not significant'})\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    individual_news_comprehensive_results = {\n",
    "        'individual_news_model_results': {\n",
    "            'model_id': 'tahamajs/my-awesome-model_final_bitcoin-individual-news-dataset',\n",
    "            'adapter_path': './qwen_bitcoin_chat_fast_more_longer/checkpoint-200',\n",
    "            'dataset': 'bitcoin-investment-advisory-dataset',\n",
    "            'training_config': 'longer_training_4_epochs_checkpoint_200',\n",
    "            'samples_analyzed': len(results),\n",
    "            'numerical_metrics': {\n",
    "                'mean_mse': float(np.mean(ind_mse)),\n",
    "                'mean_mae': float(np.mean(ind_mae)),\n",
    "                'mean_rmse': float(np.mean(ind_rmse)),\n",
    "                'mean_mape': float(np.mean(ind_mape))\n",
    "            },\n",
    "            'text_quality_metrics': {\n",
    "                'mean_jaccard_similarity': float(np.mean(ind_jaccard)),\n",
    "                'mean_length_ratio': float(np.mean(ind_length_ratio)),\n",
    "                'mean_financial_coverage': float(np.mean(ind_financial_coverage))\n",
    "            }\n",
    "        },\n",
    "        'base_model_results': {\n",
    "            'model_id': 'Qwen/Qwen2.5-8B-Instruct',\n",
    "            'samples_analyzed': len(base_results),\n",
    "            'numerical_metrics': {\n",
    "                'mean_mse': float(np.mean(base_mse)),\n",
    "                'mean_mae': float(np.mean(base_mae)),\n",
    "                'mean_rmse': float(np.mean(base_rmse)),\n",
    "                'mean_mape': float(np.mean(base_mape))\n",
    "            },\n",
    "            'text_quality_metrics': {\n",
    "                'mean_jaccard_similarity': float(np.mean(base_jaccard)),\n",
    "                'mean_length_ratio': float(np.mean(base_length_ratio)),\n",
    "                'mean_financial_coverage': float(np.mean(base_financial_coverage))\n",
    "            }\n",
    "        },\n",
    "        'detailed_individual_results': results,\n",
    "        'detailed_base_results': base_results\n",
    "    }\n",
    "    \n",
    "    with open('individual_news_model_comprehensive_analysis.json', 'w') as f:\n",
    "        json.dump(individual_news_comprehensive_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Comprehensive analysis results saved to 'individual_news_model_comprehensive_analysis.json'\")\n",
    "    \n",
    "    # Research paper summary\n",
    "    print(f\"\\nüìã RESEARCH PAPER SUMMARY - INDIVIDUAL NEWS MODEL:\")\n",
    "    print(\"=\" * 70)\n",
    "    mse_improvement = (np.mean(base_mse) - np.mean(ind_mse)) / np.mean(base_mse) * 100\n",
    "    mae_improvement = (np.mean(base_mae) - np.mean(ind_mae)) / np.mean(base_mae) * 100\n",
    "    jaccard_improvement = (np.mean(ind_jaccard) - np.mean(base_jaccard)) / np.mean(base_jaccard) * 100\n",
    "    \n",
    "    print(f\"Individual News Model Performance:\")\n",
    "    print(f\"‚Ä¢ MSE improved by {mse_improvement:.2f}%\")\n",
    "    print(f\"‚Ä¢ MAE improved by {mae_improvement:.2f}%\")\n",
    "    print(f\"‚Ä¢ Text similarity improved by {jaccard_improvement:.2f}%\")\n",
    "    print(f\"‚Ä¢ Mean Jaccard Similarity: {np.mean(ind_jaccard):.3f}\")\n",
    "    print(f\"‚Ä¢ Financial term coverage: {np.mean(ind_financial_coverage):.2f}\")\n",
    "    print(f\"‚Ä¢ Model: tahamajs/my-awesome-model_final_bitcoin-individual-news-dataset\")\n",
    "    print(f\"‚Ä¢ Checkpoint: 200 (4 epochs with longer parameters)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No valid results found for model comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72851737",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdabd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_results and results:\n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Individual News Model vs Base Qwen - Comprehensive Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # MSE comparison\n",
    "    axes[0,0].boxplot([base_mse, ind_mse], labels=['Base Qwen', 'Individual News'])\n",
    "    axes[0,0].set_title('Mean Squared Error', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('MSE')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE comparison\n",
    "    axes[0,1].boxplot([base_mae, ind_mae], labels=['Base Qwen', 'Individual News'])\n",
    "    axes[0,1].set_title('Mean Absolute Error', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('MAE')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAPE comparison\n",
    "    axes[0,2].boxplot([base_mape, ind_mape], labels=['Base Qwen', 'Individual News'])\n",
    "    axes[0,2].set_title('Mean Absolute Percentage Error', fontweight='bold')\n",
    "    axes[0,2].set_ylabel('MAPE (%)')\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Jaccard similarity comparison\n",
    "    axes[1,0].boxplot([base_jaccard, ind_jaccard], labels=['Base Qwen', 'Individual News'])\n",
    "    axes[1,0].set_title('Text Similarity (Jaccard)', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('Jaccard Similarity')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Length ratio comparison\n",
    "    axes[1,1].boxplot([base_length_ratio, ind_length_ratio], labels=['Base Qwen', 'Individual News'])\n",
    "    axes[1,1].set_title('Response Length Ratio', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Length Ratio')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement bar chart\n",
    "    metrics = ['MSE', 'MAE', 'MAPE', 'Text Sim', 'Length', 'Fin Terms']\n",
    "    improvements = [\n",
    "        (np.mean(base_mse) - np.mean(ind_mse)) / np.mean(base_mse) * 100,\n",
    "        (np.mean(base_mae) - np.mean(ind_mae)) / np.mean(base_mae) * 100,\n",
    "        (np.mean(base_mape) - np.mean(ind_mape)) / np.mean(base_mape) * 100,\n",
    "        (np.mean(ind_jaccard) - np.mean(base_jaccard)) / np.mean(base_jaccard) * 100,\n",
    "        (np.mean(ind_length_ratio) - np.mean(base_length_ratio)) / np.mean(base_length_ratio) * 100,\n",
    "        (np.mean(ind_financial_coverage) - np.mean(base_financial_coverage)) / np.mean(base_financial_coverage) * 100\n",
    "    ]\n",
    "    \n",
    "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "    bars = axes[1,2].bar(metrics, improvements, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, imp in zip(bars, improvements):\n",
    "        height = bar.get_height()\n",
    "        axes[1,2].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{imp:.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                       fontweight='bold', fontsize=8)\n",
    "    \n",
    "    axes[1,2].set_title('Performance Improvements', fontweight='bold')\n",
    "    axes[1,2].set_ylabel('Improvement (%)')\n",
    "    axes[1,2].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    axes[1,2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('individual_news_model_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Comprehensive analysis visualization saved as 'individual_news_model_comprehensive_analysis.png'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create visualizations - insufficient data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

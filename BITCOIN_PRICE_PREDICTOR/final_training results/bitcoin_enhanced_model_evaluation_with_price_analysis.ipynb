{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b16dfa",
   "metadata": {},
   "source": [
    "# Bitcoin Enhanced Model Evaluation with Price Difference Analysis\n",
    "This notebook evaluates the enhanced Bitcoin prediction model trained on the comprehensive news dataset and analyzes price differences between predictions and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575611c",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch peft accelerate matplotlib seaborn scipy pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05129c0",
   "metadata": {},
   "source": [
    "## Load Enhanced Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eeec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Load the enhanced model (assuming it's the same base as your other model)\n",
    "base_model_id = './Qwen3-8B'\n",
    "adapter_path = './my-awesome-model_final_bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news-v2/checkpoint-400'  # Adjust based on your checkpoint\n",
    "\n",
    "# Load the base model and tokenizer\n",
    "base_qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    adapter_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "base_qwen_tokenizer = tokenizer\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "base_qwen_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(\"Enhanced model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93260a12",
   "metadata": {},
   "source": [
    "## Load LoRA Adapter from Enhanced Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2734003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LoRA adapter from the enhanced training\n",
    "\n",
    "# Load the model with LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_qwen_model, adapter_path)\n",
    "model.eval()\n",
    "\n",
    "print(\"Enhanced model with adapter loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aec872",
   "metadata": {},
   "source": [
    "## Load Test Data from Enhanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enhanced dataset\n",
    "test_dataset = load_dataset('tahamajs/bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news', split='train')\n",
    "print(f\"Loaded {len(test_dataset)} test samples\")\n",
    "print(\"Sample test data:\")\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3ec1",
   "metadata": {},
   "source": [
    "## Utility Functions for Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139de884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prices_from_text(text):\n",
    "    \"\"\"Extract price predictions from model output\"\"\"\n",
    "    # Look for patterns like numbers separated by commas\n",
    "    price_pattern = r'(\\d+(?:\\.\\d+)?(?:,\\s*\\d+(?:\\.\\d+)?)*)'  \n",
    "    matches = re.findall(price_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        # Take the first match and split by comma\n",
    "        prices_str = matches[0]\n",
    "        try:\n",
    "            prices = [float(p.strip()) for p in prices_str.split(',')]\n",
    "            return prices\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def calculate_price_differences(predictions, actual):\n",
    "    \"\"\"Calculate various price difference metrics\"\"\"\n",
    "    if len(predictions) != len(actual):\n",
    "        return None\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    # Absolute differences\n",
    "    abs_diff = np.abs(predictions - actual)\n",
    "    \n",
    "    # Relative differences (percentage)\n",
    "    rel_diff = (predictions - actual) / actual * 100\n",
    "    \n",
    "    # Price direction accuracy (up/down/same)\n",
    "    actual_direction = np.diff(actual)\n",
    "    pred_direction = np.diff(predictions)\n",
    "    \n",
    "    direction_accuracy = 0\n",
    "    if len(actual_direction) > 0:\n",
    "        direction_correct = np.sign(actual_direction) == np.sign(pred_direction)\n",
    "        direction_accuracy = np.mean(direction_correct) * 100\n",
    "    \n",
    "    return {\n",
    "        'absolute_differences': abs_diff,\n",
    "        'relative_differences': rel_diff,\n",
    "        'mean_abs_diff': np.mean(abs_diff),\n",
    "        'max_abs_diff': np.max(abs_diff),\n",
    "        'min_abs_diff': np.min(abs_diff),\n",
    "        'std_abs_diff': np.std(abs_diff),\n",
    "        'mean_rel_diff': np.mean(rel_diff),\n",
    "        'max_rel_diff': np.max(rel_diff),\n",
    "        'min_rel_diff': np.min(rel_diff),\n",
    "        'std_rel_diff': np.std(rel_diff),\n",
    "        'direction_accuracy': direction_accuracy,\n",
    "        'rmse': np.sqrt(np.mean((predictions - actual) ** 2)),\n",
    "        'mae': np.mean(abs_diff),\n",
    "        'mape': np.mean(np.abs(rel_diff))\n",
    "    }\n",
    "\n",
    "def format_input(example):\n",
    "    \"\"\"Format input for the enhanced model\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    user_input = example.get('input', '')\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': instruction},\n",
    "        {'role': 'user', 'content': user_input}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "print(\"Utility functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a051476",
   "metadata": {},
   "source": [
    "## Comprehensive Model Evaluation with Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive evaluation\n",
    "results = []\n",
    "price_analysis_results = []\n",
    "total_samples = min(50, len(test_dataset))  # Test on 100 samples or all if less\n",
    "\n",
    "print(f\"Running comprehensive evaluation on {total_samples} samples...\")\n",
    "\n",
    "for i in range(total_samples):\n",
    "    test_example = test_dataset[i]\n",
    "    test_text = format_input(test_example)\n",
    "    \n",
    "    inputs = tokenizer(test_text, return_tensors='pt', truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,  # Use greedy decoding for consistency\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract predictions and ground truth\n",
    "    predicted_prices = extract_prices_from_text(generated_text)\n",
    "    actual_output = test_example.get('output', '')\n",
    "    actual_prices = extract_prices_from_text(actual_output)\n",
    "    \n",
    "    if predicted_prices and actual_prices:\n",
    "        # Truncate to minimum length for fair comparison\n",
    "        min_len = min(len(predicted_prices), len(actual_prices))\n",
    "        if min_len > 0:\n",
    "            pred_truncated = predicted_prices[:min_len]\n",
    "            actual_truncated = actual_prices[:min_len]\n",
    "            \n",
    "            # Calculate price differences\n",
    "            price_diff_analysis = calculate_price_differences(pred_truncated, actual_truncated)\n",
    "            \n",
    "            if price_diff_analysis:\n",
    "                results.append({\n",
    "                    'sample_id': i,\n",
    "                    'predicted': pred_truncated,\n",
    "                    'actual': actual_truncated,\n",
    "                    'price_analysis': price_diff_analysis\n",
    "                })\n",
    "                \n",
    "                price_analysis_results.append(price_diff_analysis)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"Processed {i + 1}/{total_samples} samples...\")\n",
    "\n",
    "print(f\"\\nEvaluation completed! Analyzed {len(results)} valid samples out of {total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d5599",
   "metadata": {},
   "source": [
    "## Price Difference Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    # Aggregate price difference statistics\n",
    "    all_abs_diffs = []\n",
    "    all_rel_diffs = []\n",
    "    all_direction_acc = []\n",
    "    all_rmse = []\n",
    "    all_mae = []\n",
    "    all_mape = []\n",
    "    \n",
    "    for analysis in price_analysis_results:\n",
    "        all_abs_diffs.extend(analysis['absolute_differences'])\n",
    "        all_rel_diffs.extend(analysis['relative_differences'])\n",
    "        all_direction_acc.append(analysis['direction_accuracy'])\n",
    "        all_rmse.append(analysis['rmse'])\n",
    "        all_mae.append(analysis['mae'])\n",
    "        all_mape.append(analysis['mape'])\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîç ENHANCED MODEL PRICE DIFFERENCE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüìä ABSOLUTE PRICE DIFFERENCES:\")\n",
    "    print(f\"Mean Absolute Difference: ${np.mean(all_abs_diffs):.2f}\")\n",
    "    print(f\"Median Absolute Difference: ${np.median(all_abs_diffs):.2f}\")\n",
    "    print(f\"Max Absolute Difference: ${np.max(all_abs_diffs):.2f}\")\n",
    "    print(f\"Min Absolute Difference: ${np.min(all_abs_diffs):.2f}\")\n",
    "    print(f\"Std Absolute Difference: ${np.std(all_abs_diffs):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìà RELATIVE PRICE DIFFERENCES (%):\") \n",
    "    print(f\"Mean Relative Difference: {np.mean(all_rel_diffs):.2f}%\")\n",
    "    print(f\"Median Relative Difference: {np.median(all_rel_diffs):.2f}%\")\n",
    "    print(f\"Max Relative Difference: {np.max(all_rel_diffs):.2f}%\")\n",
    "    print(f\"Min Relative Difference: {np.min(all_rel_diffs):.2f}%\")\n",
    "    print(f\"Std Relative Difference: {np.std(all_rel_diffs):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüéØ PERFORMANCE METRICS:\")\n",
    "    print(f\"Average Direction Accuracy: {np.mean(all_direction_acc):.2f}%\")\n",
    "    print(f\"Average RMSE: {np.mean(all_rmse):.4f}\")\n",
    "    print(f\"Average MAE: {np.mean(all_mae):.2f}\")\n",
    "    print(f\"Average MAPE: {np.mean(all_mape):.2f}%\")\n",
    "    \n",
    "    # Distribution analysis\n",
    "    print(f\"\\nüìã PRICE DIFFERENCE DISTRIBUTION:\")\n",
    "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "    print(\"Absolute Differences Percentiles:\")\n",
    "    for p in percentiles:\n",
    "        value = np.percentile(all_abs_diffs, p)\n",
    "        print(f\"  {p}th percentile: ${value:.2f}\")\n",
    "    \n",
    "    print(\"\\nRelative Differences Percentiles:\")\n",
    "    for p in percentiles:\n",
    "        value = np.percentile(all_rel_diffs, p)\n",
    "        print(f\"  {p}th percentile: {value:.2f}%\")\n",
    "    \n",
    "    # Sample predictions\n",
    "    print(f\"\\nüîç SAMPLE PREDICTIONS WITH PRICE ANALYSIS:\")\n",
    "    for i, result in enumerate(results[:5]):\n",
    "        analysis = result['price_analysis']\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Predicted: {result['predicted']}\")\n",
    "        print(f\"Actual:    {result['actual']}\")\n",
    "        print(f\"Mean Abs Diff: ${analysis['mean_abs_diff']:.2f}\")\n",
    "        print(f\"Mean Rel Diff: {analysis['mean_rel_diff']:.2f}%\")\n",
    "        print(f\"Direction Accuracy: {analysis['direction_accuracy']:.1f}%\")\n",
    "        print(f\"RMSE: {analysis['rmse']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No valid results found for price difference analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453ebf1",
   "metadata": {},
   "source": [
    "## Visualizations for Price Difference Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Enhanced Bitcoin Model - Price Difference Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Absolute differences histogram\n",
    "    axes[0,0].hist(all_abs_diffs, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution of Absolute Price Differences', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Absolute Difference ($)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Relative differences histogram\n",
    "    axes[0,1].hist(all_rel_diffs, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution of Relative Price Differences', fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Relative Difference (%)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Direction accuracy by sample\n",
    "    axes[0,2].plot(all_direction_acc, 'o-', alpha=0.7, color='green')\n",
    "    axes[0,2].set_title('Direction Accuracy by Sample', fontweight='bold')\n",
    "    axes[0,2].set_xlabel('Sample Index')\n",
    "    axes[0,2].set_ylabel('Direction Accuracy (%)')\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    axes[0,2].axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Random (50%)')\n",
    "    axes[0,2].legend()\n",
    "    \n",
    "    # 4. RMSE distribution\n",
    "    axes[1,0].boxplot(all_rmse)\n",
    "    axes[1,0].set_title('RMSE Distribution', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('RMSE')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. MAE vs MAPE scatter\n",
    "    axes[1,1].scatter(all_mae, all_mape, alpha=0.6, color='purple')\n",
    "    axes[1,1].set_title('MAE vs MAPE Relationship', fontweight='bold')\n",
    "    axes[1,1].set_xlabel('MAE')\n",
    "    axes[1,1].set_ylabel('MAPE (%)')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Cumulative error distribution\n",
    "    sorted_abs_diffs = np.sort(all_abs_diffs)\n",
    "    cumulative = np.arange(1, len(sorted_abs_diffs) + 1) / len(sorted_abs_diffs)\n",
    "    axes[1,2].plot(sorted_abs_diffs, cumulative, linewidth=2, color='orange')\n",
    "    axes[1,2].set_title('Cumulative Distribution of Absolute Errors', fontweight='bold')\n",
    "    axes[1,2].set_xlabel('Absolute Difference ($)')\n",
    "    axes[1,2].set_ylabel('Cumulative Probability')\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_model_price_difference_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìà Price difference analysis visualization saved as 'enhanced_model_price_difference_analysis.png'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create visualizations - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee1975",
   "metadata": {},
   "source": [
    "## Comparison with Base Qwen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base model with price difference analysis\n",
    "def format_input_for_base_model(example):\n",
    "    \"\"\"Format input for base Qwen model with bitcoin prediction task\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    user_input = example.get('input', '')\n",
    "    \n",
    "    bitcoin_instruction = \"\"\"You are a Bitcoin investment advisor. Based on the provided market data and news, predict the next 10 days of Bitcoin prices. Provide your predictions as comma-separated numbers.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': bitcoin_instruction},\n",
    "        {'role': 'user', 'content': f\"{instruction}\\n\\n{user_input}\\n\\nPlease provide 10 Bitcoin price predictions for the next 10 days, separated by commas.\"}\n",
    "    ]\n",
    "    return base_qwen_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Run evaluation on base model\n",
    "base_results = []\n",
    "base_price_analysis_results = []\n",
    "comparison_samples = min(50, len(results))  # Use subset for comparison\n",
    "\n",
    "print(f\"Evaluating base Qwen model on {comparison_samples} samples...\")\n",
    "\n",
    "for i in range(comparison_samples):\n",
    "    test_example = test_dataset[i]\n",
    "    test_text = format_input_for_base_model(test_example)\n",
    "    \n",
    "    inputs = base_qwen_tokenizer(test_text, return_tensors='pt', truncation=True, max_length=2048)\n",
    "    inputs = {k: v.to(base_qwen_model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = base_qwen_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False,\n",
    "            pad_token_id=base_qwen_tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = base_qwen_tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    predicted_prices = extract_prices_from_text(generated_text)\n",
    "    actual_output = test_example.get('output', '')\n",
    "    actual_prices = extract_prices_from_text(actual_output)\n",
    "    \n",
    "    if predicted_prices and actual_prices:\n",
    "        min_len = min(len(predicted_prices), len(actual_prices))\n",
    "        if min_len > 0:\n",
    "            pred_truncated = predicted_prices[:min_len]\n",
    "            actual_truncated = actual_prices[:min_len]\n",
    "            \n",
    "            price_diff_analysis = calculate_price_differences(pred_truncated, actual_truncated)\n",
    "            \n",
    "            if price_diff_analysis:\n",
    "                base_results.append({\n",
    "                    'sample_id': i,\n",
    "                    'predicted': pred_truncated,\n",
    "                    'actual': actual_truncated,\n",
    "                    'price_analysis': price_diff_analysis\n",
    "                })\n",
    "                \n",
    "                base_price_analysis_results.append(price_diff_analysis)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{comparison_samples} samples...\")\n",
    "\n",
    "print(f\"\\nBase model evaluation completed! Analyzed {len(base_results)} valid samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cebd92",
   "metadata": {},
   "source": [
    "## Comprehensive Model Comparison with Price Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_results and results:\n",
    "    # Extract metrics for comparison\n",
    "    enhanced_results_matched = results[:len(base_results)]  # Match sample count\n",
    "    \n",
    "    # Base model metrics\n",
    "    base_abs_diffs = []\n",
    "    base_rel_diffs = []\n",
    "    base_direction_acc = []\n",
    "    base_rmse = []\n",
    "    base_mae = []\n",
    "    base_mape = []\n",
    "    \n",
    "    for analysis in base_price_analysis_results:\n",
    "        base_abs_diffs.extend(analysis['absolute_differences'])\n",
    "        base_rel_diffs.extend(analysis['relative_differences'])\n",
    "        base_direction_acc.append(analysis['direction_accuracy'])\n",
    "        base_rmse.append(analysis['rmse'])\n",
    "        base_mae.append(analysis['mae'])\n",
    "        base_mape.append(analysis['mape'])\n",
    "    \n",
    "    # Enhanced model metrics (matched samples)\n",
    "    enhanced_abs_diffs = []\n",
    "    enhanced_rel_diffs = []\n",
    "    enhanced_direction_acc = []\n",
    "    enhanced_rmse = []\n",
    "    enhanced_mae = []\n",
    "    enhanced_mape = []\n",
    "    \n",
    "    for result in enhanced_results_matched:\n",
    "        analysis = result['price_analysis']\n",
    "        enhanced_abs_diffs.extend(analysis['absolute_differences'])\n",
    "        enhanced_rel_diffs.extend(analysis['relative_differences'])\n",
    "        enhanced_direction_acc.append(analysis['direction_accuracy'])\n",
    "        enhanced_rmse.append(analysis['rmse'])\n",
    "        enhanced_mae.append(analysis['mae'])\n",
    "        enhanced_mape.append(analysis['mape'])\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"üèÜ COMPREHENSIVE MODEL COMPARISON - PRICE DIFFERENCE ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Create detailed comparison table\n",
    "    comparison_metrics = {\n",
    "        'Metric': [\n",
    "            'Mean Absolute Difference ($)',\n",
    "            'Median Absolute Difference ($)',\n",
    "            'Mean Relative Difference (%)',\n",
    "            'Median Relative Difference (%)',\n",
    "            'Direction Accuracy (%)',\n",
    "            'RMSE',\n",
    "            'MAE',\n",
    "            'MAPE (%)'\n",
    "        ],\n",
    "        'Base Qwen Model': [\n",
    "            f\"{np.mean(base_abs_diffs):.2f}\",\n",
    "            f\"{np.median(base_abs_diffs):.2f}\",\n",
    "            f\"{np.mean(base_rel_diffs):.2f}\",\n",
    "            f\"{np.median(base_rel_diffs):.2f}\",\n",
    "            f\"{np.mean(base_direction_acc):.2f}\",\n",
    "            f\"{np.mean(base_rmse):.4f}\",\n",
    "            f\"{np.mean(base_mae):.2f}\",\n",
    "            f\"{np.mean(base_mape):.2f}\"\n",
    "        ],\n",
    "        'Enhanced Model': [\n",
    "            f\"{np.mean(enhanced_abs_diffs):.2f}\",\n",
    "            f\"{np.median(enhanced_abs_diffs):.2f}\",\n",
    "            f\"{np.mean(enhanced_rel_diffs):.2f}\",\n",
    "            f\"{np.median(enhanced_rel_diffs):.2f}\",\n",
    "            f\"{np.mean(enhanced_direction_acc):.2f}\",\n",
    "            f\"{np.mean(enhanced_rmse):.4f}\",\n",
    "            f\"{np.mean(enhanced_mae):.2f}\",\n",
    "            f\"{np.mean(enhanced_mape):.2f}\"\n",
    "        ],\n",
    "        'Improvement (%)': [\n",
    "            f\"{((np.mean(base_abs_diffs) - np.mean(enhanced_abs_diffs)) / np.mean(base_abs_diffs) * 100):.2f}\",\n",
    "            f\"{((np.median(base_abs_diffs) - np.median(enhanced_abs_diffs)) / np.median(base_abs_diffs) * 100):.2f}\",\n",
    "            f\"{((abs(np.mean(base_rel_diffs)) - abs(np.mean(enhanced_rel_diffs))) / abs(np.mean(base_rel_diffs)) * 100):.2f}\",\n",
    "            f\"{((abs(np.median(base_rel_diffs)) - abs(np.median(enhanced_rel_diffs))) / abs(np.median(base_rel_diffs)) * 100):.2f}\",\n",
    "            f\"{((np.mean(enhanced_direction_acc) - np.mean(base_direction_acc)) / np.mean(base_direction_acc) * 100):.2f}\",\n",
    "            f\"{((np.mean(base_rmse) - np.mean(enhanced_rmse)) / np.mean(base_rmse) * 100):.2f}\",\n",
    "            f\"{((np.mean(base_mae) - np.mean(enhanced_mae)) / np.mean(base_mae) * 100):.2f}\",\n",
    "            f\"{((np.mean(base_mape) - np.mean(enhanced_mape)) / np.mean(base_mape) * 100):.2f}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_metrics)\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    \n",
    "    # Statistical significance tests\n",
    "    print(f\"\\nüìä STATISTICAL SIGNIFICANCE TESTS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Test on sample-level aggregated metrics\n",
    "        base_sample_mae = [analysis['mae'] for analysis in base_price_analysis_results]\n",
    "        enhanced_sample_mae = [result['price_analysis']['mae'] for result in enhanced_results_matched]\n",
    "        \n",
    "        base_sample_direction = [analysis['direction_accuracy'] for analysis in base_price_analysis_results]\n",
    "        enhanced_sample_direction = [result['price_analysis']['direction_accuracy'] for result in enhanced_results_matched]\n",
    "        \n",
    "        mae_stat, mae_pval = wilcoxon(base_sample_mae, enhanced_sample_mae)\n",
    "        direction_stat, direction_pval = wilcoxon(base_sample_direction, enhanced_sample_direction)\n",
    "        \n",
    "        alpha = 0.05\n",
    "        print(f\"MAE Wilcoxon test p-value: {mae_pval:.6f}\")\n",
    "        print(f\"Direction Accuracy Wilcoxon test p-value: {direction_pval:.6f}\")\n",
    "        print(f\"\\nSignificance level: Œ± = {alpha}\")\n",
    "        print(f\"Significant improvement in MAE: {'YES' if mae_pval < alpha else 'NO'}\")\n",
    "        print(f\"Significant improvement in Direction Accuracy: {'YES' if direction_pval < alpha else 'NO'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Statistical test error: {e}\")\n",
    "    \n",
    "    # Prepare JSON-serializable detailed results\n",
    "    def make_json_serializable(results_list):\n",
    "        \"\"\"Convert numpy arrays in results to lists for JSON serialization\"\"\"\n",
    "        json_results = []\n",
    "        for result in results_list:\n",
    "            json_result = {\n",
    "                'sample_id': result['sample_id'],\n",
    "                'predicted': [float(x) for x in result['predicted']],\n",
    "                'actual': [float(x) for x in result['actual']],\n",
    "                'price_analysis': {\n",
    "                    'absolute_differences': [float(x) for x in result['price_analysis']['absolute_differences']],\n",
    "                    'relative_differences': [float(x) for x in result['price_analysis']['relative_differences']],\n",
    "                    'mean_abs_diff': float(result['price_analysis']['mean_abs_diff']),\n",
    "                    'max_abs_diff': float(result['price_analysis']['max_abs_diff']),\n",
    "                    'min_abs_diff': float(result['price_analysis']['min_abs_diff']),\n",
    "                    'std_abs_diff': float(result['price_analysis']['std_abs_diff']),\n",
    "                    'mean_rel_diff': float(result['price_analysis']['mean_rel_diff']),\n",
    "                    'max_rel_diff': float(result['price_analysis']['max_rel_diff']),\n",
    "                    'min_rel_diff': float(result['price_analysis']['min_rel_diff']),\n",
    "                    'std_rel_diff': float(result['price_analysis']['std_rel_diff']),\n",
    "                    'direction_accuracy': float(result['price_analysis']['direction_accuracy']),\n",
    "                    'rmse': float(result['price_analysis']['rmse']),\n",
    "                    'mae': float(result['price_analysis']['mae']),\n",
    "                    'mape': float(result['price_analysis']['mape'])\n",
    "                }\n",
    "            }\n",
    "            json_results.append(json_result)\n",
    "        return json_results\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    comprehensive_results = {\n",
    "        'enhanced_model_results': {\n",
    "            'model_id': base_model_id,\n",
    "            'adapter_path': 'tahamajs/my-awesome-model_final_bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news-v2/checkpoint-400',\n",
    "            'dataset': 'bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news',\n",
    "            'samples_analyzed': len(enhanced_results_matched),\n",
    "            'price_difference_metrics': {\n",
    "                'mean_abs_diff': float(np.mean(enhanced_abs_diffs)),\n",
    "                'median_abs_diff': float(np.median(enhanced_abs_diffs)),\n",
    "                'mean_rel_diff': float(np.mean(enhanced_rel_diffs)),\n",
    "                'median_rel_diff': float(np.median(enhanced_rel_diffs)),\n",
    "                'mean_direction_accuracy': float(np.mean(enhanced_direction_acc)),\n",
    "                'mean_rmse': float(np.mean(enhanced_rmse)),\n",
    "                'mean_mae': float(np.mean(enhanced_mae)),\n",
    "                'mean_mape': float(np.mean(enhanced_mape))\n",
    "            }\n",
    "        },\n",
    "        'base_model_results': {\n",
    "            'model_id': 'Qwen/Qwen2.5-8B-Instruct',\n",
    "            'samples_analyzed': len(base_results),\n",
    "            'price_difference_metrics': {\n",
    "                'mean_abs_diff': float(np.mean(base_abs_diffs)),\n",
    "                'median_abs_diff': float(np.median(base_abs_diffs)),\n",
    "                'mean_rel_diff': float(np.mean(base_rel_diffs)),\n",
    "                'median_rel_diff': float(np.median(base_rel_diffs)),\n",
    "                'mean_direction_accuracy': float(np.mean(base_direction_acc)),\n",
    "                'mean_rmse': float(np.mean(base_rmse)),\n",
    "                'mean_mae': float(np.mean(base_mae)),\n",
    "                'mean_mape': float(np.mean(base_mape))\n",
    "            }\n",
    "        },\n",
    "        'detailed_enhanced_results': make_json_serializable(enhanced_results_matched),\n",
    "        'detailed_base_results': make_json_serializable(base_results)\n",
    "    }\n",
    "    \n",
    "    with open('enhanced_model_comprehensive_analysis.json', 'w') as f:\n",
    "        json.dump(comprehensive_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Comprehensive analysis results saved to 'enhanced_model_comprehensive_analysis.json'\")\n",
    "    \n",
    "    # Research paper summary\n",
    "    print(f\"\\nüìã RESEARCH PAPER SUMMARY - ENHANCED MODEL:\")\n",
    "    print(\"=\" * 60)\n",
    "    abs_diff_improvement = (np.mean(base_abs_diffs) - np.mean(enhanced_abs_diffs)) / np.mean(base_abs_diffs) * 100\n",
    "    direction_improvement = (np.mean(enhanced_direction_acc) - np.mean(base_direction_acc)) / np.mean(base_direction_acc) * 100\n",
    "    mae_improvement = (np.mean(base_mae) - np.mean(enhanced_mae)) / np.mean(base_mae) * 100\n",
    "    \n",
    "    print(f\"Enhanced Model Performance:\")\n",
    "    print(f\"‚Ä¢ Price prediction accuracy improved by {abs_diff_improvement:.2f}% (absolute differences)\")\n",
    "    print(f\"‚Ä¢ Direction prediction accuracy improved by {direction_improvement:.2f}%\")\n",
    "    print(f\"‚Ä¢ Overall MAE improved by {mae_improvement:.2f}%\")\n",
    "    print(f\"‚Ä¢ Mean absolute price difference: ${np.mean(enhanced_abs_diffs):.2f}\")\n",
    "    print(f\"‚Ä¢ Direction accuracy: {np.mean(enhanced_direction_acc):.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot perform comprehensive comparison - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b04df",
   "metadata": {},
   "source": [
    "## Final Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_results and results:\n",
    "    # Create side-by-side comparison plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Enhanced vs Base Model: Price Difference Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Absolute differences comparison\n",
    "    axes[0,0].hist([base_abs_diffs, enhanced_abs_diffs], bins=30, alpha=0.7, \n",
    "                   label=['Base Qwen', 'Enhanced Model'], color=['red', 'blue'])\n",
    "    axes[0,0].set_title('Absolute Price Differences Distribution', fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Absolute Difference ($)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Direction accuracy comparison\n",
    "    axes[0,1].boxplot([base_direction_acc, enhanced_direction_acc], \n",
    "                      labels=['Base Qwen', 'Enhanced Model'])\n",
    "    axes[0,1].set_title('Direction Accuracy Comparison', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('Direction Accuracy (%)')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE comparison\n",
    "    axes[1,0].boxplot([base_mae, enhanced_mae], \n",
    "                      labels=['Base Qwen', 'Enhanced Model'])\n",
    "    axes[1,0].set_title('Mean Absolute Error Comparison', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('MAE')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement metrics bar chart\n",
    "    metrics = ['Abs Diff', 'Direction Acc', 'MAE', 'MAPE']\n",
    "    improvements = [\n",
    "        (np.mean(base_abs_diffs) - np.mean(enhanced_abs_diffs)) / np.mean(base_abs_diffs) * 100,\n",
    "        (np.mean(enhanced_direction_acc) - np.mean(base_direction_acc)) / np.mean(base_direction_acc) * 100,\n",
    "        (np.mean(base_mae) - np.mean(enhanced_mae)) / np.mean(base_mae) * 100,\n",
    "        (np.mean(base_mape) - np.mean(enhanced_mape)) / np.mean(base_mape) * 100\n",
    "    ]\n",
    "    \n",
    "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "    bars = axes[1,1].bar(metrics, improvements, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, imp in zip(bars, improvements):\n",
    "        height = bar.get_height()\n",
    "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{imp:.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                       fontweight='bold')\n",
    "    \n",
    "    axes[1,1].set_title('Performance Improvements', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Improvement (%)')\n",
    "    axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_vs_base_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Model comparison visualization saved as 'enhanced_vs_base_model_comparison.png'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot create comparison visualizations - insufficient data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

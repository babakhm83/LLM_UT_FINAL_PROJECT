{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45cb337c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564eec1",
   "metadata": {
    "papermill": {
     "duration": 0.0115,
     "end_time": "2025-09-11T23:41:35.680559",
     "exception": false,
     "start_time": "2025-09-11T23:41:35.669059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bitcoin Price Predictor: GRPO Training with Price Difference Rewards\n",
    "\n",
    "This notebook implements Group Relative Policy Optimization (GRPO) training for a Bitcoin price prediction model that has already been fine-tuned with SFT. GRPO is a reinforcement learning technique similar to PPO that further improves model performance by optimizing for specific rewards - in this case, minimizing price prediction errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec479c",
   "metadata": {
    "papermill": {
     "duration": 0.003885,
     "end_time": "2025-09-11T23:41:35.691337",
     "exception": false,
     "start_time": "2025-09-11T23:41:35.687452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Install Required Libraries for GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ca9bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-11T23:41:35.701223Z",
     "iopub.status.busy": "2025-09-11T23:41:35.700625Z",
     "iopub.status.idle": "2025-09-11T23:41:46.079796Z",
     "shell.execute_reply": "2025-09-11T23:41:46.077581Z"
    },
    "papermill": {
     "duration": 10.387882,
     "end_time": "2025-09-11T23:41:46.083043",
     "exception": false,
     "start_time": "2025-09-11T23:41:35.695161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepspeed in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (0.17.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (0.8.1)\r\n",
      "Requirement already satisfied: hjson in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (3.1.0)\r\n",
      "Requirement already satisfied: msgpack in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (1.1.1)\r\n",
      "Requirement already satisfied: ninja in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (1.11.1.4)\r\n",
      "Requirement already satisfied: numpy in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (2.2.6)\r\n",
      "Requirement already satisfied: nvidia-ml-py in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (13.580.82)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (25.0)\r\n",
      "Requirement already satisfied: psutil in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (9.0.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (2.11.7)\r\n",
      "Requirement already satisfied: torch in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (2.8.0)\r\n",
      "Requirement already satisfied: tqdm in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from deepspeed) (4.67.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (4.14.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.4.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (3.18.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (2025.3.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (11.3.3.83)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (10.3.9.90)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (11.7.3.90)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.5.8.93)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.90)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (12.8.93)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (1.13.1.3)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from torch->deepspeed) (3.4.0)\r\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from triton==3.4.0->torch->deepspeed) (59.6.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->deepspeed) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (3.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: matplotlib in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (3.10.5)\r\n",
      "Requirement already satisfied: seaborn in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: numpy in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (2.2.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for GRPO training\n",
    "!pip install trl==0.7.6 transformers>=4.38.0 datasets accelerate bitsandbytes\n",
    "!pip install wandb torch>=2.0.0 peft>=0.8.0 scipy evaluate\n",
    "!pip install deepspeed\n",
    "\n",
    "# Additional libraries for data processing and visualization\n",
    "!pip install pandas matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a267c7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-11T23:41:46.104526Z",
     "iopub.status.busy": "2025-09-11T23:41:46.103503Z",
     "iopub.status.idle": "2025-09-11T23:41:46.112122Z",
     "shell.execute_reply": "2025-09-11T23:41:46.110722Z"
    },
    "papermill": {
     "duration": 0.020669,
     "end_time": "2025-09-11T23:41:46.114756",
     "exception": false,
     "start_time": "2025-09-11T23:41:46.094087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Verify installation and check for compatibility issues\n",
    "# import sys\n",
    "# print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# try:\n",
    "#     import torch\n",
    "#     print(f\"PyTorch version: {torch.__version__}\")\n",
    "#     print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "#     if torch.cuda.is_available():\n",
    "#         print(f\"CUDA version: {torch.version.cuda}\")\n",
    "#         print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "# except ImportError as e:\n",
    "#     print(f\"PyTorch import error: {e}\")\n",
    "\n",
    "# try:\n",
    "#     import torchvision\n",
    "#     print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "# except ImportError as e:\n",
    "#     print(f\"Torchvision import error: {e}\")\n",
    "\n",
    "# try:\n",
    "#     import transformers\n",
    "#     print(f\"Transformers version: {transformers.__version__}\")\n",
    "# except ImportError as e:\n",
    "#     print(f\"Transformers import error: {e}\")\n",
    "\n",
    "# try:\n",
    "#     import peft\n",
    "#     print(f\"PEFT version: {peft.__version__}\")\n",
    "# except ImportError as e:\n",
    "#     print(f\"PEFT import error: {e}\")\n",
    "\n",
    "# print(\"\\n‚úÖ If all versions are displayed above without errors, you can proceed to the next cell.\")\n",
    "# print(\"‚ùå If you see import errors, please restart your kernel and re-run the installation cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266966f9",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2025-09-11T23:41:46.131185",
     "exception": false,
     "start_time": "2025-09-11T23:41:46.125177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load SFT-Trained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870347d8",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fe13f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-11T23:41:46.145780Z",
     "iopub.status.busy": "2025-09-11T23:41:46.144821Z",
     "iopub.status.idle": "2025-09-11T23:41:55.714226Z",
     "shell.execute_reply": "2025-09-11T23:41:55.712400Z"
    },
    "papermill": {
     "duration": 9.578468,
     "end_time": "2025-09-11T23:41:55.715629",
     "exception": true,
     "start_time": "2025-09-11T23:41:46.137161",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moein_salimi/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:69\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     66\u001b[0m     SUPPORTED_TP_STYLES,\n\u001b[1;32m     67\u001b[0m     shard_and_distribute_module,\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     Conv1D,\n\u001b[1;32m     72\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     prune_linear_layer,\n\u001b[1;32m     78\u001b[0m )\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/loss/loss_utils.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/loss/loss_deformable_detr.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/image_transforms.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     ChannelDimension,\n\u001b[1;32m     23\u001b[0m     ImageInput,\n\u001b[1;32m     24\u001b[0m     get_channel_dimension_axis,\n\u001b[1;32m     25\u001b[0m     get_image_size,\n\u001b[1;32m     26\u001b[0m     infer_channel_dimension_format,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/image_utils.py:64\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io \u001b[38;5;28;01mas\u001b[39;00m torchvision_io\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/torchvision/_meta_registrations.py:164\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision::nms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/torch/library.py:1069\u001b[0m, in \u001b[0;36mregister_fake.<locals>.register\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     use_lib \u001b[38;5;241m=\u001b[39m lib\n\u001b[0;32m-> 1069\u001b[0m \u001b[43muse_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_override\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/torch/library.py:219\u001b[0m, in \u001b[0;36mLibrary._register_fake\u001b[0;34m(self, op_name, fn, _stacklevel, allow_override)\u001b[0m\n\u001b[1;32m    217\u001b[0m     func_to_register \u001b[38;5;241m=\u001b[39m fn\n\u001b[0;32m--> 219\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_override\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registration_handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/torch/_library/fake_impl.py:50\u001b[0m, in \u001b[0;36mFakeImplHolder.register\u001b[0;34m(self, func, source, lib, allow_override)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/peft/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present the HuggingFace Inc. team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.17.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[1;32m     19\u001b[0m     AutoPeftModel,\n\u001b[1;32m     20\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     21\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     22\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     23\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig, PromptLearningConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m     30\u001b[0m     PEFT_TYPE_TO_MIXED_MODEL_MAPPING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     inject_adapter_in_model,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/peft/auto.py:31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoModel,\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     AutoTokenizer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     PeftModel,\n\u001b[1;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TOKENIZER_CONFIG_NAME\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/peft/config.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin, http_user_agent\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_NAME, PeftType, TaskType\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# we expect at least these keys to be present in a PEFT adapter_config.json\u001b[39;00m\n\u001b[1;32m     28\u001b[0m MIN_EXPECTED_CONFIG_KEYS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft_type\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/peft/utils/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_cache_to_layer_device_map\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloftq_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_lora_weights_loftq\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     19\u001b[0m     INCLUDE_LINEAR_LAYERS_SHORTHAND,\n\u001b[1;32m     20\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[1;32m     21\u001b[0m     TRANSFORMERS_MODELS_TO_ADALORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     22\u001b[0m     TRANSFORMERS_MODELS_TO_C3A_TARGET_MODULES_MAPPING,\n\u001b[1;32m     23\u001b[0m     TRANSFORMERS_MODELS_TO_FOURIERFT_TARGET_MODULES_MAPPING,\n\u001b[1;32m     24\u001b[0m     TRANSFORMERS_MODELS_TO_IA3_FEEDFORWARD_MODULES_MAPPING,\n\u001b[1;32m     25\u001b[0m     TRANSFORMERS_MODELS_TO_IA3_TARGET_MODULES_MAPPING,\n\u001b[1;32m     26\u001b[0m     TRANSFORMERS_MODELS_TO_LNTUNING_TARGET_MODULES_MAPPING,\n\u001b[1;32m     27\u001b[0m     TRANSFORMERS_MODELS_TO_LOHA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     28\u001b[0m     TRANSFORMERS_MODELS_TO_LOKR_TARGET_MODULES_MAPPING,\n\u001b[1;32m     29\u001b[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     30\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m     31\u001b[0m     TRANSFORMERS_MODELS_TO_RANDLORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     32\u001b[0m     TRANSFORMERS_MODELS_TO_SHIRA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     33\u001b[0m     TRANSFORMERS_MODELS_TO_VBLORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     34\u001b[0m     TRANSFORMERS_MODELS_TO_VERA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     35\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     36\u001b[0m     AuxiliaryTrainingWrapper,\n\u001b[1;32m     37\u001b[0m     ModulesToSaveWrapper,\n\u001b[1;32m     38\u001b[0m     _freeze_adapter,\n\u001b[1;32m     39\u001b[0m     _get_batch_size,\n\u001b[1;32m     40\u001b[0m     _get_input_embeddings_name,\n\u001b[1;32m     41\u001b[0m     _get_submodules,\n\u001b[1;32m     42\u001b[0m     _is_valid_match,\n\u001b[1;32m     43\u001b[0m     _prepare_prompt_learning_config,\n\u001b[1;32m     44\u001b[0m     _set_adapter,\n\u001b[1;32m     45\u001b[0m     _set_trainable,\n\u001b[1;32m     46\u001b[0m     bloom_model_postprocess_past_key_value,\n\u001b[1;32m     47\u001b[0m     cast_mixed_precision_params,\n\u001b[1;32m     48\u001b[0m     get_auto_gptq_quant_linear,\n\u001b[1;32m     49\u001b[0m     get_gptqmodel_quant_linear,\n\u001b[1;32m     50\u001b[0m     get_quantization_config,\n\u001b[1;32m     51\u001b[0m     id_tensor_storage,\n\u001b[1;32m     52\u001b[0m     infer_device,\n\u001b[1;32m     53\u001b[0m     prepare_model_for_kbit_training,\n\u001b[1;32m     54\u001b[0m     set_additional_trainable_modules,\n\u001b[1;32m     55\u001b[0m     shift_tokens_right,\n\u001b[1;32m     56\u001b[0m     transpose,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftType, TaskType, register_peft_method\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave_and_load\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_peft_model_state_dict, load_peft_weights, set_peft_model_state_dict\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/peft/utils/other.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage_ptr, storage_size\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_auto_gptq_available, is_gptqmodel_available, is_torch_tpu_available\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     41\u001b[0m     EMBEDDING_LAYER_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     starcoder_model_postprocess_past_key_value,\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/users/babak/IdeaGeneration/venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_utils because of the following error (look up to see its traceback):\noperator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Load the enhanced model (assuming it's the same base as your other model)\n",
    "base_model_id = './Qwen3-8B'\n",
    "adapter_path = './my-awesome-model_final_bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news-v2/checkpoint-400'  # Adjust based on your checkpoint\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings that might be caused by version mismatches\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set torch backend to avoid potential conflicts\n",
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "print(\"üîß Environment configured with compatibility settings...\")\n",
    "\n",
    "# Load the base model for individual news training\n",
    "base_model_id = './Qwen3_8B'\n",
    "\n",
    "print(\"üì¶ Loading base model and tokenizer...\")\n",
    "try:\n",
    "    # Load the base model and tokenizer with error handling\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True  # Help with memory issues\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_id,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    print(\"‚úÖ Individual News Model loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"üí° Try the following solutions:\")\n",
    "    print(\"1. Restart your kernel and re-run the installation cell\")\n",
    "    print(\"2. Check if the model path './Qwen3_8B' exists\")\n",
    "    print(\"3. Use the absolute path to your model\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756dfca0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Setup Reward Function for Price Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6f68b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_prices_from_text(text):\n",
    "    \"\"\"Extract price predictions from model output\"\"\"\n",
    "    # Look for patterns like numbers separated by commas\n",
    "    price_pattern = r'(\\d+(?:\\.\\d+)?(?:,\\s*\\d+(?:\\.\\d+)?)*)'  \n",
    "    matches = re.findall(price_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        # Take the first match and split by comma\n",
    "        prices_str = matches[0]\n",
    "        try:\n",
    "            prices = [float(p.strip()) for p in prices_str.split(',')]\n",
    "            return prices\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def calculate_price_difference_reward(predicted_prices, actual_prices, max_len=10):\n",
    "    \"\"\"Calculate reward based on price difference accuracy\n",
    "    \n",
    "    Lower price differences = higher rewards\n",
    "    Correct price direction predictions = bonus rewards\n",
    "    \"\"\"\n",
    "    # Ensure we have valid predictions\n",
    "    if not predicted_prices or not actual_prices:\n",
    "        return -10.0  # Penalty for invalid predictions\n",
    "    \n",
    "    # Truncate to minimum length and max_len for fair comparison\n",
    "    min_len = min(len(predicted_prices), len(actual_prices), max_len)\n",
    "    if min_len <= 1:  # Need at least 2 prices to calculate direction\n",
    "        return -5.0  # Smaller penalty for partial predictions\n",
    "        \n",
    "    pred_truncated = np.array(predicted_prices[:min_len])\n",
    "    actual_truncated = np.array(actual_prices[:min_len])\n",
    "    \n",
    "    # Calculate absolute differences\n",
    "    abs_diffs = np.abs(pred_truncated - actual_truncated)\n",
    "    mean_abs_diff = np.mean(abs_diffs)\n",
    "    \n",
    "    # Calculate direction accuracy (up/down/same)\n",
    "    actual_direction = np.diff(actual_truncated)\n",
    "    pred_direction = np.diff(pred_truncated)\n",
    "    direction_correct = np.sign(actual_direction) == np.sign(pred_direction)\n",
    "    direction_accuracy = np.mean(direction_correct) if len(direction_correct) > 0 else 0\n",
    "    \n",
    "    # Convert price differences to rewards (lower difference = higher reward)\n",
    "    # Normalize by typical Bitcoin price volatility (e.g., $1000)\n",
    "    price_diff_reward = 10.0 * np.exp(-mean_abs_diff / 1000)\n",
    "    \n",
    "    # Add bonus for direction accuracy\n",
    "    direction_bonus = 5.0 * direction_accuracy\n",
    "    \n",
    "    # Combine rewards (price difference + direction bonus)\n",
    "    total_reward = price_diff_reward + direction_bonus\n",
    "    \n",
    "    return float(total_reward)\n",
    "\n",
    "def compute_rewards(predictions, references):\n",
    "    \"\"\"Compute rewards for a batch of predictions and references\"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Extract predicted prices from model output\n",
    "        predicted_prices = extract_prices_from_text(pred)\n",
    "        \n",
    "        # Extract actual prices from reference output\n",
    "        actual_prices = extract_prices_from_text(ref)\n",
    "        \n",
    "        # Calculate reward based on price differences\n",
    "        reward = calculate_price_difference_reward(predicted_prices, actual_prices)\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58be8a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Create GRPO Dataset from Bitcoin Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3911a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "print(\"Loading Bitcoin prediction dataset...\")\n",
    "# Load the Bitcoin prediction dataset\n",
    "train_dataset = load_dataset('tahamajs/bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news', split='train')\n",
    "test_dataset = load_dataset('tahamajs/bitcoin-enhanced-prediction-dataset-with-local-comprehensive-news', split='train')\n",
    "\n",
    "print(f\"Loaded {len(train_dataset)} training samples and {len(test_dataset)} test samples\")\n",
    "\n",
    "def format_prompt(example):\n",
    "    \"\"\"Format prompt for the model\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    user_input = example.get('input', '')\n",
    "    \n",
    "    return f\"\"\"<|im_start|>system\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# Prepare a subset for GRPO training (GRPO training can be computationally expensive)\n",
    "num_samples = min(500, len(train_dataset))  # Adjust based on your computational resources\n",
    "grpo_train_dataset = train_dataset.select(range(num_samples))\n",
    "\n",
    "# Format prompts for GRPO training\n",
    "grpo_data = []\n",
    "for example in grpo_train_dataset:\n",
    "    prompt = format_prompt(example)\n",
    "    output = example.get('output', '')\n",
    "    \n",
    "    grpo_data.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": output,  # The ground truth output\n",
    "        \"rejected\": None,  # Will be generated by the model during training\n",
    "    })\n",
    "\n",
    "# Convert to Dataset format\n",
    "grpo_dataset = Dataset.from_pandas(pd.DataFrame(grpo_data))\n",
    "\n",
    "print(f\"Created GRPO dataset with {len(grpo_dataset)} samples\")\n",
    "print(\"Sample prompt:\")\n",
    "print(grpo_dataset[0]['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0abb96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Configure GRPO Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57920ecf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./grpo_bitcoin_price_predictor\"\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,                 # Number of training epochs\n",
    "    per_device_train_batch_size=4,      # Batch size for training\n",
    "    gradient_accumulation_steps=4,      # Number of updates steps to accumulate before backward pass\n",
    "    learning_rate=1e-5,                 # Learning rate\n",
    "    weight_decay=0.01,                  # Weight decay\n",
    "    warmup_steps=100,                   # Number of warmup steps\n",
    "    logging_steps=10,                   # Log every X updates steps\n",
    "    eval_strategy=\"steps\",        # Evaluation strategy\n",
    "    eval_steps=100,                     # Evaluate every X steps\n",
    "    save_strategy=\"steps\",              # Save strategy\n",
    "    save_steps=100,                     # Save checkpoint every X updates steps\n",
    "    save_total_limit=3,                 # Maximum number of checkpoints to keep\n",
    "    load_best_model_at_end=True,        # Load the best model when training finishes\n",
    "    fp16=True,                          # Use FP16 precision\n",
    "    report_to=\"none\"                    # Disable wandb reporting (change to \"wandb\" to enable)\n",
    ")\n",
    "\n",
    "# GRPO specific hyperparameters\n",
    "grpo_config = {\n",
    "    \"num_rollouts\": 32,             # Number of rollouts per prompt\n",
    "    \"chunk_size\": 4,                # Number of chunks to split the batch into\n",
    "    \"beta\": 0.1,                    # KL penalty coefficient\n",
    "    \"lambda_coef\": 0.95,            # GAE lambda coefficient\n",
    "    \"gamma\": 0.99,                  # Discount factor\n",
    "    \"eps_clip\": 0.2,                # PPO clip range\n",
    "    \"value_clip\": 0.2,              # Value clip range\n",
    "    \"generate_during_eval\": True,   # Generate completions during evaluation\n",
    "    \"max_new_tokens\": 256,          # Maximum number of tokens to generate\n",
    "    \"temperature\": 0.7,             # Temperature for generation\n",
    "    \"top_k\": 50,                    # Top-k sampling\n",
    "    \"top_p\": 0.95,                  # Top-p sampling\n",
    "    \"do_sample\": True,              # Use sampling for generation\n",
    "    \"rollout_batch_size\": 8         # Batch size for rollout generation\n",
    "}\n",
    "\n",
    "print(\"Training arguments and GRPO configuration ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998853e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Initialize GRPO Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e300c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trl import GroupPPOConfig, GroupPPOTrainer\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "# 1. Define a single, comprehensive configuration object for GroupPPO\n",
    "# This combines parameters that were previously in TrainingArguments and the separate RL config.\n",
    "ppo_config = GroupPPOConfig(\n",
    "    # --- Training loop parameters ---\n",
    "    learning_rate=1e-5,\n",
    "    batch_size=16,          # Combined from per_device_train_batch_size * gradient_accumulation_steps\n",
    "    mini_batch_size=4,      # Corresponds to per_device_train_batch_size\n",
    "    gradient_accumulation_steps=4,\n",
    "    ppo_epochs=4,           # Number of optimization epochs per PPO phase\n",
    "    \n",
    "    # --- RL-specific parameters ---\n",
    "    beta=0.1,               # KL penalty coefficient\n",
    "    lambda_=0.95,           # GAE lambda coefficient (note the underscore)\n",
    "    gamma=0.99,             # Discount factor\n",
    "    cliprange=0.2,          # PPO clip range\n",
    "    cliprange_value=0.2,    # Value function clip range\n",
    "    vf_coef=0.1,            # Value function coefficient in the loss\n",
    "    \n",
    "    # --- Other trainer settings ---\n",
    "    log_with=None,          # Set to \"wandb\" or \"tensorboard\" to enable logging\n",
    "    tracker_project_name=\"bitcoin_grpo\",\n",
    "    seed=42,\n",
    "    optimize_cuda_cache=True,\n",
    "    target_kl=0.1\n",
    ")\n",
    "\n",
    "# 2. Set generation kwargs for rollouts\n",
    "# These are passed to the `trainer.generate` method inside the training loop\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id, # Assumes tokenizer is already loaded\n",
    "}\n",
    "\n",
    "# 3. Initialize the GRPO trainer\n",
    "# Assumes model, tokenizer, and grpo_dataset are already loaded\n",
    "print(\"Initializing GRPO trainer...\")\n",
    "grpo_trainer = GroupPPOTrainer(\n",
    "    config=ppo_config,\n",
    "    model=model,\n",
    "    ref_model=None,  # It's good practice to have a reference model for KL divergence\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=grpo_dataset,\n",
    "    data_collator=None, # The trainer will use its default collator\n",
    ")\n",
    "\n",
    "print(\"GRPO trainer initialized successfully!\")\n",
    "print(\"\\nNext, you will start the training loop (e.g., for batch in grpo_trainer.dataloader: ...)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11e0cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Run GRPO Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa226e0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a length sampler for response generation\n",
    "length_sampler = LengthSampler(min_value=32, max_value=grpo_config['max_new_tokens'])\n",
    "\n",
    "# Performance tracking variables\n",
    "epochs = 3\n",
    "reward_history = []\n",
    "loss_history = []\n",
    "kl_div_history = []\n",
    "\n",
    "print(\"Starting GRPO training...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n===== Epoch {epoch+1}/{epochs} =====\")\n",
    "    \n",
    "    # Training loop for multiple batch iterations\n",
    "    for batch_idx in range(10):  # Process 10 batches per epoch - adjust as needed\n",
    "        print(f\"Processing batch {batch_idx+1}/10\")\n",
    "        \n",
    "        # Sample batch of prompts\n",
    "        batch_indices = random.sample(range(len(grpo_dataset)), grpo_config['chunk_size'])\n",
    "        batch = grpo_dataset.select(batch_indices)\n",
    "        \n",
    "        # Generate model responses\n",
    "        prompts = batch['prompt']\n",
    "        references = batch['chosen']\n",
    "        \n",
    "        # Step 1: Generate responses for reward computation\n",
    "        response_tensors = []\n",
    "        responses = []\n",
    "        \n",
    "        for prompt in prompts:\n",
    "            prompt_tensor = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            response_length = length_sampler()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                response_tensor = grpo_trainer.generate(\n",
    "                    prompt_tensor['input_ids'], \n",
    "                    **generation_kwargs\n",
    "                )\n",
    "                \n",
    "            response = tokenizer.decode(\n",
    "                response_tensor[0][prompt_tensor['input_ids'].shape[1]:],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            responses.append(response)\n",
    "            response_tensors.append(response_tensor)\n",
    "        \n",
    "        # Step 2: Compute rewards based on price differences\n",
    "        rewards = compute_rewards(responses, references)\n",
    "        mean_reward = sum(rewards) / len(rewards) if rewards else 0\n",
    "        reward_history.append(mean_reward)\n",
    "        \n",
    "        print(f\"Mean reward: {mean_reward:.4f}\")\n",
    "        \n",
    "        # Step 3: Perform GRPO update\n",
    "        stats = grpo_trainer.step(prompts, responses, rewards)\n",
    "        \n",
    "        # Track metrics\n",
    "        if stats:\n",
    "            loss_history.append(stats['ppo/loss/total'])\n",
    "            kl_div_history.append(stats.get('ppo/kl', 0))\n",
    "            \n",
    "            print(f\"Loss: {stats['ppo/loss/total']:.4f}, KL div: {stats.get('ppo/kl', 0):.4f}\")\n",
    "    \n",
    "    # Save checkpoint at the end of each epoch\n",
    "    checkpoint_path = f\"{output_dir}/checkpoint-epoch-{epoch+1}\"\n",
    "    grpo_trainer.save_pretrained(checkpoint_path)\n",
    "    print(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "\n",
    "print(\"GRPO training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cccfd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Evaluate GRPO-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6e995",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Plot training metrics\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(reward_history)\n",
    "plt.title('Mean Reward History')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(loss_history)\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(kl_div_history)\n",
    "plt.title('KL Divergence History')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('KL Divergence')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('grpo_training_metrics.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvaluating GRPO-trained model...\")\n",
    "\n",
    "# Evaluate GRPO-trained model on test dataset\n",
    "grpo_model = grpo_trainer.model\n",
    "grpo_model.eval()\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataset, num_samples=50):\n",
    "    results = []\n",
    "    total_samples = min(num_samples, len(dataset))\n",
    "    \n",
    "    print(f\"Running evaluation on {total_samples} samples...\")\n",
    "    \n",
    "    for i in range(total_samples):\n",
    "        test_example = dataset[i]\n",
    "        prompt = format_prompt(test_example)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=2048)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=256,\n",
    "                do_sample=False,  # Use greedy decoding for consistency\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract predictions and ground truth\n",
    "        predicted_prices = extract_prices_from_text(generated_text)\n",
    "        actual_output = test_example.get('output', '')\n",
    "        actual_prices = extract_prices_from_text(actual_output)\n",
    "        \n",
    "        # Calculate metrics if predictions are valid\n",
    "        if predicted_prices and actual_prices:\n",
    "            min_len = min(len(predicted_prices), len(actual_prices))\n",
    "            if min_len > 0:\n",
    "                pred_truncated = predicted_prices[:min_len]\n",
    "                actual_truncated = actual_prices[:min_len]\n",
    "                \n",
    "                # Calculate absolute differences\n",
    "                abs_diffs = np.abs(np.array(pred_truncated) - np.array(actual_truncated))\n",
    "                mean_abs_diff = np.mean(abs_diffs)\n",
    "                \n",
    "                # Calculate direction accuracy\n",
    "                actual_direction = np.diff(actual_truncated)\n",
    "                pred_direction = np.diff(pred_truncated)\n",
    "                direction_correct = np.sign(actual_direction) == np.sign(pred_direction)\n",
    "                direction_accuracy = np.mean(direction_correct) * 100 if len(direction_correct) > 0 else 0\n",
    "                \n",
    "                # Calculate reward\n",
    "                reward = calculate_price_difference_reward(pred_truncated, actual_truncated)\n",
    "                \n",
    "                results.append({\n",
    "                    'sample_id': i,\n",
    "                    'predicted': pred_truncated,\n",
    "                    'actual': actual_truncated,\n",
    "                    'mean_abs_diff': mean_abs_diff,\n",
    "                    'direction_accuracy': direction_accuracy,\n",
    "                    'reward': reward\n",
    "                })\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{total_samples} samples...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate GRPO model\n",
    "grpo_results = evaluate_model(grpo_model, tokenizer, test_dataset)\n",
    "\n",
    "# Calculate aggregate metrics\n",
    "if grpo_results:\n",
    "    grpo_abs_diffs = [r['mean_abs_diff'] for r in grpo_results]\n",
    "    grpo_direction_accs = [r['direction_accuracy'] for r in grpo_results]\n",
    "    grpo_rewards = [r['reward'] for r in grpo_results]\n",
    "    \n",
    "    print(\"\\nGRPO Model Evaluation Results:\")\n",
    "    print(f\"Mean Absolute Price Difference: ${np.mean(grpo_abs_diffs):.2f}\")\n",
    "    print(f\"Median Absolute Price Difference: ${np.median(grpo_abs_diffs):.2f}\")\n",
    "    print(f\"Mean Direction Accuracy: {np.mean(grpo_direction_accs):.2f}%\")\n",
    "    print(f\"Mean Reward: {np.mean(grpo_rewards):.4f}\")\n",
    "else:\n",
    "    print(\"No valid evaluation results for GRPO model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdd405",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Compare SFT vs GRPO Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06496151",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload the original SFT model for comparison\n",
    "print(\"Loading SFT model for comparison...\")\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "sft_model = PeftModel.from_pretrained(sft_model, adapter_path)\n",
    "sft_model.eval()\n",
    "\n",
    "# Evaluate SFT model (pre-GRPO)\n",
    "sft_results = evaluate_model(sft_model, tokenizer, test_dataset)\n",
    "\n",
    "# Compare SFT and GRPO models\n",
    "if sft_results and grpo_results:\n",
    "    sft_abs_diffs = [r['mean_abs_diff'] for r in sft_results]\n",
    "    sft_direction_accs = [r['direction_accuracy'] for r in sft_results]\n",
    "    sft_rewards = [r['reward'] for r in sft_results]\n",
    "    \n",
    "    # Calculate improvements\n",
    "    abs_diff_improvement = ((np.mean(sft_abs_diffs) - np.mean(grpo_abs_diffs)) / np.mean(sft_abs_diffs)) * 100\n",
    "    direction_improvement = ((np.mean(grpo_direction_accs) - np.mean(sft_direction_accs)) / np.mean(sft_direction_accs)) * 100\n",
    "    reward_improvement = ((np.mean(grpo_rewards) - np.mean(sft_rewards)) / np.mean(sft_rewards)) * 100 if np.mean(sft_rewards) != 0 else 0\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_metrics = {\n",
    "        'Metric': [\n",
    "            'Mean Absolute Price Difference ($)',\n",
    "            'Median Absolute Price Difference ($)',\n",
    "            'Mean Direction Accuracy (%)',\n",
    "            'Mean Reward'\n",
    "        ],\n",
    "        'SFT Model': [\n",
    "            f\"{np.mean(sft_abs_diffs):.2f}\",\n",
    "            f\"{np.median(sft_abs_diffs):.2f}\",\n",
    "            f\"{np.mean(sft_direction_accs):.2f}\",\n",
    "            f\"{np.mean(sft_rewards):.4f}\"\n",
    "        ],\n",
    "        'GRPO Model': [\n",
    "            f\"{np.mean(grpo_abs_diffs):.2f}\",\n",
    "            f\"{np.median(grpo_abs_diffs):.2f}\",\n",
    "            f\"{np.mean(grpo_direction_accs):.2f}\",\n",
    "            f\"{np.mean(grpo_rewards):.4f}\"\n",
    "        ],\n",
    "        'Improvement (%)': [\n",
    "            f\"{abs_diff_improvement:.2f}\",\n",
    "            f\"{((np.median(sft_abs_diffs) - np.median(grpo_abs_diffs)) / np.median(sft_abs_diffs) * 100):.2f}\",\n",
    "            f\"{direction_improvement:.2f}\",\n",
    "            f\"{reward_improvement:.2f}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_metrics)\n",
    "    print(\"\\n=== SFT vs GRPO Model Comparison ===\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Statistical significance tests\n",
    "    print(\"\\n=== Statistical Significance Tests ===\")\n",
    "    try:\n",
    "        abs_diff_stat, abs_diff_pval = wilcoxon(sft_abs_diffs, grpo_abs_diffs)\n",
    "        direction_stat, direction_pval = wilcoxon(sft_direction_accs, grpo_direction_accs)\n",
    "        reward_stat, reward_pval = wilcoxon(sft_rewards, grpo_rewards)\n",
    "        \n",
    "        alpha = 0.05\n",
    "        print(f\"Absolute Difference p-value: {abs_diff_pval:.6f} - {'Significant' if abs_diff_pval < alpha else 'Not significant'}\")\n",
    "        print(f\"Direction Accuracy p-value: {direction_pval:.6f} - {'Significant' if direction_pval < alpha else 'Not significant'}\")\n",
    "        print(f\"Reward p-value: {reward_pval:.6f} - {'Significant' if reward_pval < alpha else 'Not significant'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Statistical test error: {e}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Price difference comparison\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.histplot([sft_abs_diffs, grpo_abs_diffs], bins=30, alpha=0.6, \n",
    "                 label=['SFT Model', 'GRPO Model'])\n",
    "    plt.title('Absolute Price Differences Distribution')\n",
    "    plt.xlabel('Absolute Difference ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Direction accuracy comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.boxplot([sft_direction_accs, grpo_direction_accs], labels=['SFT Model', 'GRPO Model'])\n",
    "    plt.title('Direction Accuracy Comparison')\n",
    "    plt.ylabel('Direction Accuracy (%)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Reward comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.boxplot([sft_rewards, grpo_rewards], labels=['SFT Model', 'GRPO Model'])\n",
    "    plt.title('Reward Comparison')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improvement metrics\n",
    "    plt.subplot(2, 2, 4)\n",
    "    metrics = ['Abs Diff', 'Direction Acc', 'Reward']\n",
    "    improvements = [abs_diff_improvement, direction_improvement, reward_improvement]\n",
    "    \n",
    "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "    plt.bar(metrics, improvements, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, imp in enumerate(improvements):\n",
    "        plt.text(i, imp, f'{imp:.1f}%', ha='center', va='bottom' if imp > 0 else 'top',\n",
    "                fontweight='bold')\n",
    "    \n",
    "    plt.title('GRPO Improvements over SFT')\n",
    "    plt.ylabel('Improvement (%)')\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sft_vs_grpo_comparison.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nComparison visualization saved as 'sft_vs_grpo_comparison.png'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for SFT vs GRPO comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72492cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Save GRPO Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37aad2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the final GRPO model\n",
    "final_output_dir = f\"{output_dir}/final\"\n",
    "grpo_trainer.save_pretrained(final_output_dir)\n",
    "print(f\"Saved final GRPO model to {final_output_dir}\")\n",
    "\n",
    "# Save training metrics\n",
    "training_metrics = {\n",
    "    'reward_history': reward_history,\n",
    "    'loss_history': loss_history,\n",
    "    'kl_div_history': kl_div_history\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f\"{output_dir}/training_metrics.json\", 'w') as f:\n",
    "    json.dump(training_metrics, f, indent=2)\n",
    "\n",
    "# Save evaluation results\n",
    "if sft_results and grpo_results:\n",
    "    eval_results = {\n",
    "        'sft_model': {\n",
    "            'model_id': base_model_id,\n",
    "            'adapter_path': adapter_path,\n",
    "            'results': [{\n",
    "                'sample_id': r['sample_id'],\n",
    "                'predicted': [float(x) for x in r['predicted']],\n",
    "                'actual': [float(x) for x in r['actual']],\n",
    "                'mean_abs_diff': float(r['mean_abs_diff']),\n",
    "                'direction_accuracy': float(r['direction_accuracy']),\n",
    "                'reward': float(r['reward'])\n",
    "            } for r in sft_results],\n",
    "            'metrics': {\n",
    "                'mean_abs_diff': float(np.mean(sft_abs_diffs)),\n",
    "                'median_abs_diff': float(np.median(sft_abs_diffs)),\n",
    "                'mean_direction_accuracy': float(np.mean(sft_direction_accs)),\n",
    "                'mean_reward': float(np.mean(sft_rewards))\n",
    "            }\n",
    "        },\n",
    "        'grpo_model': {\n",
    "            'model_id': base_model_id,\n",
    "            'adapter_path': final_output_dir,\n",
    "            'results': [{\n",
    "                'sample_id': r['sample_id'],\n",
    "                'predicted': [float(x) for x in r['predicted']],\n",
    "                'actual': [float(x) for x in r['actual']],\n",
    "                'mean_abs_diff': float(r['mean_abs_diff']),\n",
    "                'direction_accuracy': float(r['direction_accuracy']),\n",
    "                'reward': float(r['reward'])\n",
    "            } for r in grpo_results],\n",
    "            'metrics': {\n",
    "                'mean_abs_diff': float(np.mean(grpo_abs_diffs)),\n",
    "                'median_abs_diff': float(np.median(grpo_abs_diffs)),\n",
    "                'mean_direction_accuracy': float(np.mean(grpo_direction_accs)),\n",
    "                'mean_reward': float(np.mean(grpo_rewards))\n",
    "            }\n",
    "        },\n",
    "        'improvements': {\n",
    "            'abs_diff_improvement': float(abs_diff_improvement),\n",
    "            'direction_improvement': float(direction_improvement),\n",
    "            'reward_improvement': float(reward_improvement)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f\"{output_dir}/evaluation_results.json\", 'w') as f:\n",
    "        json.dump(eval_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved evaluation results to {output_dir}/evaluation_results.json\")\n",
    "\n",
    "print(\"\\nüìä SUMMARY: GRPO TRAINING FOR BITCOIN PRICE PREDICTION\")\n",
    "print(\"=\"* 60)\n",
    "print(\"‚úÖ Completed GRPO training with price difference rewards\")\n",
    "print(\"‚úÖ Model saved and ready for inference\")\n",
    "print(\"‚úÖ Performance analysis and comparisons completed\")\n",
    "print(\"\\nTo use this model for inference, load it with:\")\n",
    "print(\"```python\")\n",
    "print(\"from transformers import AutoModelForCausalLM, AutoTokenizer\")\n",
    "print(\"from peft import PeftModel\")\n",
    "print(f\"model = AutoModelForCausalLM.from_pretrained('{base_model_id}', trust_remote_code=True)\")\n",
    "print(f\"model = PeftModel.from_pretrained(model, '{final_output_dir}')\")\n",
    "print(f\"tokenizer = AutoTokenizer.from_pretrained('{base_model_id}', trust_remote_code=True)\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfa4fc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample prediction with GRPO model\n",
    "print(\"Sample prediction with GRPO model:\")\n",
    "\n",
    "# Use a test sample\n",
    "test_sample = test_dataset[0]\n",
    "prompt = format_prompt(test_sample)\n",
    "\n",
    "# Generate prediction\n",
    "inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=2048)\n",
    "inputs = {k: v.to(grpo_model.device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = grpo_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "# Extract predictions\n",
    "predicted_prices = extract_prices_from_text(generated_text)\n",
    "actual_output = test_sample.get('output', '')\n",
    "actual_prices = extract_prices_from_text(actual_output)\n",
    "\n",
    "print(\"Input prompt:\")\n",
    "print(prompt[:500] + \"...\" if len(prompt) > 500 else prompt)\n",
    "print(\"\\nGRPO model prediction:\")\n",
    "print(generated_text[:500] + \"...\" if len(generated_text) > 500 else generated_text)\n",
    "print(f\"\\nPredicted prices: {predicted_prices}\")\n",
    "print(f\"Actual prices: {actual_prices}\")\n",
    "\n",
    "if predicted_prices and actual_prices:\n",
    "    min_len = min(len(predicted_prices), len(actual_prices))\n",
    "    if min_len > 0:\n",
    "        pred_truncated = predicted_prices[:min_len]\n",
    "        actual_truncated = actual_prices[:min_len]\n",
    "        \n",
    "        abs_diffs = np.abs(np.array(pred_truncated) - np.array(actual_truncated))\n",
    "        mean_abs_diff = np.mean(abs_diffs)\n",
    "        reward = calculate_price_difference_reward(pred_truncated, actual_truncated)\n",
    "        \n",
    "        print(f\"\\nMean absolute difference: ${mean_abs_diff:.2f}\")\n",
    "        print(f\"Reward: {reward:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.963471,
   "end_time": "2025-09-11T23:41:58.487839",
   "environment_variables": {},
   "exception": true,
   "input_path": "bitcoin_grpo_training_with_price_rewards.ipynb",
   "output_path": "out_bitcoin_grpo_training_with_price_rewards.ipynb",
   "parameters": {},
   "start_time": "2025-09-11T23:41:34.524368",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}